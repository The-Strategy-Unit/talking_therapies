---
title: "NHS Talking Therapies"
subtitle: "Evaluation of interventions to improve adherence to therapy in *NHS Talking Therapies Hampshire*"
author: "Craig Parylo"
date: today

title-block-banner: '#151412'
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: true
    embed-resources: true
    fig-format: png
    fig-width: 10
    fig-height: 3
    fig-dpi: 600
    default-image-extension: svg
    lightbox: true
    editor: visual
    favicon: "favicon.ico"
    include-in-header:
      text: |
        <link rel="icon" type="image/x-icon" href="favicon.ico">
brand: _brand.yml
css: styles.css
bibliography: references.bib
---

```{r}
#| label: setup
#| context: setup
#| cache: false

# set up params (NB, the ones in YAML don't work well when running interactively)
params <- list(
  "ods_intervention" = "RAT",
  "intervention_long_name" = "NHS Talking Therapies NELFT",
  "intervention_short_name" = "NHS TT NELFT",
  "download_from_teams" = FALSE,
  "zoo_intervention_month" = zoo::as.yearmon("Sep 2024")
)

# load in utility functions
source(here::here('scripts', 'utility_functions.R'))

# reference files ---

if (params$download_from_teams) {
  # get copies of files that don't need updating every time
  # get a list of projects that have implemented something to improve adherence
  download_file_from_channel(
    str_path = "2. Project delivery/Project plan/TT projects.xlsx",
    str_dest = here::here(
      'data',
      'project',
      'tt_intervention_projects_copy.xlsx'
    )
  )
  # get a summary of interventions conducted by each project
  download_file_from_channel(
    str_path = "2. Project delivery/Project data (quant)/project/tt_interventions_summary.xlsx",
    str_dest = here::here("data", "project", "tt_interventions_summary.xlsx")
  )
  # download the data files
  download_file_from_channel(
    str_path = "2. Project delivery/Project data (quant)/project/.secret/df_matching_contacts.Rds",
    str_dest = here::here("data", ".secret", "df_matching_contacts.Rds")
  )
  download_file_from_channel(
    str_path = "2. Project delivery/Project data (quant)/project/.secret/df_matching_referrals.Rds",
    str_dest = here::here("data", ".secret", "df_matching_referrals.Rds")
  )
  download_file_from_channel(
    str_path = "2. Project delivery/Project data (quant)/project/.secret/df_outcome_supp_discharge_reasons.Rds",
    str_dest = here::here(
      "data",
      ".secret",
      "df_outcome_supp_discharge_reasons.Rds"
    )
  )
  download_file_from_channel(
    str_path = "2. Project delivery/Project data (quant)/project/.secret/df_outcome_supp_reliable_recovery.Rds",
    str_dest = here::here(
      "data",
      ".secret",
      "df_outcome_supp_reliable_recovery.Rds"
    )
  )
}

# part 2 - read the files
df_intervention_services <- read_an_open_excel(
  path = here::here('data', 'project', 'tt_intervention_projects_copy.xlsx'),
  sheet = "intervention_projects"
)

# get a summary of interventions
df_interventions <- read_an_open_excel(
  path = here::here('data', 'project', 'tt_interventions_summary.xlsx'),
  sheet = 'interventions'
) |>
  dplyr::filter(iapt_code == params$ods_intervention) |>
  dplyr::mutate(calc_month = zoo::as.yearmon(month))

# load in matching variables
df <- get_matching_variables()

# load in variable labels
ls_labels <- get_variable_labels()
```

# Executive summary

- Complete at the end -

```{r}
#| label: List of interventions
#| cache: false

df_interventions |>
  dplyr::select(month, intervention) |>
  dplyr::arrange(month) |>
  gt::gt() |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::fmt_date(columns = month, date_style = "yMMM") |>
  gt::cols_label(month = "Month", intervention = "Intervention") |>
  gt::cols_width(month ~ gt::pct(15)) |>
  gt::tab_header(
    title = "Interventions",
    subtitle = "Changes made by the service to better prepare clients for therapy"
  )
```

```{r}
#| label: Timeline of interventions
#| cache: false

# create a df holding details about the timeline
df_timeline <-
  df_interventions |>
  # make fields compatible with {timevis}
  dplyr::rename(content = intervention_html, start = month) |>
  # select essential details
  dplyr::select(content, start)

# display as a timeline
timevis::timevis(data = df_timeline, showZoom = FALSE)

```

<br> *Timeline view of interventions* <br>

## Outcomes

Two outcome measures have been used in this evaluation:

1.  The proportion of discharged referrals where the patient attended five or more treatment sessions

2.  The proportion of discharged referrals that achieved reliable recovery.

These measures follow the numerator and denominator definitions, below.

+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Item               | Definition                                                                                                                                                                                                                                                            |
+====================+=======================================================================================================================================================================================================================================================================+
| Measure            | The proportion of discharged referrals each month where the patient attended five or more treatment sessions.                                                                                                                                                         |
+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Numerator          | Those in the denominator who attended five or more treatment care contacts during their referral^[1](#fn1)^                                                                                                                                                           |
+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Denominator        | Referrals ending each month where the patient received at least two treatment contacts ^[2](#fn2)^                                                                                                                                                                    |
+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Rationale          | This denominator represents monthly discharges for referrals that began a course of therapy.                                                                                                                                                                          |
|                    |                                                                                                                                                                                                                                                                       |
|                    | The numerator is the subset who attended at least five treatment contacts. Recent research identifies five sessions as a minimum associated with greater likelihood of achieving reliable recovery, so this group are those more likely to achieve reliable recovery. |
|                    |                                                                                                                                                                                                                                                                       |
|                    | This measure therefore captures discharged referrals each month that demonstrate sufficient adherence to have at least 50% likelihood of reliable recovery.                                                                                                           |
+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Expected variation | We expect this measure to **increase** as a result of interventions that improve adherence with therapy.                                                                                                                                                              |
+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

: Outcome measure 1

<aside id="footnotes" class="footnotes footnotes-end-of-block" role="doc-footnote">

<ol>

<li id="fn1">

<p>This count will be obtained from the field ‘TreatmentCareContact_Count’ (object I101D29) from the table ‘IDS101Referral’<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p>

</li>

<li id="fn2">

<p>This count will be obtained from the field ‘TreatmentCareContact_Count’ (object I101D29) from the table ‘IDS101Referral’<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p>

</li>

</ol>

</aside>

+--------------------+--------------------------------------------------------------------------------------------------------------------------+
| Item               | Description                                                                                                              |
+====================+==========================================================================================================================+
| Measure            | The proportion of referrals that achieved reliable recovery                                                              |
+--------------------+--------------------------------------------------------------------------------------------------------------------------+
| Numerator          | Of the denominator, those who achieved Reliable recovery^[1](#fn1)^                                                      |
+--------------------+--------------------------------------------------------------------------------------------------------------------------+
| Denominator        | Referrals ending each month where the patient received at least two treatment contacts ^[2](#fn2)^                       |
+--------------------+--------------------------------------------------------------------------------------------------------------------------+
| Rationale          | This measure identifies referrals that attained the target outcome of reliable recovery.                                 |
|                    |                                                                                                                          |
|                    | It serves to evaluate whether changes in this outcome align with the shifts observed in the process measure (Outcome 1). |
+--------------------+--------------------------------------------------------------------------------------------------------------------------+
| Expected variation | We expect this measure to **increase** as a result of interventions that improve adherence with therapy.                 |
+--------------------+--------------------------------------------------------------------------------------------------------------------------+

: Outcome measure 2

<aside id="footnotes" class="footnotes footnotes-end-of-block" role="doc-footnote">

<ol>

<li id="fn1">

<p>Defined as both <code>ReliableImprovement_Flag = `True`</code> <strong>and</strong> <code>Recovery_Flag = `True`</code><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p>

</li>

<li id="fn2">

<p>This count will be obtained from the field ‘TreatmentCareContact_Count’ (object I101D29) from the table ‘IDS101Referral’<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p>

</li>

</ol>

</aside>

## Matching variables

Since no consensus exists on predictors of therapy adherence, a [literature search](https://github.com/The-Strategy-Unit/talking_therapies/blob/main/data/reference/lit_search.xlsx) identified plausible variables. These were shortlisted based on feasibility of measurement in the IAPT dataset.

The selected factors, listed below, are mostly expressed as proportions of either referrals or care contacts. Aggregating patient-level data into these proportions represents the overall Talking Therapies service and makes the variables more suitable for the matching process.

Outcome measure:

-   Proportion of referrals that have completed treatment, but where the patient did not attend at least five treatment sessions.

Demographic characteristics:

-   Proportion of referrals for people aged 25 years and younger at referral

-   Proportion of referrals for people aged 60 years and older at referral

-   Proportion of referrals for people whose gender identity is female

-   Proportion of referrals for people whose LSOA of residence is among the 20% most deprived in England

-   Proportion of referrals for people whose LSOA of residence is among the 20% least deprived in England

-   Proportion of referrals for people whose broad ethnic background is 'White'

Therapist and service characteristics:

-   Proportion of care contacts where the therapist has attained an NHS TT qualification

-   Proportion of care contacts conducted on hospital premises

-   Proportion of care contacts conducted face-to-face

-   Proportion of care contacts outside of weekdays, 9am to 5pm

-   Proportion of care contacts delivered as internet enabled therapy

-   Proportion of care contacts delivered to an individual patient

-   Proportion of referrals where the referral-to-treatment wait time was within six weeks

-   Proportion of referrals where there was step-up to high-intensity therapy

Language and accessibility:

-   Proportion of care contacts conducted in English

-   Proportion of care contacts conducted with an interpreter present

A draft version of these matching variables was shared by email with members of the NHS Talking Therapies (TT) and Individual Placement and Support (IPS) National Programme Delivery Group for review in July 2025. The list above has since been augmented based on feedback.

## Outcomes for `r params$intervention_long_name`

`r params$intervention_long_name` discharges data is available from the beginning of 2022 with the most recent data point being June 2025.

```{r}
#| label: project discharges time series 1
#| fig-height: 7
#| cache: false

p <-
  df |>
  dplyr::filter(ods_code == params$ods_intervention) |>
  ggplot2::ggplot(
    mapping = ggplot2::aes(
      x = calc_month,
      y = o1_denom_discharges_count
    )
  ) +
  # add an arrow and text pointing to start of regular activity
  ggplot2::annotate(
    geom = "segment",
    x = zoo::as.yearmon("Aug 2021"),
    xend = zoo::as.yearmon("Nov 2021"),
    y = 780,
    yend = 780,
    colour = "#5881c1",
    arrow = ggplot2::arrow(type = "closed", length = ggplot2::unit(0.2, "cm"))
  ) +
  ggplot2::annotate(
    geom = "text",
    x = zoo::as.yearmon("Jul 2021"),
    y = 780,
    label = "Discharges begin",
    hjust = 1,
    colour = "#5881c1"
  ) +
  zoo::scale_x_yearmon(limits = c(zoo::as.yearmon(c("Sep 2019")), NA)) +
  # add in the rest of the plot
  ggplot2::geom_line() +
  ggplot2::geom_point() +
  ggplot2::theme_minimal(base_size = 20) +
  ggplot2::theme(axis.title.x = ggplot2::element_blank()) +
  ggplot2::labs(
    title = params$intervention_long_name,
    subtitle = stringr::str_wrap(
      glue::glue(
        "Referral discharges begin with regular frequency from January 2022"
      ),
      60
    ),
    # x = "",
    y = "Number of discharges"
  )
p
# p |> plotly::ggplotly()
```

Following the commencement of activity in January 2022, two months stand out for having notably lower referral discharge volumes:

-   **September 2024**: 2 discharges

-   **September 2025**: 2 discharges

These periods may lead to erratic outcome performance, as the small number of discharges increases the likelihood of statistical volatility - making proportions more sensitive to individual variations.

The time series for each of the outcome variables is shown below. Each plot includes a trendline in [orange]{style="color: #f9bf07;"} and a dotted line in [blue]{style="color: #5881c1;"} indicating when each of the interventions was started.

```{r}
#| label: project outcome 1
#| fig-height: 7
#| cache: false

# filter the data for the project and a suitable timeframe
df_temp <-
  df |>
  dplyr::filter(
    ods_code == params$ods_intervention,
    dplyr::between(
      x = calc_month,
      left = zoo::as.yearmon("Jan 2022"),
      right = zoo::as.yearmon("Aug 2025")
    )
  )

# get a rate of increase for outcome 1
lm_temp <-
  lm(
    formula = o1_rate ~ calc_month,
    data = df_temp
  )

# extract as a variable
rate_per_year <-
  lm_temp |>
  broom::tidy() |>
  dplyr::filter(term == "calc_month") |>
  dplyr::pull(estimate) |>
  round(3)

# plot
df_temp |>
  plot_outcomes_over_time(
    df_interventions = df_interventions,
    var_outcome = "o1_rate",
    trendline = TRUE,
    interventions = TRUE,
    align = "right",
    separation_pct = 0.08,
    title = params$intervention_long_name,
    subtitle = stringr::str_wrap(
      string = describe_trajectory(
        rate_per_year = rate_per_year,
        str_outcome = "Outcome 1"
      ),
      width = 61
    )
  ) +
  ggplot2::theme(
    panel.grid.minor.x = ggplot2::element_blank()
  )
```

```{r}
#| label: project outcome 2
#| fig-height: 7
#| cache: false

# get a rate of increase for outcome 2 - recalculate
lm_temp <-
  lm(
    formula = o2_rate ~ calc_month,
    data = df_temp
  )

# extract as a variable
rate_per_year <-
  lm_temp |>
  broom::tidy() |>
  dplyr::filter(term == "calc_month") |>
  dplyr::pull(estimate) |>
  round(3)

# plot
df_temp |>
  plot_outcomes_over_time(
    df_interventions = df_interventions,
    var_outcome = "o2_rate",
    trendline = TRUE,
    interventions = TRUE,
    align = "right",
    title = params$intervention_long_name,
    subtitle = stringr::str_wrap(
      string = describe_trajectory(
        rate_per_year = rate_per_year,
        str_outcome = "Outcome 2"
      ),
      width = 61
    )
  ) +
  ggplot2::theme(
    panel.grid.minor.x = ggplot2::element_blank()
  )
```

# National outcome trends

We will first look at the national trends for our two outcome measures.

The next two charts include only months in which each services recorded at least 100 discharges. This filter removes unreliable rates that can arise from newly launched services or months with very few discharges.

```{r}
#| fig-height: 7
#| label: outcome 1 national trend
#| cache: false

# filter the data to make it easier to use
df_temp <-
  df |>
  dplyr::filter(
    # limit to the start of activity and exclude latest point
    dplyr::between(
      calc_month,
      zoo::as.yearmon("Jan 2022"),
      zoo::as.yearmon("May 2025")
    ),
    # limit to months where each service has more than 100 discharges to avoid spurious rates
    o1_denom_discharges_count > 100
  )

# linear model
lm_temp <-
  lm(
    formula = o1_rate ~ calc_month,
    data = df_temp
  )
# extract as a variable
rate_per_year <- lm_temp |>
  broom::tidy() |>
  dplyr::filter(term == "calc_month") |>
  dplyr::pull(estimate) |>
  round(3)

# get average rates per month
df_summary_per_month <-
  df_temp |>
  dplyr::summarise(
    o1_rate_av = mean(o1_rate, na.rm = TRUE),
    o1_rate_sd = sd(o1_rate, na.rm = TRUE),
    o2_rate_av = mean(o2_rate, na.rm = TRUE),
    o2_rate_sd = sd(o2_rate, na.rm = TRUE),
    .by = c(calc_month)
  ) |>
  dplyr::arrange(calc_month)

# show a spaghetti plot of all TT services over time
ggplot2::ggplot() +
  # add traces for each individual TT service
  ggplot2::geom_line(
    data = df_temp,
    mapping = ggplot2::aes(
      x = calc_month,
      y = o1_rate,
      group = ods_code
    ),
    colour = adjustcolor("#9d928a", alpha.f = 0.3),
    linewidth = 0.5
  ) +
  # add a ribbon of +/- one sd to show spread
  ggplot2::geom_ribbon(
    data = df_summary_per_month,
    mapping = ggplot2::aes(
      x = calc_month,
      ymin = (o1_rate_av - o1_rate_sd),
      ymax = (o1_rate_av + o1_rate_sd)
    ),
    fill = adjustcolor("#f9bf07", alpha.f = 0.2)
  ) +
  # add a trendline
  ggplot2::geom_smooth(
    data = df_temp,
    mapping = ggplot2::aes(x = calc_month, y = o1_rate),
    method = "lm",
    formula = y ~ x, # made explicit to avoid console messages
    se = FALSE,
    colour = adjustcolor("#2c2825", alpha.f = 1),
    linetype = "dotted"
  ) +
  ggplot2::scale_y_continuous(labels = scales::label_percent(accuracy = 1)) +
  zoo::scale_x_yearmon() +
  ggplot2::theme_minimal(base_size = 20) +
  ggplot2::theme(
    axis.title = ggplot2::element_blank()
  ) +
  ggplot2::labs(
    title = "Outcome 1: discharges with 5+ treatment contacts",
    subtitle = glue::glue(
      "National trend since 2022 is upwards at a rate of {rate_per_year * 100}% per year"
    )
  )
```

**What the chart shows:**

-   Each grey line traces a single Talking Therapy service's monthly performance on outcome 1 (percentage of discharged referrals that received at least five treatment contacts).

-   The dotted line is a linear regression that captures the overall trend across all services.

-   The yellow band around the dotted line marks ± 1 standard deviation, illustrating the typical spread of service-level rates.

Nationally, the proportion of referrals meeting the 5-contact threshold has risen by around 1.6% per year, climbing from \~57% in Jan 2022 to \~ 62% in May 2025. Monthly results are highly variable; some services approach 100% in certain months, while others fall to near 0%, especially during mid-to-late 2023 when several services achieved 0% in several months.

The upward national trend indicates overall improvement, but the wide dispersion (yellow band) shows that individual services experience very different outcomes, highlighting opportunities for targeted support.

```{r}
#| fig-height: 7
#| label: outcome 2 national trend
#| warning: false
#| cache: false

# linear model
lm_temp <-
  lm(
    formula = o2_rate ~ calc_month,
    data = df_temp
  )
# extract as a variable
rate_per_year <- lm_temp |>
  broom::tidy() |>
  dplyr::filter(term == "calc_month") |>
  dplyr::pull(estimate) |>
  round(3)

# show a spaghetti plot of all TT services over time
ggplot2::ggplot() +
  # add traces for each individual TT service
  ggplot2::geom_line(
    data = df_temp,
    mapping = ggplot2::aes(
      x = calc_month,
      y = o2_rate,
      group = ods_code
    ),
    colour = adjustcolor("#9d928a", alpha.f = 0.3),
    linewidth = 0.5
  ) +
  # add a ribbon of +/- one sd to show spread
  ggplot2::geom_ribbon(
    data = df_summary_per_month,
    mapping = ggplot2::aes(
      x = calc_month,
      ymin = (o2_rate_av - o2_rate_sd),
      ymax = (o2_rate_av + o2_rate_sd)
    ),
    fill = adjustcolor("#f9bf07", alpha.f = 0.2)
  ) +
  # add a trendline
  ggplot2::geom_smooth(
    data = df_temp,
    mapping = ggplot2::aes(x = calc_month, y = o2_rate),
    method = "lm",
    formula = y ~ x, # made explicit to avoid console messages
    se = FALSE,
    colour = adjustcolor("#2c2825", alpha.f = 1),
    linetype = "dotted"
  ) +
  ggplot2::scale_y_continuous(labels = scales::label_percent(accuracy = 1)) +
  zoo::scale_x_yearmon() +
  ggplot2::theme_minimal(base_size = 20) +
  ggplot2::theme(
    axis.title = ggplot2::element_blank()
  ) +
  ggplot2::labs(
    title = "Outcome 2: discharges achieving reliable recovery",
    subtitle = glue::glue(
      "National trend since 2022 is upwards at a rate of {rate_per_year * 100}% per year"
    )
  )
```

**What the chart shows:**

-   Each grey line traces a single Talking Therapy service's monthly performance on outcome 2 (percentage of discharged referrals that received between 2 and 4 treatment contacts).

-   The dotted line is a linear regression that captures the overall trend across all services.

-   The yellow band around the dotted line marks ± 1 standard deviation, illustrating the typical spread of service-level rates.

The national share of these referrals has been increasing at a rate of 0.2% per year since 2022. Some services report low rates for this outcome each month, indicating most of their completed cases do not achieve reliable recovery. Other services show over 50% of completed referrals achieving reliable recovery which exceeds the national ambition to achieve 50% reliable recovery in Talking Therapy referrals.

While the overall picture is improving, the wide spread among individual services suggests targeted interventions are needed to help the higher-percentage providers move more referrals toward the five-contact benchmark.

# Matching variables

The aim of matching is to pair our intervention service, *`r params$intervention_long_name`*, with one or more untreated services that have similar characteristics, creating a comparison group that mimics a randomised experiment. This reduces bias and makes it easier to estimate the intervention's effect from observational data.

## Using all matching variables - `r params$zoo_intervention_month - 1/12`

The dataset is cut off at `r params$zoo_intervention_month - 1/12`, the month immediately before `r params$intervention_short_name` launched its first intervention. This pre-intervention slice will serve as the basis for the matching process.

In the initial matching run we include all matching variables and specify five nearest neighbour services. Using several candidates increases the chance of finding at least one service that meets the parallel-trends assumption.

```{r}
#| label: matching_all_vars
#| fig-height: 9
#| cache: false
#| eval: false

# get a list of matching vars
temp_vars <- stringr::str_subset(string = names(df), pattern = "^m.*_rate$")

# prepare the data
df_prep <-
  df |>
  # keep just the variables of interest
  dplyr::select(
    c(
      ods_code,
      name,
      calc_month,
      flag_intervention,
      dplyr::contains("o1_denom"),
      dplyr::contains("_rate")
    )
  ) |>
  dplyr::filter(
    # keep services that have data for all the matching variables
    dplyr::if_all(
      .cols = dplyr::any_of(temp_vars),
      .fns = ~ !is.na(.)
    ),
    # keep services that have activity up to censor
    max(calc_month, na.rm = TRUE) >= zoo::as.yearmon("Sep 2025"),
    # keep services that have activity in each of the matching yearmonths
    # all(yearmons_matching %in% calc_month),
    # exclude other services that have implemented an intervention
    (ods_code == params$ods_intervention | flag_intervention == 0),
    .by = ods_code
  ) |>
  # shorten the 'o1_denom' variable name
  dplyr::rename("o1_denom" = o1_denom_discharges_count) |>
  # limit to just month before the interventions began
  dplyr::filter(calc_month == params$zoo_intervention_month - 1 / 12)

# string wrap variable names to better fit the plot
ls_labels_wrap <-
  purrr::modify_if(
    .x = ls_labels,
    .p = is.character,
    .f = ~ stringr::str_wrap(string = .x, width = 50)
  )

# set the matching formula
formula_matching <-
  formula(
    paste0(
      "flag_intervention ~ ",
      paste0(
        stringr::str_subset(
          string = names(df_prep),
          pattern = "^m.*_rate$"
        ),
        collapse = " + "
      )
    )
  )

# do the matching
obj_matches <-
  MatchIt::matchit(
    data = df_prep,
    formula = formula_matching,
    distance = "glm",
    method = "nearest",
    ratio = 5,
  )

# review the covariate balance
cobalt::love.plot(
  x = obj_matches,
  abs = TRUE,
  thresholds = 0.1,
  var.names = ls_labels_wrap,
  stars = "raw",
  drop.distance = TRUE
) +
  ggplot2::theme_minimal(base_size = 16) +
  ggplot2::scale_colour_manual(
    values = c("Unadjusted" = "#ec6555", Adjusted = "#5881c1")
  )
```

There are three warning messages displayed. The first two warning messages come from the propensity score matching process and likely indicate issues such as perfect separation of the data, or multicollinearity, which break key logistic regression assumptions. The third warning message comes from the process to visualise the model.

Reviewing the data reveals possible causes:

-   M14 Proportion of contacts conducted in English - the asterisk means the 'raw' score is displayed rather than absolute standardised mean differences the rest of the variables are displayed in

Clearly, using all these matching variables is problematic. Let's investigate further ...

## Examining matching variables

### Pre-matching assessment

First let us see the level of balance in the matching variables before any matching occurs:

```{r}
#| label: pre-matching covariate balance
#| cache: false
#| eval: false

# set the matching formula
formula_matching <-
  formula(
    paste0(
      "flag_intervention ~ ",
      paste0(
        c(
          stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
          stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
        ),
        collapse = " + "
      )
    )
  )

# check the balance prior to matching
set.seed(123)
match_pre <-
  MatchIt::matchit(
    formula = formula_matching,
    data = df_prep,
    method = NULL,
    distance = 'glm'
  ) |>
  summary()

t <-
  match_pre$sum.all |>
  tibble::as_tibble(rownames = "Matching variable") |>
  # exclude the distance metric - it isn't very useful here
  dplyr::filter(`Matching variable` != "distance") |>
  # drop the var. ratio and std. pair dist measures as they're not useful as the model doens't resolve
  dplyr::select(-c(`Var. Ratio`, `Std. Pair Dist.`)) |>
  gt::gt() |>
  gt::fmt_number(
    columns = gt::everything(),
    decimals = 4
  ) |>
  gt::data_color(
    columns = c(`Std. Mean Diff.`),
    method = "numeric",
    palette = "#f5b2aa",
    rows = abs(`Std. Mean Diff.`) < 0.1
  ) |>
  gt::tab_options(quarto.disable_processing = TRUE)
t
```

This table lists each matching variable together with its average value for `r params$intervention_long_name` (the treated group) and for all other donor services (the control group).

Our goal is to identify variables that show large differences, because those are the ones that the matching process can potentially improve. Variables with a standardised mean difference less than 0.1 are highlighted in pink. Variables which are uncoloured indicate where we could increase similarity between the treated and control groups.

Variables with less than 0.1 difference are less promising for improvement. In this case:

-   `m13_rate` (M13 Proportion of contacts conducted outside of weekdays, 9am to 5pm)

-   `m14_rate` (M14 Proportion of contacts conducted in English)

**Recommendation:** drop `m13_rate` and `m14_rate` from the matching process as there is little scope to improve balance on these variables.

### Separation

Perfect separation occurs when the model can perfectly predict treatment assignment based solely on covariates - meaning it assigns propensity scores of exactly 0 or 1. In this scenario, treated and untreated units become completely distinguishable, making it impossible to find suitable matches for some observations. This lack of overlap in covariate distributions can lead to biased or unstable estimates.

In our case, where covariates are expressed as proportions bounded between 0 and 1, separation may arise when these covariates take on extreme values of exactly 0 or 1.

Here we see a list of covariates for `r params$intervention_long_name` which have values of exactly 0 or 1:

```{r}
#| label: separation
#| cache: false
#| eval: false

# list the variables likely to result in perfect separation
df_prep |>
  # get the project's record
  dplyr::filter(ods_code == params$ods_intervention) |>
  # pivot so that variables are now rows
  tidyr::pivot_longer(
    cols = c(
      dplyr::everything(),
      -dplyr::any_of(c("ods_code", "name", "calc_month", "flag_intervention"))
    ),
    names_to = "variable",
    values_to = "value"
  ) |>
  # filter for values of either 1 or 0
  dplyr::filter(
    value %in% c(0L, 1L),
    !variable %in% c("m13_rate", "m14_rate") # already excluded from the above process
  ) |>
  # add in variable descriptions
  dplyr::left_join(
    y = tibble::tibble(
      variable = names(ls_labels),
      description = as.character(unname(ls_labels))
    ),
    by = dplyr::join_by("variable")
  ) |>
  # display the result
  dplyr::select(variable, description, value) |>
  gt::gt() |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::cols_label(
    variable = "Matching variable",
    value = params$zoo_intervention_month - 1 / 12,
    description = "Variable description"
  )
```

**Recommendation:** drop `m15_rate` and `m16_rate` from the matching process as they are likely to result in perfect separation.

### Multicollinearity

Multicollinearity occurs when two or more matching variables are highly linearly related. Because such variables convey overlapping information, the matching process struggles to calculate reliable propensity scores.

In this section we identify strongly related matching variables using the Variance Inflation Factor (VIF). VIF measures how much a variable is linearly related to the others; higher values indicate stronger multicollinearity.

-   A VIF between 5 and 10 is often considered a warning sign. In the table below these are highlighted in yellow.
-   A VIF greater than 10 strongly signals multicollinearity. Variables with such high VIF values should be excluded from the model. In the table below, any variable whose VIF exceeds 10 is highlighted in pink to flag a potential problem.

```{r}
#| label: multicollinearity - step 1
#| cache: false
#| eval: false

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(
  matching_vars,
  c("m13_rate", "m14_rate", "m15_rate", "m16_rate")
)
t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

**Next step:** evaluate the impact of removing `m12_rate` from the matching model.

```{r}
#| label: multicollinearity - step 2
#| cache: false
#| eval: false

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(
  matching_vars,
  c("m13_rate", "m14_rate", "m15_rate", "m16_rate", "m12_rate")
)
t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

**Next step:** remove `m8_rate` from the matching model.

```{r}
#| label: multicollinearity - step 3
#| cache: false
#| eval: false

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(
  matching_vars,
  c(
    "m13_rate",
    "m14_rate",
    "m15_rate",
    "m16_rate",
    "m12_rate",
    "m8_rate"
  )
)
t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

**Next step:** drop `m6_rate` from the matching model.

```{r}
#| label: multicollinearity - step 4
#| cache: false
#| eval: false

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(
  matching_vars,
  c(
    "m13_rate",
    "m14_rate",
    "m15_rate",
    "m16_rate",
    "m12_rate",
    "m8_rate",
    "m6_rate"
  )
)
t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

**Next step:** remove `m5_rate` from the matching model.

```{r}
#| label: multicollinearity - step 5
#| cache: false
#| eval: false

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(
  matching_vars,
  c(
    "m13_rate",
    "m14_rate",
    "m15_rate",
    "m16_rate",
    "m12_rate",
    "m8_rate",
    "m6_rate",
    "m5_rate"
  )
)
t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

**Next step:** remove `m3_rate`from the matching model.

```{r}
#| label: multicollinearity - step 6
#| cache: false
#| eval: false

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(
  matching_vars,
  c(
    "m13_rate",
    "m14_rate",
    "m15_rate",
    "m16_rate",
    "m12_rate",
    "m8_rate",
    "m6_rate",
    "m5_rate",
    "m3_rate"
  )
)
t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

**Next step:** drop `m7_rate` from the matching model.

```{r}
#| label: multicollinearity - step 7
#| cache: false
#| eval: false

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(
  matching_vars,
  c(
    "m13_rate",
    "m14_rate",
    "m15_rate",
    "m16_rate",
    "m12_rate",
    "m8_rate",
    "m6_rate",
    "m5_rate",
    "m3_rate",
    "m7_rate"
  )
)
t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

**Next step:** drop `o1_denom` from the matching model.

```{r}
#| label: multicollinearity - step 8
#| cache: false
#| eval: false

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(
  matching_vars,
  c(
    "m13_rate",
    "m14_rate",
    "m15_rate",
    "m16_rate",
    "m12_rate",
    "m8_rate",
    "m6_rate",
    "m5_rate",
    "m3_rate",
    "m7_rate",
    "o1_denom"
  )
)

t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

**Next step:** drop `m4_rate` from the matching model.

```{r}
#| label: multicollinearity - step 9
#| cache: false
#| eval: false

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(
  matching_vars,
  c(
    "m13_rate",
    "m14_rate",
    "m15_rate",
    "m16_rate",
    "m12_rate",
    "m8_rate",
    "m6_rate",
    "m5_rate",
    "m3_rate",
    "m7_rate",
    "o1_denom",
    "m4_rate"
  )
)

t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

All matching variables now have VIF scores below 3, confirming they are suitable for propensity-score matching. The model has converged, so the matching process proceeds without issue; the only remaining warning relates to having a single treated service and can safely be ignored.

The set of matching variables now consists of:

```{r}
#| label: multicollinearity - final list of variables
#| cache: false
#| eval: false

# get the list of variables in a tibble
df_matching_var_labels <-
  tibble::tibble(
    variable = names(ls_labels),
    description = unlist(ls_labels, use.names = FALSE)
  ) |>
  dplyr::filter(variable %in% matching_vars)

# present as a {gt} table
df_matching_var_labels |>
  gt::gt() |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::cols_label(
    variable = "Variable name",
    description = "Variable description"
  )
```

# Analysis

## Propensity score matching - `r params$zoo_intervention_month - 1/12`

Using this list of matching variables we can now re-examine the propensity score matching results for `r params$intervention_long_name`.

The below plot is called a love plot (also known as a covariate balance plot) which visualises how well our matching variables are balanced between `r params$intervention_long_name` before and after applying a propensity-score matching process.

Our matching variables are listed along the y-axis and the x-axis shows the standardised mean difference (SMD), which is a measure of how different the averages are between the two groups.

Points in red indicate the differences between `r params$intervention_long_name` and all other Talking Therapy services before matching. Points in blue indicate the differences between `r params$intervention_long_name` and eight of the closest matched services.

The dotted line is a reference at 0.2 SMD that indicates an acceptable imbalance threshold.

```{r}
#| label: propensity score matching new
#| fig-height: 7
#| message: false
#| warning: false
#| cache: false
#| eval: false

# set the matching formula
formula_matching <-
  formula(
    paste0(
      "flag_intervention ~ ",
      paste0(matching_vars, collapse = " + ")
    )
  )

# do the matching
obj_matches <-
  MatchIt::matchit(
    data = df_prep,
    formula = formula_matching,
    distance = "glm",
    method = "nearest",
    ratio = 8,
  )

# review the covariate balance
cobalt::love.plot(
  x = obj_matches,
  abs = TRUE,
  thresholds = 0.2,
  var.names = ls_labels_wrap,
  stars = "raw",
  drop.distance = FALSE,
  var.order = "unadjusted"
) +
  ggplot2::theme_minimal(base_size = 16) +
  ggplot2::scale_colour_manual(
    values = c("Unadjusted" = "#ec6555", Adjusted = "#5881c1")
  )
```

These results indicate that the matched services are reasonably close, though not perfect, comparators for `r params$intervention_long_name`.

Following matching, three variables show improved balance between `r params$intervention_long_name` and the eight matched services, as evidenced by blue points being closer to zero than red points. However, one variable (M9) became notably more imbalanced post-matching and another variable (M10) became slightly more imbalanced.

Three variables fall within the 0.2 Standardised Mean Difference (SMD) threshold.

The eight matched services identified through this process are listed in the table below:

```{r}
#| label: propensity score matches
#| fig-height: 8
#| cache: false
#| eval: false

# extract the matches
matches <- MatchIt::get_matches(obj_matches)

# show in a table
matches |>
  dplyr::select(name, ods_code) |>
  dplyr::mutate(
    ods_code = ods_code |>
      as.factor() |>
      forcats::fct_relevel(params$ods_intervention)
  ) |>
  dplyr::arrange(ods_code) |>
  gt::gt() |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::data_color(
    columns = gt::everything(),
    rows = ods_code == params$ods_intervention,
    palette = "#f9bf07"
  ) |>
  gt::cols_label(
    name = "Talking Therapies organisation",
    ods_code = "ODS code"
  )
```

### Parallel trends assumption

The parallel trends assumption states that, if the intervention never occurred, `r params$intervention_long_name` and its control group would have followed the same trajectory over time. A difference-in-differences (DiD) analysis depends on this assumption because it uses the control group's pre-intervention trend as the counterfactual for `r params$intervention_long_name`.

To check this assumption holds we look at the pre-intervention period and if the outcome trends for both groups move together (i.e. have similar slopes), the assumption is plausible.

We will now assess the pre-intervention trends for `r params$intervention_long_name` (shown in orange) and each of the eight matched Talking Therapy services (shown in grey). Trendlines are overlaid on each plot to make it easier to judge whether the series move together.

#### Talking Matters Sefton (W5N3Z)

Outcome 1: ❌ The trends are not parallel - they are convergent

Outcome 2: ✔️ The trends are more or less parallel

```{r}
#| label: PSM - talking matters sefton
#| fig-height: 8
#| cache: false
#| eval: false

# plots comparing each matched service
plot_list <-
  purrr::map(
    # select the matches - but exclude the project
    .x = stringr::str_subset(
      string = matches$ods_code,
      pattern = params$ods_intervention,
      negate = TRUE
    ),
    .f = \(.x) {
      p <-
        compare_matches_preintervention(
          df = df,
          selected_ods = c(params$ods_intervention, .x),
          period_preintervention = zoo::as.yearmon(c(
            "Jan 2022",
            as.character(params$zoo_intervention_month - 1 / 12)
          )),
          trendline = TRUE
        )
      return(p)
    }
  )

# display
plot_list[[1]]
```

#### Vita Health Group; Vitaminds Bristol, North Somerset & South Gloucestershire (NWC07)

Outcome 1: ✔️ The trends are parallel

Outcome 2: ✔️ The trends are parallel

```{r}
#| label: PSM - vita health group
#| fig-height: 8
#| cache: false
#| eval: false
plot_list[[2]]
```

#### Westminster Wellbeing Service (RV3DG)

Outcome 1: ✔️ The trends are almost parallel - there is a hint of divergence

Outcome 2: ✔️ The trends are parallel

```{r}
#| label: PSM - westminster
#| fig-height: 8
#| cache: false
#| eval: false
plot_list[[3]]
```

#### Mill House (RV3AR)

Outcome 1: ✔️ The trends are almost parallel - there is a hint of divergence

Outcome 2: ✔️ The trends are parallel

```{r}
#| label: PSM - mill house
#| fig-height: 8
#| cache: false
#| eval: false
plot_list[[4]]
```

#### Take Time to Talk (RV3L8)

Outcome 1: ❌ The trends are not parallel - they are divergent

Outcome 2: ✔️ The trends are parallel

```{r}
#| label: PSM - take time to talk
#| fig-height: 8
#| cache: false
#| eval: false
plot_list[[5]]
```

#### Warrington Psychological Service (NO202)

Outcome 1: ❌ The trends are not parallel - they interesected around September 2022

Outcome 2: ❌ The trends are not parallel - they are divergent

```{r}
#| label: PSM - warrington
#| fig-height: 8
#| cache: false
#| eval: false
plot_list[[6]]
```

#### IESO Digital Health (UK) (AM601)

Outcome 1: ❌ The trends are not parallel - they are divergent

Outcome 2: ✔️ The trends are almost parallel

```{r}
#| label: PSM - ieso
#| fig-height: 8
#| cache: false
#| eval: false
plot_list[[7]]
```

#### IAPT Services (RV3HC)

Outcome 1: ✔️ The trends are parallel

Outcome 2: ✔️ The trends are parallel

```{r}
#| label: PSM - iapt services
#| fig-height: 8
#| cache: false
#| eval: false
plot_list[[8]]
```

### Matching summary

A total of eight Talking Therapy services were matched with `r params$intervention_long_name` using *Propensity Score Matching (PSM)*. Of these, four had pre-intervention trends that visually match those of `r params$intervention_long_name`'s for both outcome measures.

```{r}
#| label: psm - matches with parallel trends
#| cache: false
#| eval: false

# list out the matches with parallel pre-intervention trends
matches_parallel_ods <- c("NWC07", "RV3DG", "RV3AR", "RV3HC")

# add these controls to a list for use in the synthetic control section
controls <-
  list(
    "psm_all" = matches$ods_code,
    "psm_parallel" = matches_parallel_ods
  )

# display these in a table
matches |>
  dplyr::filter(ods_code %in% matches_parallel_ods) |>
  dplyr::select(name, ods_code) |>
  dplyr::arrange(ods_code) |>
  gt::gt() |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::cols_label(
    name = "Talking Therapies organisation",
    ods_code = "ODS code"
  )
```

### Analysis

Now we have matched `r params$intervention_long_name` with other Talking Therapies services and assessed their likelihood of meeting the parallel trends assumption based on their pre-intervention data, let us review how the full time series looks for this group of services.

#### Outcome 1

```{r}
#| label: psm - spaghetti plot1 outcome 1
#| fig-height: 6
#| cache: false
#| eval: false

# get a df with the details for our matched services
df_analysis <-
  df |>
  dplyr::filter(
    # limit to activity between Jan 2022 and Sep 2025
    dplyr::between(
      calc_month,
      zoo::as.yearmon("Jan 2022"),
      zoo::as.yearmon("Sep 2025")
    ),
    # limit to our matched services with parallel trends
    ods_code %in% c(params$ods_intervention, matches_parallel_ods)
  ) |>
  # simplify the data
  dplyr::select(ods_code, calc_month, o1_rate, o2_rate) |>
  # create treatment and post indicators
  dplyr::mutate(
    treated = dplyr::if_else(ods_code == params$ods_intervention, 1L, 0L),
    post = dplyr::if_else(calc_month >= params$zoo_intervention_month, 1L, 0L),
    line_colour = dplyr::if_else(
      ods_code == params$ods_intervention,
      "#f9bf07",
      adjustcolor("#9d928a", alpha.f = 0.5)
    )
  )

# show a spaghetti plot for these services
p <-
  plot_spaghetti_plot(
    df = df_analysis,
    str_outcome = "o1_rate",
    ods_intervention = params$ods_intervention,
    str_title = "Outcome 1: discharges with 5+ treatment contacts",
    str_subtitle = "RW1 displays abnormal results in Sep 2024 and Sep 2025",
    zoo_intervention = params$zoo_intervention_month,
    bool_intervention = TRUE,
    .yearmon_scale_to = zoo::as.yearmon("Nov 2025")
  )
p
# p |> plotly::ggplotly()
```

**What this chart shows:**

-   Performance against outcome 1 is shown on the y-axis and time is along the x-axis.

-   There are three time series displayed, one for `r params$intervention_long_name`, shown in orange, and one for each of the two of our matched services, shown in grey.

-   Each series is identified by its ODS code at the end of the data in May 2025.

-   The dotted line represents the start of `r params$intervention_long_name`'s interventions in `r params$zoo_intervention_month`.

```{r}
#| label: psm - anomalous months outcome 1
#| cache: false
#| eval: false

# return any anomalous observations
identify_anomalies(
  df = df_analysis,
  outcome = "o1_rate",
  iqr_alpha = 0.05,
  anomaly_threshold = 0.2
) |>
  identify_anomalies_gt()
```

**Key observations**

Our intervention service, RW1, exhibited abnormal dips:

-   September 2024 - 0%

-   September 2025 - 0%

These brief, but steep declines would bias the post-implementation estimates downward for the intervention service. To avoid this bias, the low-performance points should be excluded from the dataset.

#### Outcome 2

```{r}
#| label: psm - spaghetti plot1 outcome 2
#| fig-height: 6
#| cache: false
#| eval: false

# show a spaghetti plot for these services
p <-
  plot_spaghetti_plot(
    df = df_analysis,
    str_outcome = "o2_rate",
    ods_intervention = params$ods_intervention,
    str_title = "Outcome 2: discharges achieving reliable recovery",
    str_subtitle = "RW1 displays abnormal results in September 2025",
    zoo_intervention = params$zoo_intervention_month,
    bool_intervention = TRUE,
    .yearmon_scale_to = zoo::as.yearmon("Nov 2025")
  )
p
# p |> plotly::ggplotly()
```

```{r}
#| label: psm - anomalous months outcome 2
#| cache: false
#| eval: false

# return any anomalous observations
identify_anomalies(
  df = df_analysis,
  outcome = "o2_rate",
  iqr_alpha = 0.05,
  anomaly_threshold = 0.2
) |>
  identify_anomalies_gt()
```

**Key observations**

Our intervention service, RW1, exhibited an abnormal dip to 0% in September 2025.

#### Both outcomes excluding outliers

```{r}
#| label: psm - spaghetti plot2 outcomes 1 and 2
#| fig-height: 6
#| cache: false
#| eval: false

# get a df excluding the problematic months for the controls
df_analysis2 <-
  df_analysis |>
  dplyr::filter(
    !(ods_code == "RW1" &
      calc_month %in% zoo::as.yearmon(c("Sep 2024", "Sep 2025")))
  )

# show as a spaghetti plot
plot_spaghetti_plot(
  df = df_analysis2,
  str_outcome = "o1_rate",
  ods_intervention = params$ods_intervention,
  str_title = "Outcome 1: discharges with 5+ treatment contacts",
  str_subtitle = "These time series now seem less likely to bias the analysis",
  zoo_intervention = params$zoo_intervention_month,
  bool_intervention = TRUE,
  .yearmon_scale_to = zoo::as.yearmon("Nov 2025")
)

# show as a spaghetti plot
plot_spaghetti_plot(
  df = df_analysis2,
  str_outcome = "o2_rate",
  ods_intervention = params$ods_intervention,
  str_title = "Outcome 2: discharges with reliable recovery",
  str_subtitle = "These time series now seem less likely to bias the analysis",
  zoo_intervention = params$zoo_intervention_month,
  bool_intervention = TRUE,
  .yearmon_scale_to = zoo::as.yearmon("Nov 2025")
)
```

#### Difference-in-Differences (DiD)

The results of the DiD analyses are presented below:

```{r}
#| label: psm - did table
#| cache: false
#| eval: false

# conduct did analysis on the matched service
did <-
  get_manual_did_estimation(
    df = df_analysis2,
    ods_intervention = params$ods_intervention,
    zoo_intervention = params$zoo_intervention_month
  )

# add to a combined summary (for sensitivity analysis)
did_overall <-
  did |>
  dplyr::mutate(specification = "Main model (baseline)")

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  tibble::tibble(
    specification = "PSM main model",
    outcome = did$outcome,
    estimate = did$estimate,
    se = did$std.error
  )

# display
did |> display_manual_did_results_as_gt()
```

This table summarises the Difference-in-Differences (DiD) analysis for `r params$intervention_long_name`'s interventions using the <r controls$psm_parallel |> length()> control services identified using the Propensity Score Matching process and which exhibited parallel trends.

There is no strong evidence of a true effect for either outcome at the conventional 5% significance level.

The point estimates give the best single indicator of direction and magnitude:

-   Outcome 1: small increase around 0.4%

-   Outcome 2: small decrease of 0.5%

Since neither confidence interval excludes zero, **these findings are not statistically significant**, indicating that the observed differences could be due to chance rather than a true effect.

::: callout-tip
#### Interpretation

```{r}
#| label: interpretation help psm
#| cache: false
#| eval: false

# work out the total discharges in 12 months preceeding
total_discharges <-
  df |>
  dplyr::filter(
    ods_code == params$ods_intervention,
    dplyr::between(
      calc_month,
      zoo::as.yearmon("Jun 2024"),
      zoo::as.yearmon("May 2025")
    )
  ) |>
  dplyr::summarise(
    total = sum(o1_denom_discharges_count, na.rm = TRUE)
  ) |>
  dplyr::pull(total)

# work out the expected number of people to benefit from the uplift
people_benefit_o1 <- floor(total_discharges * (did$estimate[1]))
people_benefit_o2 <- floor(total_discharges * (did$estimate[2]))
```

These findings indicate `r params$intervention_long_name`'s post-intervention performance exceeds the counterfactual for outcomes 2, but the confidence interval is too wide to support a definitive claim of effectiveness.

-   Assuming the <r scales::percent(did$estimate[1], accuracy = 0.01)> change is real, it translates to <r dplyr::if_else(did$estimate[1] > 0, "an additional", "a reduction of")> <r people_benefit_o1> people receiving 5+ treatment contacts as part of their referral.

-   Assuming the <r scales::percent(did$estimate[2], accuracy = 0.01)> change is real, it translates to <r dplyr::if_else(did$estimate[2] > 0, "an additional", "a reduction of")> <r people_benefit_o2> people achieving reliable recovery.

NB, these estimates are based based on `r params$intervention_long_name`'s annual discharge volume of <r scales::comma(total_discharges)> from June 2024 to May 2025.
:::

### Sensitivity analysis

Two important decisions were made that led to the above analytical findings:

1.  **Parallel trend selection** - We inspected the 8 matched control services visually and excluded four that did not follow `r params$intervention_long_name`'s pre-intervention trend.

2.  **Anomalous month removal** - For the remaining matched services we omitted several months for one service with extreme values, which yielded more stable performance across outcomes.

Below we reassess the findings after relaxing each of these decisions to determine whether the original conclusions hold are are sensitive to these analytical choices.

#### Keeping anomalous months

What impact does keeping the extreme values in the time series have?

```{r}
#| label: psm - sensitivity - anomalous months
#| cache: false
#| eval: false

# conduct did analysis on the two matched services
did <-
  get_manual_did_estimation(
    df = df_analysis,
    ods_intervention = params$ods_intervention,
    zoo_intervention = params$zoo_intervention_month
  )

# add to a combined summary (for sensitivity analysis)
did_overall <-
  dplyr::bind_rows(
    did_overall,
    did |>
      dplyr::mutate(specification = "Alternative 1 - keep anomalous months")
  )

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "PSM alternative 1 - keep anomalous months",
      outcome = did$outcome,
      estimate = did$estimate,
      se = did$std.error
    )
  )

# show as a table
did |> display_manual_did_results_as_gt()
```

-   For outcome 1 the DiD estimate switches to a negative estimate of -6.21%, and the confidence interval is much wider.

-   For outcome 2 the DiD estimate becomes more negative (-2.13%) and the confidence interval is wider too.

Sensitivity analyses relaxing the exclusion of anomalous months resulted in both estimates becoming negative, though with wider confidence intervals. These results suggest that the estimated effects sensitive to the inclusion of outlier data and remain statistically inconclusive.

#### Using all PSM controls

What impact does using all 8 matched control services have on the findings?

```{r}
#| label: psm - sensitivity - all controls
#| cache: false
#| eval: false

df_analysis3 <-
  df |>
  dplyr::filter(
    # limit to activity between Jan 2022 and Sep 2025
    dplyr::between(
      calc_month,
      zoo::as.yearmon("Jan 2022"),
      zoo::as.yearmon("Sep 2025")
    ),
    # limit to our matched services
    ods_code %in% c(params$ods_intervention, controls$psm_all)
  ) |>
  # simplify the data
  dplyr::select(ods_code, calc_month, o1_rate, o2_rate) |>
  # create treatment and post indicators
  dplyr::mutate(
    treated = dplyr::if_else(ods_code == params$ods_intervention, 1L, 0L),
    post = dplyr::if_else(calc_month >= params$zoo_intervention_month, 1L, 0L),
    line_colour = dplyr::if_else(
      ods_code == params$ods_intervention,
      "#f9bf07",
      adjustcolor("#9d928a", alpha.f = 0.5)
    )
  ) |>
  # remove the anomalous months (to isolate the effect of expanding controls)
  dplyr::filter(
    !(ods_code == "RW1" &
      calc_month %in% zoo::as.yearmon(c("Sep 2024", "Sep 2025")))
  )

# conduct did analysis
did <-
  get_manual_did_estimation(
    df = df_analysis3,
    ods_intervention = params$ods_intervention,
    zoo_intervention = params$zoo_intervention_month
  )

# add to a combined summary (for sensitivity analysis)
did_overall <-
  dplyr::bind_rows(
    did_overall,
    did |>
      dplyr::mutate(specification = "Alternative 2 - use all 8 controls")
  )

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "CEM alternative 2 - use all 8 controls",
      outcome = did$outcome,
      estimate = did$estimate,
      se = did$std.error
    )
  )

# display as a table
did |> display_manual_did_results_as_gt()
```

-   For outcome 1 the DiD estimate switches to a negative estimate of -2.23%, and the confidence interval is much wider.

-   For outcome 2 the DiD estimate becomes slightly less negative (-0.21%) and the confidence interval is reduced though still includes zero.

Expanding the control group to include all eight matched services yielded inconsistent results for both outcomes. The estimated effects for outcome 1 changes in direction to become negative, whereas the size of the estimated effect for outcome 2 is closer to zero. Neither result reached statistical significance, and the results suggest the estimates effects are sensitive to the inclusion of additional controls.

### Summary

```{r}
#| label: psm - sensitivity summary
#| cache: false
#| eval: false

# display a summary table of results
did_overall |> display_manual_did_sensitvity_results_as_gt()
```

**There were no statistically significant findings across any specification.**

The direction of estimates varies depending on model choice (positive in baseline, negative in alternatives), suggesting sensitivity to specification.

Confidence intervals are wide, especially when anomalous months are included, indicating limited precision.

## Coarsened exact matching - `r params$zoo_intervention_month - 1/12`

Coarsened Exact Matching (CEM) offers an alternative approach to propensity score matching. First, each variable is grouped into broader categories (e.g., 0-19%, 20-39%, 40-59%, etc.). Then Talking Therapy services are matched **exactly** on these coarsened bins.

The key advantage is that balance on the matching variables is guaranteed within each bin. The researcher controls the trade-off by choosing the width of the categories:

-   Narrower bins - tighter similarity between matched services but fewer matches

-   Wider bins - more matches but less precise similarity

The same matching variables selected from the multicollinearity optimisation process will be used. We use five cutpoints to divide each matching variable into six separate bins.

```{r}
#| label: coarsened exact matching
#| fig-height: 8
#| message: FALSE
#| cache: false
#| eval: false

# experiment with removing matching vars
matching_vars_v2 <- setdiff(
  matching_vars,
  c(
    "m13_rate",
    "m14_rate",
    "m15_rate",
    "m16_rate",
    "m12_rate",
    "m8_rate",
    "m6_rate",
    "m5_rate",
    "m3_rate",
    "m7_rate",
    "o1_denom",
    "m4_rate",
    "m9_rate"
  )
)

# set the matching formula for this
formula_matching <-
  formula(
    paste0(
      "flag_intervention ~ ",
      paste0(matching_vars_v2, collapse = " + ")
    )
  )

# do the matching
obj_matches <-
  MatchIt::matchit(
    data = df_prep,
    formula = formula_matching, # using the same formula as determined by VIF analysis
    method = "cem",
    cutpoints = 4
  )

# review the covariate balance
cobalt::love.plot(
  x = obj_matches,
  abs = TRUE,
  thresholds = 0.2,
  var.names = ls_labels_wrap,
  stars = "raw",
  var.order = "unadjusted"
) +
  ggplot2::theme_minimal(base_size = 16) +
  ggplot2::scale_colour_manual(
    values = c("Unadjusted" = "#ec6555", Adjusted = "#5881c1")
  )
```

Removed M9 (Proportion of discharges where there was a step-up in therapy) because only two matches were found using 4 cutpoints. M9 had close to the 0.2 SMD before matching so it was felt this change was justified by the additional two matches found by removing it.

These results show the matched services as close, but not perfect, matches for `r params$intervention_long_name`.

After matching, most variables show improved similarity (the blue points are nearer to 0 than the red points) and one variable is within the 0.2 SMD threshold.

The matched services found using using four cut-points are:

```{r}
#| label: coarsened exact matches
#| fig-height: 8
#| cache: false
#| eval: false

# extract the matched services to a var
matches <- MatchIt::match_data(obj_matches)

# show in a table
matches |>
  dplyr::select(name, ods_code) |>
  dplyr::mutate(
    ods_code = ods_code |>
      as.factor() |>
      forcats::fct_relevel(params$ods_intervention)
  ) |>
  dplyr::arrange(ods_code) |>
  gt::gt() |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::data_color(
    columns = gt::everything(),
    rows = ods_code == params$ods_intervention,
    palette = "#f9bf07"
  ) |>
  gt::cols_label(
    name = "Talking Therapies organisation",
    ods_code = "ODS code"
  )

# plots comparing each matched service
plot_list <-
  purrr::map(
    .x = stringr::str_subset(
      string = matches$ods_code,
      pattern = params$ods_intervention,
      negate = TRUE
    ),
    .f = \(.x) {
      p <-
        compare_matches_preintervention(
          df = df,
          selected_ods = c(params$ods_intervention, .x),
          period_preintervention = zoo::as.yearmon(c(
            "Jan 2022",
            as.character(params$zoo_intervention_month - 1 / 12)
          )),
          trendline = TRUE
        )
      return(p)
    }
  )
```

### Parallel trends assumption

We now assess the parallel trends for `r params$intervention_long_name` (shown in orange) and each of the 20 matched Talking Therapy services (shown in grey). Trendlines are overlaid on each plot to make it easier to judge whether the series move together.

#### Warrington Psychological Service (NO202)

**Outcome 1:** ❌ The trends are not parallel - they interected around September 2022

**Outcome 2:** ❌ The trends are not parallel - they are divergent

```{r}
#| label: cem - warringon
#| fig-height: 8
#| cache: false
#| eval: false

plot_list[[1]]
```

#### NHS Northumberland Talking Therapies (NO204)

**Outcome 1:** ❌ The trends are not parallel - they are divergent

**Outcome 2:** ✔️ The trends are almost parallel

```{r}
#| label: cem - northumberland
#| fig-height: 8
#| cache: false
#| eval: false

plot_list[[2]]
```

#### Vita Health Group: Vitaminds Bristol, North Somerset & South Gloucestershire (NWC07)

**Outcome 1:** ✔️ The trends are parallel

**Outcome 2:** ✔️ The trends are parallel

```{r}
#| label: cem - vita health group
#| fig-height: 8
#| cache: false
#| eval: false

plot_list[[3]]
```

#### Talking Matter Sefton (W5N3Z)

**Outcome 1:** ❌ The trends are not parallel - they are convergent

**Outcome 2:** ✔️ The trends are more or less parallel

```{r}
#| label: cem - talking matters
#| fig-height: 8
#| cache: false
#| eval: false

plot_list[[4]]
```

### Matching summary

A total of 4 Talking Therapy services were matched with `r params$intervention_long_name` using *Coarsened Exact Matching (CEM)*. Of these, 1 exhibited pre-intervention trends that closely align with those of `r params$intervention_long_name` for both outcome measures.

```{r}
#| label: cem - matches with parallel trends
#| cache: false
#| eval: false

# list out the matches with parallel pre-intervention trends
matches_parallel_ods <- c("NWC07")

# add these controls to a list for use in the synthetic control section
controls <- c(
  controls,
  list(
    "cem_all" = matches$ods_code,
    "cem_parallel" = matches_parallel_ods
  )
)

# display these in a table
matches |>
  dplyr::filter(ods_code %in% matches_parallel_ods) |>
  dplyr::select(name, ods_code) |>
  dplyr::arrange(ods_code) |>
  gt::gt() |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::cols_label(
    name = "Talking Therapies organisation",
    ods_code = "ODS code"
  )
```

### Analysis

Now we have matched `r params$intervention_long_name` with another Talking Therapy service and assessed their likelihood of meeting the parallel trends assumption based on their pre-intervention data, let us review how the full time series looks.

#### Outcome 1

```{r}
#| label: cem - spaghetti plot1 outcome 1
#| fig-height: 6
#| cache: false
#| eval: false

# get a df with the details for our matched services
df_analysis <-
  df |>
  dplyr::filter(
    # limit to activity in the timeframe
    dplyr::between(
      calc_month,
      zoo::as.yearmon("Jan 2022"),
      zoo::as.yearmon("Sep 2025")
    ),
    # limit to our matched services with parallel trends
    ods_code %in% c(params$ods_intervention, matches_parallel_ods)
  ) |>
  # simplify the data
  dplyr::select(ods_code, calc_month, o1_rate, o2_rate) |>
  # create treatment and post indicators
  dplyr::mutate(
    treated = dplyr::if_else(ods_code == params$ods_intervention, 1L, 0L),
    post = dplyr::if_else(calc_month >= params$zoo_intervention_month, 1L, 0L),
    line_colour = dplyr::if_else(
      ods_code == params$ods_intervention,
      "#f9bf07",
      adjustcolor("#9d928a", alpha.f = 0.5)
    )
  )

# show a spaghetti plot for these services
p <-
  plot_spaghetti_plot(
    df = df_analysis,
    str_outcome = "o1_rate",
    ods_intervention = params$ods_intervention,
    str_title = "Outcome 1: discharges with 5+ treatment contacts",
    str_subtitle = "",
    zoo_intervention = params$zoo_intervention_month,
    bool_intervention = TRUE,
    .yearmon_scale_to = zoo::as.yearmon("Nov 2025")
  )
p
# p |> plotly::ggplotly()
```

**What this chart shows:**

-   Performance against outcome 1 is shown on the y-axis and time is along the x-axis.

-   There are three time series displayed, one for `r params$intervention_long_name`, shown in orange, and one for each of the two of our matched services, shown in grey.

-   Each series is identified by its ODS code at the end of the data in May 2025.

-   The dotted line represents the start of `r params$intervention_long_name`'s interventions in `r params$zoo_intervention_month`.

```{r}
#| label: cem - anomalous months outcome 1
#| cache: false
#| eval: false

# return any anomalous observations
identify_anomalies(
  df = df_analysis,
  outcome = "o1_rate",
  iqr_alpha = 0.05,
  anomaly_threshold = 0.2
) |>
  identify_anomalies_gt()
```

**Key observations:**

Our intervention service, RW1, exhibited abnormal dips:

-   September 2024 - 0%

-   September 2025 - 0%

These brief, but steep declines would bias the post-implementation estimates downward for the intervention service. To avoid this bias, the low-performance points should be excluded from the dataset.

#### Outcome 2

```{r}
#| label: cem - spaghetti plot1 outcome 2
#| fig-height: 6
#| cache: false
#| eval: false

# show a spaghetti plot for outcome 2
p <-
  plot_spaghetti_plot(
    df = df_analysis,
    str_outcome = "o2_rate",
    ods_intervention = params$ods_intervention,
    str_title = "Outcome 2: discharges achieving reliable recovery",
    str_subtitle = "",
    zoo_intervention = params$zoo_intervention_month,
    bool_intervention = TRUE,
    .yearmon_scale_to = zoo::as.yearmon("Oct 2025")
  )
p
# p |> plotly::ggplotly()
```

```{r}
#| label: cem - anomalous months outcome 2
#| cache: false
#| eval: false

# return any anomalous observations
identify_anomalies(
  df = df_analysis,
  outcome = "o2_rate",
  iqr_alpha = 0.05,
  anomaly_threshold = 0.2
) |>
  identify_anomalies_gt()
```

**Key observations:**

Our intervention service, RW1, exhibited an abnormal dip to 0% in September 2025.

##### Both outcome excluding outliers

Here are the two outcomes excluding the anomalous months:

```{r}
#| label: cem - spaghetti plot2 outcomes 1 and 2
#| fig-height: 6
#| cache: false
#| eval: false

# get a df excluding the problematic months
df_analysis2 <-
  df_analysis |>
  dplyr::filter(
    !(ods_code == "RW1" &
      calc_month %in% zoo::as.yearmon(c("Sep 2024", "Sep 2025")))
  )

# show as a spaghetti plot
plot_spaghetti_plot(
  df = df_analysis2,
  str_outcome = "o1_rate",
  ods_intervention = params$ods_intervention,
  str_title = "Outcome 1: discharges with 5+ treatment contacts",
  str_subtitle = "These time series now seem less likely to bias the analysis",
  zoo_intervention = params$zoo_intervention_month,
  bool_intervention = TRUE,
  .yearmon_scale_to = zoo::as.yearmon("Oct 2025")
)

# show as a spaghette plot
plot_spaghetti_plot(
  df = df_analysis2,
  str_outcome = "o2_rate",
  ods_intervention = params$ods_intervention,
  str_title = "Outcome 2: discharges with reliable recovery",
  str_subtitle = "These time series now seem less likely to bias the analysis",
  zoo_intervention = params$zoo_intervention_month,
  bool_intervention = TRUE,
  .yearmon_scale_to = zoo::as.yearmon("Oct 2025")
)

```

#### Difference-in-Differences (DiD)

The results of the DiD analyses are presented below:

```{r}
#| label: cem - did table
#| cache: false
#| eval: false

# conduct did analysis on the two matched services
did <-
  get_manual_did_estimation(
    df = df_analysis2,
    ods_intervention = params$ods_intervention,
    zoo_intervention = params$zoo_intervention_month
  )

# add to a combined summary (for sensitivity analysis)
did_overall <-
  did |>
  dplyr::mutate(specification = "Main model (baseline)")

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "CEM main model",
      outcome = did$outcome,
      estimate = did$estimate,
      se = did$std.error
    )
  )

# display
did |> display_manual_did_results_as_gt()
```

This table summarises the Difference-in-Differences analysis for `r params$intervention_long_name`'s interventions using the 7 controls identified using the Coarsened Exact Matching process and which exhibited parallel trends.

For outcome 1, `r params$intervention_long_name`'s observed rate is about **2.58 lower** than what the matched controls would predict, with a 95% confidence interval (-4.77% to -0.39%) that is a **statistically significant difference**.

For outcome 2, `r params$intervention_long_name`'s rate is about **0.64% lower** than expected, with a 95% confidence interval (-2.54% to 1.26%) that includes zero, indicating **no statistically reliable difference**.

::: callout-tip
## Interpretation

```{r}
#| label: interpretation help cem
#| cache: false
#| eval: false

# work out the total discharges in 12 months preceeding
total_discharges <-
  df |>
  dplyr::filter(
    ods_code == params$ods_intervention,
    dplyr::between(
      calc_month,
      zoo::as.yearmon("Jun 2024"),
      zoo::as.yearmon("May 2025")
    )
  ) |>
  dplyr::summarise(
    total = sum(o1_denom_discharges_count, na.rm = TRUE)
  ) |>
  dplyr::pull(total)

# work out the expected number of people to benefit from the uplift
people_benefit_o1 <- floor(total_discharges * (did$estimate[1]))
people_benefit_o2 <- floor(total_discharges * (did$estimate[2]))
```

These findings indicate `r params$intervention_long_name`'s post-intervention performance exceeds the counterfactual for outcomes 2, but the confidence interval is too wide to support a definitive claim of effectiveness.

-   Assuming the <r scales::percent(did$estimate[1], accuracy = 0.01)> change is real, it translates to <r dplyr::if_else(did$estimate[1] > 0, "an additional", "a reduction of")> <r people_benefit_o1> people receiving 5+ treatment contacts as part of their referral.

-   Assuming the <r scales::percent(did$estimate[2], accuracy = 0.01)> change is real, it translates to <r dplyr::if_else(did$estimate[2] > 0, "an additional", "a reduction of")> <r people_benefit_o2> people achieving reliable recovery.

NB, these estimates are based based on `r params$intervention_long_name`'s annual discharge volume of <r scales::comma(total_discharges)> from June 2024 to May 2025.
:::

### Sensitivity analysis

Two important decisions were made that led to the above analytical findings:

1.  **Parallel trend selection** - We inspected the 4 matched controls series visually and excluded 3 that did not follow `r params$intervention_long_name`'s pre-intervention trend.

2.  **Anomalous month removal** - For the remaining matched services we omitted data for a service with extreme values, which yielded more stable performance across outcomes.

Below we reassess the findings after relaxing each of these decisions to determine whether the original conclusions hold or are sensitive to this analytical choice.

#### Keeping anomalous months

What impact does keeping the extreme values in the time series have?

```{r}
#| label: cem - sensitivity - anomalous months
#| cache: false
#| eval: false

# conduct did analysis using the original data before anomalous months excluded
did <-
  get_manual_did_estimation(
    df = df_analysis,
    ods_intervention = params$ods_intervention,
    zoo_intervention = params$zoo_intervention_month
  )

# add to a combined summary (for sensitivity analysis)
did_overall <-
  dplyr::bind_rows(
    did_overall,
    did |>
      dplyr::mutate(specification = "Alternative 1 - keep anomalous months")
  )

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "CEM alternative 1 - keep anomalous months",
      outcome = did$outcome,
      estimate = did$estimate,
      se = did$std.error
    )
  )

# show as a table
did |> display_manual_did_results_as_gt()
```

This sensitivity analysis confirms the robustness of the main findings:

-   Outcome 1 remains negatively affected by the intervention however, the confidence interval is wider and now includes zero, meaning the result is no longer statistically significant

-   Outcome 2 effect size becomes even more negative though the wide confidence interval includes zero, meaning the result is not statistically significant

#### Using all CEM controls

What impact does using all 14 matched control services have on the findings?

```{r}
#| label: cem - sensitivity - all controls
#| cache: false
#| eval: false

# get a df with the details for our matched services
df_analysis3 <-
  df |>
  dplyr::filter(
    # limit to activity to our timeperiod
    dplyr::between(
      calc_month,
      zoo::as.yearmon("Jan 2022"),
      zoo::as.yearmon("Sep 2025")
    ),
    # limit to our matched services
    ods_code %in% c(params$ods_intervention, controls$cem_all)
  ) |>
  # simplify the data
  dplyr::select(ods_code, calc_month, o1_rate, o2_rate) |>
  # create treatment and post indicators
  dplyr::mutate(
    treated = dplyr::if_else(ods_code == params$ods_intervention, 1L, 0L),
    post = dplyr::if_else(calc_month >= params$zoo_intervention_month, 1L, 0L),
    line_colour = dplyr::if_else(
      ods_code == params$ods_intervention,
      "#f9bf07",
      adjustcolor("#9d928a", alpha.f = 0.5)
    )
  ) |>
  # remove the anomalous months (to ensure we focus on the change just from using all CEM controls)
  dplyr::filter(
    !(ods_code == "RW1" &
      calc_month %in% zoo::as.yearmon(c("Sep 2024", "Sep 2025")))
  )

# conduct did analysis on the two matched services
did <-
  get_manual_did_estimation(
    df = df_analysis3,
    ods_intervention = params$ods_intervention,
    zoo_intervention = params$zoo_intervention_month
  )

# add to a combined summary (for sensitivity analysis)
did_overall <-
  dplyr::bind_rows(
    did_overall,
    did |>
      dplyr::mutate(specification = "Alternative 2 - use all CEM controls")
  )

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "CEM alternative 2 - use all CEM controls",
      outcome = did$outcome,
      estimate = did$estimate,
      se = did$std.error
    )
  )


# display as a table
did |> display_manual_did_results_as_gt()
```

This sensitivity analysis confirms the robustness of the main findings:

-   Outcome 1 remains negatively and significantly affected by the intervention with a wider confidence interval which indicates these findings are statistically significant

-   Outcome 2 effect size moves slightly closer to zero with a similar sized confidence interval that includes zero, meaning the results are statistically indistinguishable from no effect

#### Summary

```{r}
#| label: cem - sensitivity summary
#| cache: false
#| eval: false

# display a summary table of results
did_overall |>
  # simplify
  dplyr::select(
    specification,
    outcome,
    did = estimate,
    p.value,
    conf.low,
    conf.high
  ) |>
  # group by the sensitivity test
  dplyr::group_by(specification) |>
  gt::gt(row_group_as_column = TRUE) |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::fmt_percent(columns = c(did, conf.low, conf.high), decimals = 2) |>
  gt::cols_merge(columns = c(conf.low, conf.high), pattern = "{1} to {2}") |>
  gt::tab_style(
    style = list(gt::cell_text(weight = "bold")),
    locations = gt::cells_body(
      columns = c(did, conf.low),
      rows = p.value <= 0.05
    )
  ) |>
  gt::cols_hide(columns = p.value) |>
  gt::cols_label(
    outcome = "Outcome",
    did = "DiD estimate",
    conf.low = "95% confidence interval"
  ) |>
  gt::tab_source_note(gt::md(
    "Statistically significant findings are shown in **bold**"
  ))
```

These sensitivity tests show:

-   **Outcome 1** There was a consistent evidence of a negative effect across specifications with significance in both the baseline and the all-controls model.

-   **Outcome 2** There was no significant effect in any specification.

These checks suggest the effect on Outcome 1 is robust, though its magnitude varies depending on model choice.

## Synthetic Difference-in-Differences (DiD)

The preceeding section highlights the challenges of finding genuine control services that closely match `r params$intervention_long_name`'s profile and satisfy the parallel-trends assumption. Because the estimated treatment effect proved sensitive to several analytical choices, we turn to alternative method: synthetic controls.

Synthetic Difference-in-Differences (Synthetic DiD) blends two ideas: the traditional difference-in-differences method and the synthetic control technique.

-   First it builds a "synthetic" version of the control group by assigning weights to untreated units so that, before the intervention, this synthetic group looks just like the treated unit.

-   Then it compares the outcomes after the intervention between the treated unit and its synthetic counterpart. By creating a better-matched control, Synthetic DiD helps produce more reliable estimates of a treatment's effect, especially when the parallel-trend assumption is weak.

The [{synthdid}](https://synth-inference.github.io/synthdid/) package was used to conduct these Synthetic DiD analyses. This uses the method described by [@arkhangelsky2019] to combine the strengths of synthetic-control weighting with the traditional DiD framework. According to the paper this technique delivers unbiased treatment-effect estimates, even when the parallel-trends assumption is violated.

In this approach we will build a 'donor pool' of all Talking Therapy services to create a synthetic counterfactual that estimates how `r params$intervention_long_name` would have performed without its interventions.

-   As with the earlier section, we first exclude any service that has its own adherence-improvement intervention

-   The {synthdid} package requires a balanced panel; every service in the donor pool must have data for every month from July 2022 through May 2025.

-   Consequently, any service with even a single missing month is dropped from the donor pool.

NB, **Months with anomalous data for our intervention service have been removed from the dataset to avoid bias in the post-intervention period.**

### Outcome 1

```{r}
#| label: synthdid - outcome 1
#| fig-height: 8
#| warning: false
#| cache: false
#| eval: false

# set up for the did analysis
set.seed(12345)
.yearmon_period = zoo::as.yearmon(c("Jan 2022", "Aug 2025"))
.yearmon_intervention = params$zoo_intervention_month

# NOVEL step:
# {synthdid} requires a balanced panel - meaning data for each month included in the analysis.
# Our intervention group has missing data for March 2025 (unknown reason why), which is causing it to
# be rejected from the data preparation phase.
# The solution is to replace the missing data point with a value that is consistent with its time series.
# The {zoo} package has a useful function `na.approx()` that fills missing values by interpolating between
# the nearest non-missing points.
df <- interpolate_missing_month_outcomes_for_intervention_service(
  df = df |>
    # exclude the anomalous months in our intervention service
    dplyr::filter(
      !(ods_code %in%
        params$ods_intervention &
        calc_month %in% zoo::as.yearmon(c("Sep 2024", "Sep 2025")))
    ),
  .ods_intervention = params$ods_intervention
)

# get a dataset that is ready for synthetic DiD
df_synth <-
  prepare_df_for_synthdid(
    df = df,
    outcome = "o1_rate",
    yearmon_period = .yearmon_period,
    yearmon_intervention = .yearmon_intervention,
    ods_treated = params$ods_intervention,
    df_intervention_services = df_intervention_services
  )

# get the did estimate, confidence intervals and plot
did <-
  delegate_synthdid_analysis(
    df_synth = df_synth,
    .yearmon_intervention = .yearmon_intervention,
    .yearmon_period = .yearmon_period,
    .yearmon_scale_to = zoo::as.yearmon("Feb 2026"),
    .ods_treated = params$ods_intervention,
    str_treated = params$intervention_short_name,
    summary_spec = "Main model (baseline)",
    summary_outcome = "Outcome 1",
    str_outcome = "o1_rate",
    labs_title = "Outcome 1: discharges with 5+ treatment contacts"
  )

# add these findings to a combined summary (for sensitivity analysis)
did_overall <-
  did$did_summary

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "Synthdid main model (all controls)",
      outcome = "Outcome 1",
      estimate = as.numeric(did$did_estimate),
      se = did$did_se
    )
  )

# display the plot
did$did_plot
```

**What the chart displays**

+------------------------------+-------------------------------------------------------------------------------+-------------------------------------------+
| Element                      | Meaning                                                                       | Visual clue                               |
+==============================+===============================================================================+===========================================+
| Axes                         | Outcome performance (y-axis) vs time (x-axis)                                 | Standard Cartesian axes                   |
+------------------------------+-------------------------------------------------------------------------------+-------------------------------------------+
| Project's actual performance | Measured values for the project                                               | Orange solid line                         |
+------------------------------+-------------------------------------------------------------------------------+-------------------------------------------+
| Synthetic control            | Counterfactual series built from weighted pre-intervention data               | Blue solid line                           |
+------------------------------+-------------------------------------------------------------------------------+-------------------------------------------+
| Intervention start           | Point at which the project's interventions began                              | Vertical grey line                        |
+------------------------------+-------------------------------------------------------------------------------+-------------------------------------------+
| Pre-intervention weights     | Relative contribution of each pre-intervention month to the synthetic control | Pink shapes in the lower-left corner      |
+------------------------------+-------------------------------------------------------------------------------+-------------------------------------------+
| Parallelogram overlay        | Visual comparison of the two trajectories                                     | Blue-topped edge = synthetic control path |
|                              |                                                                               |                                           |
|                              |                                                                               | Dotted bottom edge = counterfactual path  |
|                              |                                                                               |                                           |
|                              |                                                                               | Orange line = project's actual trajectory |
+------------------------------+-------------------------------------------------------------------------------+-------------------------------------------+

: Chart key

**How to read the parallelogram**

-   Top edge (blue) - trajectory of the synthetic control from the pre- to post-intervention period

-   Bottom edge (dotted) - what `r params$intervention_long_name`'s trend would have looked like without any interventions (the counterfactual)

-   Orange line - `r params$intervention_long_name`'s observed post-intervention trend.

`r params$intervention_long_name`'s orange line does not rise in line with the dotted counterfactual, indicating a negative impact of the interventions. The estimated change is 2.2% below the expected value. The 95% confidence interval spans -11.6% to + 7.3%, meaning the true effect could be negative or positive. Consequently, the result is **not statistically significant**.

#### Contribution plot

```{r}
#| label: synthdid - outcome 1 - contribution plot
#| fig-height: 5
#| warning: false
#| cache: false
#| eval: false

set.seed(12345)

synthdid::synthdid_units_plot(
  estimates = did$did_estimate,
  se.method = "placebo"
) +
  ggplot2::theme(axis.text.x = ggplot2::element_text(size = 5))
```

This plot shows:

-   The synthetic estimate as the black horizontal line

-   Each control Talking Therapy service as a point, where servicees that contribute more weight to the synthetic model shown in larger size

-   The grey horizontal lines represent the end points of a 95% confidence interval

A total of <r length(summary(did$did_estimate)$controls)> Talking Therapy services were used in the construction of this synthetic control.

### Outcome 2

```{r}
#| label: synthdid - outcome 2
#| fig-height: 8
#| warning: false
#| cache: false
#| eval: false

# set seed for reproducibility
set.seed(12345)

df_synth <-
  prepare_df_for_synthdid(
    df = df,
    outcome = "o2_rate",
    yearmon_period = .yearmon_period,
    yearmon_intervention = .yearmon_intervention,
    ods_treated = params$ods_intervention,
    df_intervention_services = df_intervention_services
  )

# get the did estimate, confidence intervals and plot
did <-
  delegate_synthdid_analysis(
    df_synth = df_synth,
    .yearmon_intervention = .yearmon_intervention,
    .yearmon_period = .yearmon_period,
    .yearmon_scale_to = zoo::as.yearmon("Feb 2026"),
    .ods_treated = params$ods_intervention,
    str_treated = params$intervention_short_name,
    summary_spec = "Main model (baseline)",
    summary_outcome = "Outcome 2",
    str_outcome = "o2_rate",
    labs_title = "Outcome 2: discharges achieving reliable recovery"
  )

# add these findings to a combined summary (for sensitivity analysis)
did_overall <-
  dplyr::bind_rows(
    did_overall,
    did$did_summary
  )

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "Synthdid main model (all controls)",
      outcome = "Outcome 2",
      estimate = as.numeric(did$did_estimate),
      se = did$did_se
    )
  )

# display the plot
did$did_plot
```

**How to read the parallelogram**

-   Top edge (dotted) - what `r params$intervention_long_name`'s trend would have looked like without any interventions (the counterfactual)

-   Bottom edge (blue) - trajectory of the synthetic control from the pre- to post-intervention period

-   Orange line - `r params$intervention_long_name`'s observed post-intervention trend.

`r params$intervention_long_name`'s orange line rises faster than the dotted counterfactual, indicating a higher-than-expected effect in the post-intervention period. The estimated difference is 0.5% above the expected value. The 95% confidence interval spans -5.9% to +6.9%, meaning the true effect could be negative or positive. Consequently, the result is **not statistically significant**.

#### Contribution plot

```{r}
#| label: synthdid - outcome 2 - contribution plot
#| fig-height: 5
#| warning: false
#| cache: false
#| eval: false

set.seed(12345)

synthdid::synthdid_units_plot(
  estimates = did$did_estimate,
  se.method = "placebo"
) +
  ggplot2::theme(axis.text.x = ggplot2::element_text(size = 5))
```

A total of <r length(summary(did$did_estimate)$controls)> Talking Therapy services were used in the construction of this synthetic control.

### Summary

```{r}
#| label: synthdid - summary table
#| cache: false
#| eval: false

did_overall |>
  display_did_summary_in_gt(sensitivity_summary = FALSE)
```

::: callout-tip
## Interpretation

```{r}
#| label: interpretation help synthdid
#| cache: false
#| eval: false

# work out the total discharges in 12 months preceeding
total_discharges <-
  df |>
  dplyr::filter(
    ods_code == params$ods_intervention,
    dplyr::between(
      calc_month,
      zoo::as.yearmon("Jun 2024"),
      zoo::as.yearmon("May 2025")
    )
  ) |>
  dplyr::summarise(
    total = sum(o1_denom_discharges_count, na.rm = TRUE)
  ) |>
  dplyr::pull(total)

temp_est <- did_overall$estimate |> utils::tail(n = 2)

# work out the expected number of people to benefit from the uplift
people_benefit_o1 <- floor(total_discharges * temp_est[1])
people_benefit_o2 <- floor(total_discharges * temp_est[2])
```

-   Assuming the <r scales::percent(temp_est[1], accuracy = 0.01)> change is real, it translates to <r dplyr::if_else(temp_est[1] > 0, "an additional", "a reduction of")> <r people_benefit_o1> people receiving 5+ treatment contacts as part of their referral.

-   Assuming the <r scales::percent(temp_est[2], accuracy = 0.01)> change is real, it translates to <r dplyr::if_else(temp_est[2] > 0, "an additional", "a reduction of")> <r people_benefit_o2> people achieving reliable recovery.

NB, these estimates are based based on `r params$intervention_long_name`'s annual discharge volume of <r scales::comma(total_discharges)> from June 2024 to May 2025.
:::

### Sensitivity analysis

In the previous analysis we supplied {synthdid} with the outcomes for *all* Talking Therapy services that were not involved in any known adherence-improving intervention. This full set served as the donor pool for constructing a counterfactual that best matches `r params$intervention_long_name`'s pre-intervention outcome trends.

We adopted this approach because synthetic-control methods require a reasonably large donor pool to generate a reliable weighted counterfactual. However, the propensity score matching and coarsened exact matching sections showed that the donor pool varies across our matching variables.

In this section we examine how restricting the donor pool influences the DiD estimates and assess whether our original conclusions remain robust or become sensitive to these restrictions.

#### Using matches from PSM

What impact does using the matches returned from the propensity score matching (PSM) section have?

```{r}
#| label: synthdid - sensitivity PSM - outcome 1
#| fig-height: 7
#| warning: false
#| cache: false
#| eval: false

set.seed(12345)

# get a did estimate
df_synth <-
  prepare_df_for_synthdid(
    df = df,
    outcome = "o1_rate",
    yearmon_period = .yearmon_period,
    yearmon_intervention = .yearmon_intervention,
    ods_treated = params$ods_intervention,
    ods_controls = controls$psm_all,
    df_intervention_services = df_intervention_services
  )

# get the did estimate, confidence intervals and plot
did <-
  delegate_synthdid_analysis(
    df_synth = df_synth,
    .yearmon_intervention = .yearmon_intervention,
    .yearmon_period = .yearmon_period,
    .yearmon_scale_to = zoo::as.yearmon("Feb 2026"),
    .ods_treated = params$ods_intervention,
    str_treated = params$intervention_short_name,
    summary_spec = "Alternative 1 - using all PSM matches",
    summary_outcome = "Outcome 1",
    str_outcome = "o1_rate",
    labs_title = "Outcome 1: discharges with 5+ treatment contacts"
  )

# add these findings to a combined summary (for sensitivity analysis)
did_overall <-
  dplyr::bind_rows(
    did_overall,
    did$did_summary
  )

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "Synthdid alternative 1 (PSM controls)",
      outcome = "Outcome 1",
      estimate = as.numeric(did$did_estimate),
      se = did$did_se
    )
  )

# display the plot
did$did_plot
```

`r params$intervention_long_name` performed 4.1% below the synthetic control expectation, however, the 95% confidence interval (-14.8% to 6.6%) includes zero so we cannot make any definitive claim.

```{r}
#| label: synthdid - sensitivity PSM - outcome 2
#| fig-height: 7
#| warning: false
#| cache: false
#| eval: false

set.seed(12345)

# get a did estimate
df_synth <-
  prepare_df_for_synthdid(
    df = df,
    outcome = "o2_rate",
    yearmon_period = .yearmon_period,
    yearmon_intervention = .yearmon_intervention,
    ods_treated = params$ods_intervention,
    ods_controls = controls$psm_all,
    df_intervention_services = df_intervention_services
  )

# get the did estimate, confidence intervals and plot
did <-
  delegate_synthdid_analysis(
    df_synth = df_synth,
    .yearmon_intervention = .yearmon_intervention,
    .yearmon_period = .yearmon_period,
    .yearmon_scale_to = zoo::as.yearmon("Feb 2026"),
    .ods_treated = params$ods_intervention,
    str_treated = params$intervention_short_name,
    summary_spec = "Alternative 1 - using all PSM matches",
    summary_outcome = "Outcome 2",
    str_outcome = "o2_rate",
    labs_title = "Outcome 2: discharges achieving reliable recovery"
  )

# add these findings to a combined summary (for sensitivity analysis)
did_overall <-
  dplyr::bind_rows(
    did_overall,
    did$did_summary
  )

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "Synthdid alternative 1 (PSM controls)",
      outcome = "Outcome 2",
      estimate = as.numeric(did$did_estimate),
      se = did$did_se
    )
  )

# display the plot
did$did_plot
```

`r params$intervention_long_name` performed 0.7% above the synthetic control expectation, yet the 95% confidence interval (-15.2% to 16.7%) includes zero so we cannot make any definitive claim.

#### Using matches from CEM

What impact does using the matches returned from the coarsened exact matching (CEM) section have?

```{r}
#| label: synthdid - sensitivity CEM - outcome 1
#| fig-height: 7
#| warning: false
#| cache: false
#| eval: false

set.seed(12345)

# get a did estimate
df_synth <-
  prepare_df_for_synthdid(
    df = df,
    outcome = "o1_rate",
    yearmon_period = .yearmon_period,
    yearmon_intervention = .yearmon_intervention,
    ods_treated = params$ods_intervention,
    ods_controls = controls$cem_all,
    df_intervention_services = df_intervention_services
  )

# get the did estimate, confidence intervals and plot
did <-
  delegate_synthdid_analysis(
    df_synth = df_synth,
    .yearmon_intervention = .yearmon_intervention,
    .yearmon_period = .yearmon_period,
    .yearmon_scale_to = zoo::as.yearmon("Feb 2026"),
    .ods_treated = params$ods_intervention,
    str_treated = params$intervention_short_name,
    summary_spec = "Alternative 2 - using all CEM matches",
    summary_outcome = "Outcome 1",
    str_outcome = "o1_rate",
    labs_title = "Outcome 1: discharges with 5+ treatment contacts"
  )

# add these findings to a combined summary (for sensitivity analysis)
did_overall <-
  dplyr::bind_rows(
    did_overall,
    did$did_summary
  )

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "Synthdid alternative 2 (CEM controls)",
      outcome = "Outcome 1",
      estimate = as.numeric(did$did_estimate),
      se = did$did_se
    )
  )

# display the plot
did$did_plot
```

`r params$intervention_long_name`'s observed outcome was **1.8% below** the synthetic control expectation, and the 95% confidence interval (-1.9% to -1.6%) does not include zero which makes this **statistically significant**.

```{r}
#| label: synthdid - sensitivity CEM - outcome 2
#| fig-height: 7
#| warning: false
#| cache: false
#| eval: false

set.seed(12345)

df_synth <-
  prepare_df_for_synthdid(
    df = df,
    outcome = "o2_rate",
    yearmon_period = .yearmon_period,
    yearmon_intervention = .yearmon_intervention,
    ods_treated = params$ods_intervention,
    ods_controls = controls$cem_all,
    df_intervention_services = df_intervention_services
  )

# get the did estimate, confidence intervals and plot
did <-
  delegate_synthdid_analysis(
    df_synth = df_synth,
    .yearmon_intervention = .yearmon_intervention,
    .yearmon_period = .yearmon_period,
    .yearmon_scale_to = zoo::as.yearmon("Feb 2026"),
    .ods_treated = params$ods_intervention,
    str_treated = params$intervention_short_name,
    summary_spec = "Alternative 2 - using all CEM matches",
    summary_outcome = "Outcome 2",
    str_outcome = "o2_rate",
    labs_title = "Outcome 2: discharges achieving reliable recovery"
  )

# add these findings to a combined summary (for sensitivity analysis)
did_overall <-
  dplyr::bind_rows(
    did_overall,
    did$did_summary
  )

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "Synthdid alternative 2 (CEM controls)",
      outcome = "Outcome 2",
      estimate = as.numeric(did$did_estimate),
      se = did$did_se
    )
  )

# display the plot
did$did_plot
```

`r params$intervention_long_name`'s observed outcome was **0.2% lower** than the synthetic control expectation, and the 95% confidence interval (-0.5% to \<0%) does not include zero, so the result is **statistically significant**.

#### Summary

```{r}
#| label: synthdid - sensitivity - summary table
#| cache: false
#| eval: false

did_overall |>
  display_did_summary_in_gt(sensitivity_summary = TRUE)

# save a copy of the summary table for future meta-analyses
saveRDS(
  object = did_meta,
  file = here::here("data", "project", "did_estimates", "hampshire.Rds")
)
```

Across all specifications, the estimates were small in magnitude and not statistically significant, with confidence intervals consistently spanning zero.

Overall, the sensitivity analyses indicate the findings are robust to different matching approaches, but the lack of statistical significance suggest that any observed differences should be interpreted cautiously.

## Supplementary analysis

```{r}
#| label: supp - gather data
#| cache: false
supp1 <-
  delegate_supp_outcome_analysis(
    supp = "mutual_discharge",
    ods_intervention = params$ods_intervention,
    str_intervention = params$intervention_short_name,
    ods_controls = c("RAT"),
    zoo_intervention = params$zoo_intervention_month,
    zoo_period = zoo::as.yearmon(c("Jan 2022", "Sep 2025"))
  )

supp2 <-
  delegate_supp_outcome_analysis(
    supp = "reliable_recovery",
    ods_intervention = params$ods_intervention,
    str_intervention = params$intervention_short_name,
    ods_controls = c("RAT"),
    zoo_intervention = params$zoo_intervention_month,
    zoo_period = zoo::as.yearmon(c("Jan 2022", "Sep 2025"))
  )
```

To contextualise the results for out two primary outcomes, we conducted two supplementary analyses:

1.  **Mutual discharge agreement** - the proportion of discharges jointly agreed up by patient and therapist

2.  **Reliable recovery** - the proportion of discharges that met criteria for reliable recovery

For each measure we compared:

-   **Pre- vs post-intervention** periods (before and after `r params$intervention_long_name`'s interventions)

-   **Treatment intensity** groups: participants who received **\>= 5 contacts** versus those with **\< 5 contacts**

### Discharge by mutual agreement

On discharge from a Talking Therapy service, every client record must include a coded reason in the `EndCode` field. According to the [IAPT Techical Output Specification](https://digital.nhs.uk/data-and-information/information-standards/governance/latest-activity/standards-and-collections/dapb-1520-improving-access-to-psychological-therapies-data-set), there are 14 predefined categories for coding discharge reasons:

```{r}
#| label: supp - discharge codes
#| cache: false

readxl::read_xlsx(
  path = here::here("data", "reference", "iapt_tos_endcode.xlsx")
) |>
  dplyr::group_by(group) |>
  gt::gt(row_group_as_column = TRUE) |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  # label the columns
  gt::cols_label(
    code = "Code",
    description = "Definition"
  ) |>
  # highlight the code we are interested in
  # bold any statistically significant results
  gt::tab_style(
    # style = gt::cell_text(weight = "bold"),
    style = gt::cell_fill(color = "#fcdf83"),
    locations = gt::cells_body(
      # columns = gt::vars(group, statistic, p.value, parameter),
      columns = gt::any_of(c("code", "description")),
      rows = code == 46
    )
  ) |>
  # headings and footnotes
  gt::tab_header(
    title = "Discharge from Improving Access to Psychological Therapies Service Reason"
  ) |>
  gt::tab_source_note(
    "Details of `EndCode` codes from version 2.1 of the IAPT Technical Output Specification"
  )
```

This section analyses the proportion of referrals coded as **Mutually Agreed Completion of Treatment** (code 46), indicating that both the patient and therapist concurred that the course of therapy had been successfully completed. Consistent with the primary analyses, we limit the sample to referrals with at least two treatment contacts to ensure inclusion of people who entered a course of care.

Where data permits, we also examine referrals coded as **ended before the therapist planned** (code 47) and referrals that **ended earlier than the patient wanted** (code 48). Due to the requirements of the chi-squared analysis - which requires a minimum of five events per cell - these categories may be combined with 'Other codes' if referrals volumes are insufficient.

The bar chart below displays `r params$intervention_long_name`'s data only. The chart highlights broadly similar profiles in discharge reason pre- and post-intervention for the 5+ treatment intensity group. The 2-4 treatment intensity group indicates a 2.5 percentage point increase in the use of 'Other codes', accompanied by small reductions in the use of the remaining discharge codes.

```{r}
#| label: supp - mutual - plot
#| cache: false
#| fig-height: 8
#| fig-width: 12

# display a bar chart
supp1$bar_plot

# display the chi-square test results
supp1$gt_chi2_results
```

The chi-squared test confirms that the observed changes are **statistically significant** for the 2-4 treatment contact intensity group.

These findings suggest that the interventions measurable effects on the proportion of referrals completed through mutual agreement between patient and therapist.

### Achieving reliable recovery

This section assesses the proportion of referrals that attained *reliable recovery* after completing therapy.

Reliable recovery requires two conditions: 1) the patient's symptoms fall below the clinical threshold ('recovery'), and 2) the magnitude of symptom reduction exceeds the reliable index, indicating a change that is statistically meaningful.

As with the previous analysis, the bar chart shows only `r params$intervention_long_name`'s data. In indicates minor fluctuations in the proportion of discharged referrals achieving reliable recovery during the post-intervention period compared with the pre-intervention period.

```{r}
#| label: supp - recovery - plot
#| cache: false
#| fig-height: 4
#| fig-width: 12

# display a bar chart
supp2$bar_plot

# display the chi-square test results
supp2$gt_chi2_results
```

The chi-squared test confirms that the observed changes are not statistically significant for both treatment intensity groups.

# Conclusions

We estimated the impact of `r params$intervention_long_name`'s interventions using two complimentary DiD approaches:

-   **Manual DiD** - `r params$intervention_long_name` was compared with services selected through a propensity score matched (PSM) and coarsened exact matched (CEM) procedures

-   **Synthetic control DiD** - `r params$intervention_long_name` was contrasted with a synthetic counterfactual build from all available donor services.

For the CEM and synthetic approaches we performed a series of sensitivity checks, for example, expanding the control pool and changing the intervention start date and using different matching methods.

## Outcome 1

Only the CEM baseline shows a statistically significant reduction in Outcome 1. PSM and synthdid estimates are small and not significant.

## Outcome 2

Across all three methods, Outcome 2 shows no statistically significant effect. Estimates are close to zero with confidence intervals crossing zero.

## Recommendations for future evaluation

To obtain a definitive assessment of `r params$intervention_long_name`'s interventions, a more rigorous experimental design is needed:

1.  Identify a cohort of comparable services using the matching variables described in this report

2.  Randomly assign half of the services to receive the full intervention package (FAQ pages, explanatory animations, assessment video, communication review, DNA rate tracking) and the other half to serve as controls

3.  Track outcomes prospectively over and adequate post-intervention horizon

4.  Analyse the data with a pre-registered DiD or mixed-effects model, complemented by placebo tests and robustness checks

Such a randomised controlled design would eliminate the donor-pool and specification sensitivities that currently limit inference, allowing a clear determination of whether `r params$intervention_long_name`'s interventions truly improve client preparation and engagement.

# Limitations

The limitations for this analysis include:

**Only one treated unit**

The causal estimate rests on a single time-series (`r params$intervention_long_name`). The result is that standard errors are large which translates to wide confidence intervals and a much larger treatment effect is required to reach statistical significance as a consequence.

**Possible hidden interventions in the donor pool**

We removed services with known interventions from the group of control services, but undisclosed changes may still be present.

Comparing `r params$intervention_long_name` to other services that are also improving attenuates the estimated effect, biasing the results toward zero.

**No single treatment date**

`r params$intervention_long_name`'s rollout was staggered across several components and spread over twelve months. As a result the "treated" period is diffuse, making it difficult to define a clean pre-/post-intervention split and to isolate the effect of any one component.

**Synthetic control sensitivity to outliers**

The CEM-derived donor pool contained services with extreme spikes. Outliers can dominate the weighted synthetic control, producing unstable counterfactuals and potentially misleading effect sizes.

Taken together, these limitations suggest that the estimated impacts should be interpreted with caution and highlight the need for a more rigorous, preferably experimental, design in future evaluations.