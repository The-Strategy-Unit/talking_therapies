---
title: "NHS Talking Therapies"
subtitle: "Evaluation of interventions to improve adherence to therapy in *NHS Kent and Medway Talking Therapies*"
author: "Craig Parylo"
date: today

title-block-banner: '#151412'
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: true
    embed-resources: true
    fig-format: png
    fig-width: 10
    fig-height: 3
    fig-dpi: 600
    default-image-extension: svg
    lightbox: true
    editor: visual
    favicon: "favicon.ico"
    include-in-header:
      text: |
        <link rel="icon" type="image/x-icon" href="favicon.ico">
brand: _brand.yml
css: styles.css
bibliography: references.bib
---

```{r}
#| label: setup
#| context: setup
#| cache: false

# set up params (NB, the ones in YAML don't work well when running interactively)
params <- list(
  "ods_intervention" = "E0W9O",
  "intervention_long_name" = "NHS Kent and Medway Talking Therapies",
  "intervention_short_name" = "NHS Kent and Medway TT",
  "download_from_teams" = FALSE,
  "zoo_intervention_month" = zoo::as.yearmon("Jan 2024")
)

# load in utility functions
source(here::here('scripts', 'utility_functions.R'))

# reference files ---

if (params$download_from_teams) {
  # get copies of files that don't need updating every time
  # get a list of projects that have implemented something to improve adherence
  download_file_from_channel(
    str_path = "2. Project delivery/Project plan/TT projects.xlsx",
    str_dest = here::here(
      'data',
      'project',
      'tt_intervention_projects_copy.xlsx'
    )
  )
  # get a summary of interventions conducted by each project
  download_file_from_channel(
    str_path = "2. Project delivery/Project data (quant)/project/tt_interventions_summary.xlsx",
    str_dest = here::here("data", "project", "tt_interventions_summary.xlsx")
  )
  # download the data files
  download_file_from_channel(
    str_path = "2. Project delivery/Project data (quant)/project/.secret/df_matching_contacts.Rds",
    str_dest = here::here("data", ".secret", "df_matching_contacts.Rds")
  )
  download_file_from_channel(
    str_path = "2. Project delivery/Project data (quant)/project/.secret/df_matching_referrals.Rds",
    str_dest = here::here("data", ".secret", "df_matching_referrals.Rds")
  )
  download_file_from_channel(
    str_path = "2. Project delivery/Project data (quant)/project/.secret/df_outcome_supp_discharge_reasons.Rds",
    str_dest = here::here(
      "data",
      ".secret",
      "df_outcome_supp_discharge_reasons.Rds"
    )
  )
  download_file_from_channel(
    str_path = "2. Project delivery/Project data (quant)/project/.secret/df_outcome_supp_reliable_recovery.Rds",
    str_dest = here::here(
      "data",
      ".secret",
      "df_outcome_supp_reliable_recovery.Rds"
    )
  )
}

# part 2 - read the files
df_intervention_services <- read_an_open_excel(
  path = here::here('data', 'project', 'tt_intervention_projects_copy.xlsx'),
  sheet = "intervention_projects"
)

# get a summary of interventions
df_interventions <- read_an_open_excel(
  path = here::here('data', 'project', 'tt_interventions_summary.xlsx'),
  sheet = 'interventions'
) |>
  dplyr::filter(iapt_code == params$ods_intervention) |>
  dplyr::mutate(calc_month = zoo::as.yearmon(month))

# load in matching variables
df <- get_matching_variables()

# load in variable labels
ls_labels <- get_variable_labels()
```

# Executive summary

\< To be completed at the end \>

```{r}
#| label: List of interventions
#| cache: false

df_interventions |>
  dplyr::select(month, intervention) |>
  dplyr::arrange(month) |>
  gt::gt() |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::fmt_date(columns = month, date_style = "yMMM") |>
  gt::cols_label(month = "Month", intervention = "Intervention") |>
  gt::cols_width(month ~ gt::pct(15)) |>
  gt::tab_header(
    title = "Interventions",
    subtitle = "Changes made by the service to better prepare clients for therapy"
  )
```

```{r}
#| label: Timeline of interventions
#| cache: false

# create a df holding details about the timeline
df_timeline <-
  df_interventions |>
  # make fields compatible with {timevis}
  dplyr::rename(content = intervention_html, start = month) |>
  # select essential details
  dplyr::select(content, start)

# display as a timeline
timevis::timevis(data = df_timeline, showZoom = FALSE)

```

<br> *Timeline view of interventions* <br>

**Other interventions (not impact evaluated)**

In September 2025 the team introduced the Limbic Care app, a digital CBT-based tool used nationally to support patients between assessment and therapy by improving engagement, reducing dropout, and preparing them for treatment through psychoeducation and expectation-setting. However, the current IAPT data cannot yet evaluate the impact of this recent intervention.

## Outcomes

Two outcome measures have been used in this evaluation:

1.  The proportion of discharged referrals where the patient attended five or more treatment sessions

2.  The proportion of discharged referrals that achieved reliable recovery.

These measures follow the numerator and denominator definitions, below.

+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Item               | Definition                                                                                                                                                                                                                                                            |
+====================+=======================================================================================================================================================================================================================================================================+
| Measure            | The proportion of discharged referrals each month where the patient attended five or more treatment sessions.                                                                                                                                                         |
+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Numerator          | Those in the denominator who attended five or more treatment care contacts during their referral^[1](#fn1)^                                                                                                                                                           |
+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Denominator        | Referrals ending each month where the patient received at least two treatment contacts ^[2](#fn2)^                                                                                                                                                                    |
+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Rationale          | This denominator represents monthly discharges for referrals that began a course of therapy.                                                                                                                                                                          |
|                    |                                                                                                                                                                                                                                                                       |
|                    | The numerator is the subset who attended at least five treatment contacts. Recent research identifies five sessions as a minimum associated with greater likelihood of achieving reliable recovery, so this group are those more likely to achieve reliable recovery. |
|                    |                                                                                                                                                                                                                                                                       |
|                    | This measure therefore captures discharged referrals each month that demonstrate sufficient adherence to have at least 50% likelihood of reliable recovery.                                                                                                           |
+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Expected variation | We expect this measure to **increase** as a result of interventions that improve adherence with therapy.                                                                                                                                                              |
+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

: Outcome measure 1

<aside id="footnotes" class="footnotes footnotes-end-of-block" role="doc-footnote">

<ol>

<li id="fn1">

<p>This count will be obtained from the field ‘TreatmentCareContact_Count’ (object I101D29) from the table ‘IDS101Referral’<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p>

</li>

<li id="fn2">

<p>This count will be obtained from the field ‘TreatmentCareContact_Count’ (object I101D29) from the table ‘IDS101Referral’<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p>

</li>

</ol>

</aside>

+--------------------+--------------------------------------------------------------------------------------------------------------------------+
| Item               | Description                                                                                                              |
+====================+==========================================================================================================================+
| Measure            | The proportion of referrals that achieved reliable recovery                                                              |
+--------------------+--------------------------------------------------------------------------------------------------------------------------+
| Numerator          | Of the denominator, those who achieved Reliable recovery^[1](#fn1)^                                                      |
+--------------------+--------------------------------------------------------------------------------------------------------------------------+
| Denominator        | Referrals ending each month where the patient received at least two treatment contacts ^[2](#fn2)^                       |
+--------------------+--------------------------------------------------------------------------------------------------------------------------+
| Rationale          | This measure identifies referrals that attained the target outcome of reliable recovery.                                 |
|                    |                                                                                                                          |
|                    | It serves to evaluate whether changes in this outcome align with the shifts observed in the process measure (Outcome 1). |
+--------------------+--------------------------------------------------------------------------------------------------------------------------+
| Expected variation | We expect this measure to **increase** as a result of interventions that improve adherence with therapy.                 |
+--------------------+--------------------------------------------------------------------------------------------------------------------------+

: Outcome measure 2

<aside id="footnotes" class="footnotes footnotes-end-of-block" role="doc-footnote">

<ol>

<li id="fn1">

<p>Defined as both <code>ReliableImprovement_Flag = `True`</code> <strong>and</strong> <code>Recovery_Flag = `True`</code><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p>

</li>

<li id="fn2">

<p>This count will be obtained from the field ‘TreatmentCareContact_Count’ (object I101D29) from the table ‘IDS101Referral’<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p>

</li>

</ol>

</aside>

## Matching variables

Since no consensus exists on predictors of therapy adherence, a [literature search](https://github.com/The-Strategy-Unit/talking_therapies/blob/main/data/reference/lit_search.xlsx) identified plausible variables. These were shortlisted based on feasibility of measurement in the IAPT dataset.

The selected factors, listed below, are mostly expressed as proportions of either referrals or care contacts. Aggregating patient-level data into these proportions represents the overall Talking Therapies service and makes the variables more suitable for the matching process.

Outcome measure:

-   Proportion of referrals that have completed treatment, but where the patient did not attend at least five treatment sessions.

Demographic characteristics:

-   Proportion of referrals for people aged 25 years and younger at referral

-   Proportion of referrals for people aged 60 years and older at referral

-   Proportion of referrals for people whose gender identity is female

-   Proportion of referrals for people whose LSOA of residence is among the 20% most deprived in England

-   Proportion of referrals for people whose LSOA of residence is among the 20% least deprived in England

-   Proportion of referrals for people whose broad ethnic background is 'White'

Therapist and service characteristics:

-   Proportion of care contacts where the therapist has attained an NHS TT qualification

-   Proportion of care contacts conducted on hospital premises

-   Proportion of care contacts conducted face-to-face

-   Proportion of care contacts outside of weekdays, 9am to 5pm

-   Proportion of care contacts delivered as internet enabled therapy

-   Proportion of care contacts delivered to an individual patient

-   Proportion of referrals where the referral-to-treatment wait time was within six weeks

-   Proportion of referrals where there was step-up to high-intensity therapy

Language and accessibility:

-   Proportion of care contacts conducted in English

-   Proportion of care contacts conducted with an interpreter present

A draft version of these matching variables was shared by email with members of the NHS Talking Therapies (TT) and Individual Placement and Support (IPS) National Programme Delivery Group for review in July 2025. The list above has since been augmented based on feedback.

## Outcomes for `r params$intervention_long_name`

`r params$intervention_long_name` discharges data is mostly available from the beginning of 2022 with the most recent data point being June 2025.

```{r}
#| label: project discharges time series
#| fig-height: 7
#| cache: true

p <-
  df |>
  dplyr::filter(ods_code == params$ods_intervention) |>
  ggplot2::ggplot(
    mapping = ggplot2::aes(
      x = calc_month,
      y = o1_denom_discharges_count
    )
  ) +
  # add an arrow and text pointing to start of regular activity
  ggplot2::annotate(
    geom = "segment",
    x = zoo::as.yearmon("Apr 2021"),
    xend = zoo::as.yearmon("Nov 2021"),
    y = 500,
    yend = 500,
    colour = "#5881c1",
    arrow = ggplot2::arrow(type = "closed", length = ggplot2::unit(0.2, "cm"))
  ) +
  ggplot2::annotate(
    geom = "text",
    x = zoo::as.yearmon("Mar 2021"),
    y = 500,
    label = "Discharges begin",
    hjust = 1,
    colour = "#5881c1"
  ) +
  zoo::scale_x_yearmon(limits = c(zoo::as.yearmon(c("Jan 2019")), NA)) +
  # add in the rest of the plot
  ggplot2::geom_line() +
  ggplot2::geom_point() +
  ggplot2::theme_minimal(base_size = 20) +
  ggplot2::theme(axis.title.x = ggplot2::element_blank()) +
  ggplot2::labs(
    title = params$intervention_long_name,
    subtitle = stringr::str_wrap(
      "Referral discharges begin with regular frequency from January 2022",
      60
    ),
    # x = "",
    y = "Number of discharges"
  )
p
# p |> plotly::ggplotly()
```

Focusing on the period January 2022 to June 2025, the time series for each of the outcome variables is shown below. Each plot includes a trendline in [orange]{style="color: #f9bf07;"} and a dotted line in [blue]{style="color: #5881c1;"} indicating when each of the interventions was started.

```{r}
#| label: project outcome 1
#| fig-height: 7
#| cache: true

# filter the data for the project and a suitable timeframe
df_temp <-
  df |>
  dplyr::filter(
    ods_code == params$ods_intervention,
    dplyr::between(
      x = calc_month,
      left = zoo::as.yearmon("Jan 2022"),
      right = zoo::as.yearmon("Aug 2025")
    )
  )

# get a rate of increase for outcome 1
lm_temp <-
  lm(
    formula = o1_rate ~ calc_month,
    data = df_temp
  )

# extract as a variable
rate_per_year <-
  lm_temp |>
  broom::tidy() |>
  dplyr::filter(term == "calc_month") |>
  dplyr::pull(estimate) |>
  round(3)

# plot
df_temp |>
  plot_outcomes_over_time(
    df_interventions = df_interventions,
    var_outcome = "o1_rate",
    trendline = TRUE,
    interventions = TRUE,
    align = "right",
    separation_pct = 0.08,
    title = params$intervention_long_name,
    subtitle = stringr::str_wrap(
      string = describe_trajectory(
        rate_per_year = rate_per_year,
        str_outcome = "Outcome 1"
      ),
      width = 61
    )
  )
```

```{r}
#| label: project outcome 2
#| fig-height: 7
#| cache: true

# get a rate of increase for outcome 2
lm_temp <-
  lm(
    formula = o2_rate ~ calc_month,
    data = df_temp
  )

# extract as a variable
rate_per_year <-
  lm_temp |>
  broom::tidy() |>
  dplyr::filter(term == "calc_month") |>
  dplyr::pull(estimate) |>
  round(3)

# plot
df_temp |>
  plot_outcomes_over_time(
    df_interventions = df_interventions,
    var_outcome = "o2_rate",
    trendline = TRUE,
    interventions = TRUE,
    align = "right",
    title = params$intervention_long_name,
    subtitle = stringr::str_wrap(
      string = describe_trajectory(
        rate_per_year = rate_per_year,
        str_outcome = "Outcome 2"
      ),
      width = 61
    )
  )
```

The matching process will use data from the eleven-month period preceding `r params$intervention_long_name` first intervention, specifically from Jan 2022 to `r params$zoo_intervention - 1/12`. This pre-intervention period provides a stable baseline for matching services, ensuring that the comparison is conducted before any intervention effects could potentially influence the data.

# National outcome trends

We will first look at the national trends for our two outcome measures.

The next two charts include only months in which each services recorded at least 100 discharges. This filter removes unreliable rates that can arise from newly launched services or months with very few discharges.

```{r}
#| fig-height: 7
#| label: outcome 1 national trend
#| cache: true

# filter the data to make it easier to use
df_temp <-
  df |>
  dplyr::filter(
    # limit to the start of activity and exclude latest point
    dplyr::between(
      calc_month,
      zoo::as.yearmon("Jan 2022"),
      zoo::as.yearmon("May 2025")
    ),
    # limit to months where each service has more than 100 discharges to avoid spurious rates
    o1_denom_discharges_count > 100
  )

# linear model
lm_temp <-
  lm(
    formula = o1_rate ~ calc_month,
    data = df_temp
  )
# extract as a variable
rate_per_year <- lm_temp |>
  broom::tidy() |>
  dplyr::filter(term == "calc_month") |>
  dplyr::pull(estimate) |>
  round(3)

# get average rates per month
df_summary_per_month <-
  df_temp |>
  dplyr::summarise(
    o1_rate_av = mean(o1_rate, na.rm = TRUE),
    o1_rate_sd = sd(o1_rate, na.rm = TRUE),
    o2_rate_av = mean(o2_rate, na.rm = TRUE),
    o2_rate_sd = sd(o2_rate, na.rm = TRUE),
    .by = c(calc_month)
  ) |>
  dplyr::arrange(calc_month)

# show a spaghetti plot of all TT services over time
ggplot2::ggplot() +
  # add traces for each individual TT service
  ggplot2::geom_line(
    data = df_temp,
    mapping = ggplot2::aes(
      x = calc_month,
      y = o1_rate,
      group = ods_code
    ),
    colour = adjustcolor("#9d928a", alpha.f = 0.3),
    linewidth = 0.5
  ) +
  # add a ribbon of +/- one sd to show spread
  ggplot2::geom_ribbon(
    data = df_summary_per_month,
    mapping = ggplot2::aes(
      x = calc_month,
      ymin = (o1_rate_av - o1_rate_sd),
      ymax = (o1_rate_av + o1_rate_sd)
    ),
    fill = adjustcolor("#f9bf07", alpha.f = 0.2)
  ) +
  # add a trendline
  ggplot2::geom_smooth(
    data = df_temp,
    mapping = ggplot2::aes(x = calc_month, y = o1_rate),
    method = "lm",
    formula = y ~ x, # made explicit to avoid console messages
    se = FALSE,
    colour = adjustcolor("#2c2825", alpha.f = 1),
    linetype = "dotted"
  ) +
  ggplot2::scale_y_continuous(labels = scales::label_percent(accuracy = 1)) +
  zoo::scale_x_yearmon() +
  ggplot2::theme_minimal(base_size = 20) +
  ggplot2::theme(
    axis.title = ggplot2::element_blank()
  ) +
  ggplot2::labs(
    title = "Outcome 1: discharges with 5+ treatment contacts",
    subtitle = glue::glue(
      "National trend since 2022 is upwards at a rate of {rate_per_year * 100}% per year"
    )
  )
```

**What the chart shows:**

-   Each grey line traces a single Talking Therapy service's monthly performance on outcome 1 (percentage of discharged referrals that received at least five treatment contacts).

-   The dotted line is a linear regression that captures the overall trend across all services.

-   The yellow band around the dotted line marks ± 1 standard deviation, illustrating the typical spread of service-level rates.

Nationally, the proportion of referrals meeting the 5-contact threshold has risen by around 1.6% per year, climbing from \~57% in Jan 2022 to \~ 62% in May 2025. Monthly results are highly variable; some services approach 100% in certain months, while others fall to near 0%, especially during mid-to-late 2023 when several services achieved 0% in several months.

The upward national trend indicates overall improvement, but the wide dispersion (yellow band) shows that individual services experience very different outcomes, highlighting opportunities for targeted support.

```{r}
#| fig-height: 7
#| label: outcome 2 national trend
#| warning: false
#| cache: true

# linear model
lm_temp <-
  lm(
    formula = o2_rate ~ calc_month,
    data = df_temp
  )
# extract as a variable
rate_per_year <- lm_temp |>
  broom::tidy() |>
  dplyr::filter(term == "calc_month") |>
  dplyr::pull(estimate) |>
  round(3)

# show a spaghetti plot of all TT services over time
ggplot2::ggplot() +
  # add traces for each individual TT service
  ggplot2::geom_line(
    data = df_temp,
    mapping = ggplot2::aes(
      x = calc_month,
      y = o2_rate,
      group = ods_code
    ),
    colour = adjustcolor("#9d928a", alpha.f = 0.3),
    linewidth = 0.5
  ) +
  # add a ribbon of +/- one sd to show spread
  ggplot2::geom_ribbon(
    data = df_summary_per_month,
    mapping = ggplot2::aes(
      x = calc_month,
      ymin = (o2_rate_av - o2_rate_sd),
      ymax = (o2_rate_av + o2_rate_sd)
    ),
    fill = adjustcolor("#f9bf07", alpha.f = 0.2)
  ) +
  # add a trendline
  ggplot2::geom_smooth(
    data = df_temp,
    mapping = ggplot2::aes(x = calc_month, y = o2_rate),
    method = "lm",
    formula = y ~ x, # made explicit to avoid console messages
    se = FALSE,
    colour = adjustcolor("#2c2825", alpha.f = 1),
    linetype = "dotted"
  ) +
  ggplot2::scale_y_continuous(labels = scales::label_percent(accuracy = 1)) +
  zoo::scale_x_yearmon() +
  ggplot2::theme_minimal(base_size = 20) +
  ggplot2::theme(
    axis.title = ggplot2::element_blank()
  ) +
  ggplot2::labs(
    title = "Outcome 2: discharges achieving reliable recovery",
    subtitle = glue::glue(
      "National trend since 2022 is upwards at a rate of {rate_per_year * 100}% per year"
    )
  )
```

**What the chart shows:**

-   Each grey line traces a single Talking Therapy service's monthly performance on outcome 2 (percentage of discharged referrals that received between 2 and 4 treatment contacts).

-   The dotted line is a linear regression that captures the overall trend across all services.

-   The yellow band around the dotted line marks ± 1 standard deviation, illustrating the typical spread of service-level rates.

The national share of these referrals has been increasing at a rate of 0.2% per year since 2022. Some services report low rates for this outcome each month, indicating most of their completed cases do not achieve reliable recovery. Other services show over 50% of completed referrals achieving reliable recovery which exceeds the national ambition to achieve 50% reliable recovery in Talking Therapy referrals.

While the overall picture is improving, the wide spread among individual services suggests targeted interventions are needed to help the higher-percentage providers move more referrals toward the five-contact benchmark.

# Matching variables

The aim of matching is to pair our intervention Talking Therapies service, `r params$intervention_long_name`, with one more untreated services that have similar characteristics, creating a comparison group that mimics a randomised experiment. This reduces bias and makes it easier to estimate the intervention's effect from observational data.

## Using all matching variables - Feb 2025

The dataset is cut off at Feburary 2025, the month immediately before `r params$intervention_short_name` launched its first intervention. This pre-intervention slice will serve as the basis for the matching process.

In the initial matching run we include all matching variables and specify five nearest neighbour services. Using several candidates increases the chance of finding one service that meets the parallel-trends assumption.

```{r}
#| label: matching_all_vars
#| fig-height: 9
#| cache: false
#| eval: false

# get a list of matching vars
temp_vars <- stringr::str_subset(string = names(df), pattern = "^m.*_rate$")

# prepare the data
df_prep <-
  df |>
  # keep just the variables of interest
  dplyr::select(
    c(
      ods_code,
      name,
      calc_month,
      dplyr::contains("o1_denom"),
      dplyr::contains("_rate")
    )
  ) |>
  # flag records for the intervention service
  dplyr::mutate(
    flag_intervention = ods_code %in% params$ods_intervention
  ) |>
  dplyr::filter(
    # keep services that have data for all the matching variables
    dplyr::if_all(
      .cols = dplyr::any_of(temp_vars),
      .fns = ~ !is.na(.)
    ),
    # keep services that have activity up to censor
    max(calc_month, na.rm = TRUE) >= zoo::as.yearmon("Aug 2025"),
    # keep services that have activity in each of the matching yearmonths
    # all(yearmons_matching %in% calc_month),
    # exclude other services that have implemented an intervention
    (ods_code == params$ods_intervention | flag_intervention == 0),
    .by = ods_code
  ) |>
  # shorten the 'o1_denom' variable name
  dplyr::rename("o1_denom" = o1_denom_discharges_count) |>
  # limit to just month before the interventions began
  dplyr::filter(calc_month == params$zoo_intervention_month - 1 / 12)

# string wrap variable names to better fit the plot
ls_labels_wrap <-
  purrr::modify_if(
    .x = ls_labels,
    .p = is.character,
    .f = ~ stringr::str_wrap(string = .x, width = 50)
  )

# set the matching formula
formula_matching <-
  formula(
    paste0(
      "flag_intervention ~ ",
      paste0(
        stringr::str_subset(
          string = names(df_prep),
          pattern = "^m.*_rate$"
        ),
        collapse = " + "
      )
    )
  )

# do the matching
obj_matches <-
  MatchIt::matchit(
    data = df_prep,
    formula = formula_matching,
    distance = "glm",
    method = "nearest",
    ratio = 5,
  )

# review the covariate balance
cobalt::love.plot(
  x = obj_matches,
  abs = TRUE,
  thresholds = 0.1,
  var.names = ls_labels_wrap,
  stars = "raw",
  drop.distance = TRUE
) +
  ggplot2::theme_minimal(base_size = 16) +
  ggplot2::scale_colour_manual(
    values = c("Unadjusted" = "#ec6555", Adjusted = "#5881c1")
  )
```

There are three warning messages displayed. The first two warning messages come from the propensity score matching process and likely indicate issues such as perfect separation of the data, or multicollinearity, which break key logistic regression assumptions. The third warning message comes from the process to visualise the model.

Reviewing the data reveals possible causes:

-   M14 Proportion of contacts conducted in English - the asterisk means the 'raw' score is displayed rather than absolute standardised mean differences the rest of the variables are displayed in

Clearly, using all these matching variables is problematic. Let's investigate further

## Examining matching variables

### Pre-matching assessment

First let us see the level of balance in the matching variables before any matching occurs:

```{r}
#| label: pre-matching covariate balance
#| cache: true
#| eval: false

# set the matching formula
formula_matching <-
  formula(
    paste0(
      "flag_intervention ~ ",
      paste0(
        c(
          stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
          stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
        ),
        collapse = " + "
      )
    )
  )

# check the balance prior to matching
set.seed(123)
match_pre <-
  MatchIt::matchit(
    formula = formula_matching,
    data = df_prep,
    method = NULL,
    distance = 'glm'
  ) |>
  summary()

t <-
  match_pre$sum.all |>
  tibble::as_tibble(rownames = "Matching variable") |>
  # exclude the distance metric - it isn't very useful here
  dplyr::filter(`Matching variable` != "distance") |>
  # drop the var. ratio and std. pair dist measures as they're not useful as the model doens't resolve
  dplyr::select(-c(`Var. Ratio`, `Std. Pair Dist.`)) |>
  gt::gt() |>
  gt::fmt_number(
    columns = gt::everything(),
    decimals = 4
  ) |>
  gt::data_color(
    columns = c(`Std. Mean Diff.`),
    method = "numeric",
    palette = "#f5b2aa",
    rows = abs(`Std. Mean Diff.`) < 0.1
  ) |>
  gt::tab_options(quarto.disable_processing = TRUE)
t
```

This table lists each matching variable together with its average value for `r params$intervention_long_name` (the treated group) and for all other donor services (the control group).

Our goal is to identify variables that show large differences, because those are the ones that the matching process can potentially improve. Variables with a standardised mean difference less than 0.1 are highlighted in pink. Variables which are uncoloured indicate where we could increase similarity between the treated and control groups.

Variables with less than 0.1 difference are less promising for improvement. In this case, `m14_rate` (M14 Proportion of contacts conducted in English).

**Recommendation:** drop `m14_rate` from the matching process as there is little scope to improve balance on these variables.

### Separation

Perfect separation occurs when the model can perfectly predict treatment assignment based solely on covariates - meaning it assigns propensity scores of exactly 0 or 1. In this scenario, treated and untreated units become completely distinguishable, making it impossible to find suitable matches for some observations. This lack of overlap in covariate distributions can lead to biased or unstable estimates.

In our case, where covariates are expressed as proportions bounded between 0 and 1, separation may arise when these covariates take on extreme values of exactly 0 or 1.

Here we see a list of covariates for `r params$intervention_long_name` which have values of exactly 0 or 1:

```{r}
#| label: separation
#| cache: true
#| eval: false

# list the variables likely to result in perfect separation
df_prep |>
  # get the project's record
  dplyr::filter(ods_code == params$ods_intervention) |>
  # pivot so that variables are now rows
  tidyr::pivot_longer(
    cols = c(
      dplyr::everything(),
      -dplyr::any_of(c("ods_code", "name", "calc_month", "flag_intervention"))
    ),
    names_to = "variable",
    values_to = "value"
  ) |>
  # filter for values of either 1 or 0
  dplyr::filter(
    value %in% c(0L, 1L),
    !variable %in% c("m14_rate") # already excluded from the above process
  ) |>
  # add in variable descriptions
  dplyr::left_join(
    y = tibble::tibble(
      variable = names(ls_labels),
      description = as.character(unname(ls_labels))
    ),
    by = dplyr::join_by("variable")
  ) |>
  # display the result
  dplyr::select(variable, description, value) |>
  gt::gt() |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::cols_label(
    variable = "Matching variable",
    value = params$zoo_intervention_month - 1 / 12,
    description = "Variable description"
  )
```

**Recommendation:** drop `m10_rate`, `m11_rate` and `m16_rate` from the matching process as they are likely to result in perfect separation.

### Multicollinearity

Multicollinearity occurs when two or more matching variables are highly linearly related. Because such variables convey overlapping information, the matching process struggles to calculate reliable propensity scores.

In this section we identify strongly related matching variables using the Variance Inflation Factor (VIF). VIF measures how much a variable is linearly related to the others; higher values indicate stronger multicollinearity.

-   A VIF between 5 and 10 is often considered a warning sign. In the table below these are highlighted in yellow.
-   A VIF greater than 10 is strongly signals multicollinearity. Variables with such high VIF values should be excluded from the model. In the table below, any variable whose VIF exceeds 10 is highlighted in pink to flag a potential problem.

```{r}
#| label: multicollinearity - step 1
#| cache: true
#| eval: false

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(
  matching_vars,
  c("m14_rate", "m10_rate", "m11_rate", "m16_rate")
)
t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

**Next step:** evaluate the impact of removing `m3_rate` from the matching model.

```{r}
#| label: multicollinearity - step 2
#| cache: true
#| eval: false

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(
  matching_vars,
  c("m14_rate", "m10_rate", "m11_rate", "m16_rate", "m3_rate")
)
t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

**Next step:** remove `m4_rate` from the matching model.

```{r}
#| label: multicollinearity - step 3
#| cache: true
#| eval: false

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(
  matching_vars,
  c("m14_rate", "m10_rate", "m11_rate", "m16_rate", "m3_rate", "m4_rate")
)
t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

**Next step:** drop `m9_rate` from the matching model.

```{r}
#| label: multicollinearity - step 4
#| cache: true
#| eval: false

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(
  matching_vars,
  c(
    "m14_rate",
    "m10_rate",
    "m11_rate",
    "m16_rate",
    "m3_rate",
    "m4_rate",
    "m9_rate"
  )
)
t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

**Next step:** remove `m2_rate` from the matching model.

```{r}
#| label: multicollinearity - step 5
#| cache: true
#| eval: false

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(
  matching_vars,
  c(
    "m14_rate",
    "m10_rate",
    "m11_rate",
    "m16_rate",
    "m3_rate",
    "m4_rate",
    "m9_rate",
    "m2_rate"
  )
)
t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

**Next step:** remove `m6_rate`from the matching model.

```{r}
#| label: multicollinearity - step 6
#| cache: true
#| eval: false

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(
  matching_vars,
  c(
    "m14_rate",
    "m10_rate",
    "m11_rate",
    "m16_rate",
    "m3_rate",
    "m4_rate",
    "m9_rate",
    "m2_rate",
    "m6_rate"
  )
)
t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

**Next step:** drop `m12_rate` from the matching model.

```{r}
#| label: multicollinearity - step 7
#| cache: true
#| eval: false

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(
  matching_vars,
  c(
    "m14_rate",
    "m10_rate",
    "m11_rate",
    "m16_rate",
    "m3_rate",
    "m4_rate",
    "m9_rate",
    "m2_rate",
    "m6_rate",
    "m12_rate"
  )
)
t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

**Next step:** drop `m17_rate` from the matching model.

```{r}
#| label: multicollinearity - step 8
#| cache: true
#| eval: false

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(
  matching_vars,
  c(
    "m14_rate",
    "m10_rate",
    "m11_rate",
    "m16_rate",
    "m3_rate",
    "m4_rate",
    "m9_rate",
    "m2_rate",
    "m6_rate",
    "m12_rate",
    "m17_rate"
  )
)

t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

All matching variables now have VIF scores below 3, confirming they are suitable for propensity-score matching. The model has converged, so the matching process proceeds without issue; the only remaining warning relates to having a single treated service and can safely be ignored.

The set of matching variables now consists of:

```{r}
#| label: multicollinearity - final list of variables
#| cache: true
#| eval: false
# get the list of variables in a tibble

df_matching_var_labels <-
  tibble::tibble(
    variable = names(ls_labels),
    description = unlist(ls_labels, use.names = FALSE)
  ) |>
  dplyr::filter(variable %in% matching_vars)

# present as a {gt} table
df_matching_var_labels |>
  gt::gt() |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::cols_label(
    variable = "Variable name",
    description = "Variable description"
  )
```

# Analysis

## Propensity score matching - Feb 2025

Using this list of matching variables we can now re-examine the propensity score matching results for `r params$intervention_long_name`.

The below plot is called a love plot (also known as a covariate balance plot) which visualises how well our matching variables are balanced between `r params$intervention_long_name` before and after applying a propensity-score matching process.

Our matching variables are listed along the y-axis and the x-axis shows the standardised mean difference (SMD), which is a measure of how different the averages are between the two groups.

Points in red indicate the differences between `r params$intervention_long_name` and all other Talking Therapy services before matching. Points in blue indicate the differences between `r params$intervention_long_name` and eight of the closest matched services.

The dotted line is a reference at 0.2 SMD that indicates an acceptable imbalance threshold.

```{r}
#| label: propensity score matching new
#| fig-height: 7
#| message: false
#| warning: false
#| cache: true
#| eval: false

# set the matching formula
formula_matching <-
  formula(
    paste0(
      "flag_intervention ~ ",
      paste0(matching_vars, collapse = " + ")
    )
  )

# do the matching
obj_matches <-
  MatchIt::matchit(
    data = df_prep,
    formula = formula_matching,
    distance = "glm",
    method = "nearest",
    ratio = 8,
  )

# review the covariate balance
cobalt::love.plot(
  x = obj_matches,
  abs = TRUE,
  thresholds = 0.2,
  var.names = ls_labels_wrap,
  stars = "raw",
  drop.distance = FALSE,
  var.order = "unadjusted"
) +
  ggplot2::theme_minimal(base_size = 16) +
  ggplot2::scale_colour_manual(
    values = c("Unadjusted" = "#ec6555", Adjusted = "#5881c1")
  )
```

These results indicate that the matched services are reasonably close, though not perfect, comparators for `r params$intervention_long_name`.

Following matching, most variables show improved balance between `r params$intervention_long_name` and the eight matched services, as evidenced by blue points being closer to zero than red points. However, one variable (M6) became notably more imbalanced post-matching.

Four variables fall within the 0.2 Standardised Mean Difference (SMD) threshold, and a fifth (M7) is just outside this boundary.

The eight matched services identified through this process are listed in the table below:

```{r}
#| label: propensity score matches
#| fig-height: 8
#| cache: true
#| eval: false

# extract the matches
matches <- MatchIt::get_matches(obj_matches)

# show in a table
matches |>
  dplyr::select(name, ods_code) |>
  dplyr::mutate(
    ods_code = ods_code |>
      as.factor() |>
      forcats::fct_relevel(params$ods_intervention)
  ) |>
  dplyr::arrange(ods_code) |>
  gt::gt() |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::data_color(
    columns = gt::everything(),
    rows = ods_code == params$ods_intervention,
    palette = "#f9bf07"
  ) |>
  gt::cols_label(
    name = "Talking Therapies organisation",
    ods_code = "ODS code"
  )
```

### Parallel trends assumption

The parallel trends assumption states that, if the intervention never occurred, `r params$intervention_long_name` and its control group would have followed the same trajectory over time. A difference-in-differences (DiD) analysis depends on this assumption because it uses the control group's pre-intervention trend as the counterfactual for `r params$intervention_long_name`.

To check this assumption holds we look at the pre-intervention period and if the outcome trends for both groups move together (i.e. have similar slopes), the assumption is plausible.

We will now assess the pre-intervention trends for `r params$intervention_long_name` (shown in orange) and each of the eight matched Talking Therapy services (shown in grey). Trendlines are overlaid on each plot to make it easier to judge whether the series move together.

#### Take Time to Talk RV3L8

Outcome 1: ✔️ The trends are almost parallel, there is a hint of divergence but otherwise looks good

Outcome 2: ✔️ The trends are parallel

```{r}
#| label: PSM - take time to talk
#| fig-height: 8
#| cache: true
#| eval: false

# plots comparing each matched service
plot_list <-
  purrr::map(
    # select the matches - but exclude the project
    .x = stringr::str_subset(
      string = matches$ods_code,
      pattern = params$ods_intervention,
      negate = TRUE
    ),
    .f = \(.x) {
      p <-
        compare_matches_preintervention(
          df = df,
          selected_ods = c(params$ods_intervention, .x),
          period_preintervention = zoo::as.yearmon(c("Jan 2022", "Feb 2025")),
          trendline = TRUE
        )
      return(p)
    }
  )

# display
plot_list[[1]]
```

#### We Are With You In Surrey G7X5M

Outcome 1: ❌ The trends are not parallel - the control only has data from July 2023 onward, though it closely tracks from July 2024 onward.

Outcome 2: ❌ The trends are not parallel - the control only has data from July 2023 onward, though it tracks from July 2024 onward.

```{r}
#| label: PSM - we are with you surrey
#| fig-height: 8
#| cache: true
#| eval: false
plot_list[[2]]
```

#### Northwick Park Hospital RV383

Outcome 1: ❌ The trends are not parallel - they are slightly convergent

Outcome 2: ❌ The trends are not parallel - they are slightly divergent

```{r}
#| label: PSM - northwick
#| fig-height: 8
#| cache: true
#| eval: false
plot_list[[3]]
```

#### ICCS RV3CH

Outcome 1: ❌ The trends are not parallel - they are convergent

Outcome 2: ❌ The trends are not parallel - they are convergent

```{r}
#| label: PSM - iccs
#| fig-height: 8
#| cache: true
#| eval: false
plot_list[[4]]
```

#### Mind Matters Surrey NHS RXX1Y

Outcome 1: ✔️ The trends are parallel

Outcome 2: ✔️ The trends are parallel

```{r}
#| label: PSM - mind matters
#| fig-height: 8
#| cache: true
#| eval: false
plot_list[[5]]
```

#### Centre for Psychology ANV01

Outcome 1: ❌ The trends are not parallel - they are convergent

Outcome 2: ❌ The trends are not parallel - they are divergent

```{r}
#| label: PSM - centre for psych
#| fig-height: 8
#| cache: true
#| eval: false
plot_list[[6]]
```

#### Westminster Wellbeing Service RV3DG

Outcome 1: ❌ The trends are not parallel - they are divergent

Outcome 2: ❌ The trends are not parallel - they are convergent

```{r}
#| label: PSM - westminster
#| fig-height: 8
#| cache: true
#| eval: false
plot_list[[7]]
```

#### Everyturn Services Ltd. Talking Therapies (Peterborough) (NDC05)

Outcome 1: ✔️ The trends are parallel

Outcome 2: ✔️ The trends are parallel

```{r}
#| label: PSM - everyturn
#| fig-height: 8
#| cache: true
#| eval: false
plot_list[[8]]
```

### Matching summary

A total of eight Talking Therapy services were matched with `r params$intervention_long_name` using *Propensity Score Matching (PSM)*. Of these, three had pre-intervention trends that visually match those of `r params$intervention_long_name`'s for both outcome measures.

```{r}
#| label: psm - matches with parallel trends
#| cache: false
#| eval: false

# list out the matches with parallel pre-intervention trends
matches_parallel_ods <- c("RV3L8", "RXX1Y", "NDC05")

# add these controls to a list for use in the synthetic control section
controls <-
  list(
    "psm_all" = matches$ods_code,
    "psm_parallel" = matches_parallel_ods
  )

# display these in a table
matches |>
  dplyr::filter(ods_code %in% matches_parallel_ods) |>
  dplyr::select(name, ods_code) |>
  dplyr::arrange(ods_code) |>
  gt::gt() |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::cols_label(
    name = "Talking Therapies organisation",
    ods_code = "ODS code"
  )
```

### Analysis

Now we have matched `r params$intervention_long_name` with three other Talking Therapies services and assessed their likelihood of meeting the parallel trends assumption based on their pre-intervention data, let us review how the full time series looks for this group of services.

#### Outcome 1

```{r}
#| label: psm - spaghetti plot1 outcome 1
#| fig-height: 6
#| cache: true
#| eval: false

# get a df with the details for our matched services
df_analysis <-
  df |>
  dplyr::filter(
    # limit to activity between Jul 2022 and May 2025
    dplyr::between(
      calc_month,
      zoo::as.yearmon("Jan 2022"),
      zoo::as.yearmon("Aug 2025")
    ),
    # limit to our matched services with parallel trends
    ods_code %in% c(params$ods_intervention, matches_parallel_ods)
  ) |>
  # simplify the data
  dplyr::select(ods_code, calc_month, o1_rate, o2_rate) |>
  # create treatment and post indicators
  dplyr::mutate(
    treated = dplyr::if_else(ods_code == params$ods_intervention, 1L, 0L),
    post = dplyr::if_else(calc_month >= params$zoo_intervention_month, 1L, 0L),
    line_colour = dplyr::if_else(
      ods_code == params$ods_intervention,
      "#f9bf07",
      adjustcolor("#9d928a", alpha.f = 0.5)
    )
  )

# show a spaghetti plot for these services
p <-
  plot_spaghetti_plot(
    df = df_analysis,
    str_outcome = "o1_rate",
    ods_intervention = params$ods_intervention,
    str_title = "Outcome 1: discharges with 5+ treatment contacts",
    str_subtitle = "RWK79 displays abnormal results in mid-2023",
    zoo_intervention = params$zoo_intervention_month,
    bool_intervention = TRUE
  )
p
# p |> plotly::ggplotly()
```

**What this chart shows:**

-   Performance against outcome 1 is shown on the y-axis and time is along the x-axis.

-   There are three time series displayed, one for `r params$intervention_long_name`, shown in orange, and one for each of the two of our matched services, shown in grey.

-   Each series is identified by its ODS code at the end of the data in May 2025.

-   The dotted line represents the start of `r params$intervention_long_name`'s interventions in `r params$zoo_intervention_month`.

**Key observations**

-   One control service, RWK79, exhibited an abnormal dip to 20% performance in outcome 1 in September 2023.

-   `r params$intervention_long_name` also experienced a similar, but smaller dip to 57% in June 2024.

These brief, but steep declines would bias the post-implementation estimates downward for `r params$zoo_intervention_month`. To avoid this bias, the low-performance points should be excluded from the dataset.

#### Outcome 2

```{r}
#| label: psm - spaghetti plot1 outcome 2
#| fig-height: 6
#| cache: true
#| eval: false

# show a spaghetti plot for these services
p <-
  plot_spaghetti_plot(
    df = df_analysis,
    str_outcome = "o2_rate",
    ods_intervention = params$ods_intervention,
    str_title = "Outcome 2: discharges achieving reliable recovery",
    str_subtitle = "",
    zoo_intervention = params$zoo_intervention_month,
    bool_intervention = TRUE
  )
p
# p |> plotly::ggplotly()
```

**Key observations**

Two control services exhibited abnormal dips in performance:

-   RWK79 briefly fell to 20% in September 2023

-   RXX1Y briefly fell to 27% in March 2024

-   `r params$intervention_long_name` also experienced a dip to 23% in May 2024

#### Both outcomes excluding outliers

```{r}
#| label: psm - spaghetti plot2 outcomes 1 and 2
#| fig-height: 6
#| cache: true
#| eval: false

# get a df excluding the problematic months for the controls
df_analysis2 <-
  df_analysis |>
  dplyr::filter(
    !(ods_code == params$ods_intervention &
      calc_month %in%
        zoo::as.yearmon(c("May 2022", "Sep 2023", "May 2024", "Jun 2024"))),
    !(ods_code == "RWK79" &
      calc_month %in% zoo::as.yearmon(c("Sep 2023", "Mar 2024"))),
    !(ods_code == "RXX1Y" & calc_month %in% zoo::as.yearmon(c("Mar 2024")))
  )

# show as a spaghetti plot
plot_spaghetti_plot(
  df = df_analysis2,
  str_outcome = "o1_rate",
  ods_intervention = params$ods_intervention,
  str_title = "Outcome 1: discharges with 5+ treatment contacts",
  str_subtitle = "These time series now seem less likely to bias the analysis",
  zoo_intervention = params$zoo_intervention_month,
  bool_intervention = TRUE
)

# show as a spaghetti plot
plot_spaghetti_plot(
  df = df_analysis2,
  str_outcome = "o2_rate",
  ods_intervention = params$ods_intervention,
  str_title = "Outcome 2: discharges with reliable recovery",
  str_subtitle = "These time series now seem less likely to bias the analysis",
  zoo_intervention = params$zoo_intervention_month,
  bool_intervention = TRUE
)
```

#### Difference-in-Differences (DiD)

The results of the DiD analyses are presented below:

```{r}
#| label: psm - did table
#| cache: true
#| eval: false
# conduct did analysis on the matched service
did <-
  get_manual_did_estimation(
    df = df_analysis2,
    ods_intervention = params$ods_intervention,
    zoo_intervention = params$zoo_intervention_month
  )

# add to a combined summary (for sensitivity analysis)
did_overall <-
  did |>
  dplyr::mutate(specification = "Main model (baseline)")

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  tibble::tibble(
    specification = "PSM main model",
    outcome = did$outcome,
    estimate = did$estimate,
    se = did$std.error
  )

# display
did |>
  dplyr::select(
    outcome,
    estimate,
    conf.low,
    conf.high,
    p.value
  ) |>
  gt::gt() |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::fmt_percent(
    columns = c(estimate, conf.low, conf.high),
    decimals = 2
  ) |>
  gt::cols_merge(
    columns = c(conf.low, conf.high),
    pattern = "{1} to {2}"
  ) |>
  gt::cols_label(
    outcome = "Outcome",
    estimate = "Difference-in-Differences (DiD) estimate",
    conf.low = "95% confidence interval"
  ) |>
  gt::tab_style(
    style = list(gt::cell_text(weight = "bold")),
    locations = gt::cells_body(
      columns = c(estimate, conf.low),
      rows = p.value <= 0.05
    )
  ) |>
  gt::cols_hide(columns = p.value) |>
  gt::tab_source_note(gt::md(
    "Statistically significant findings are shown in **bold**"
  ))
```

This table summarises the Difference-in-Differences (DiD) analysis for `r params$intervention_long_name`'s interventions using the three control services identified using the Propensity Score Matching process and which exhibited parallel trends.

There is no strong evidence of a true effect for either outcome at the conventional 5% significance level.

The point estimates give the best single indicator of direction and magnitude:

-   Outcome 1: small decrease

-   Outcome 2: small increase

Since neither confidence interval excludes zero, **these findings are not statistically significant**, indicating that the observed differences could be due to chance rather than a true effect.

::: callout-tip
#### Interpretation

```{r}
#| label: interpretation help psm
#| cache: true
#| eval: false

# work out the total discharges in 12 months preceeding
total_discharges <-
  df |>
  dplyr::filter(
    ods_code == params$ods_intervention,
    dplyr::between(
      calc_month,
      zoo::as.yearmon("Jun 2024"),
      zoo::as.yearmon("May 2025")
    )
  ) |>
  dplyr::summarise(
    total = sum(o1_denom_discharges_count, na.rm = TRUE)
  ) |>
  dplyr::pull(total)

# work out the expected number of people to benefit from the uplift
people_benefit_o1 <- floor(total_discharges * (-1.96 / 100))
people_benefit_o2 <- floor(total_discharges * (1.55 / 100))
```

These findings indicate `r params$intervention_long_name`'s post-intervention performance exceeds the counterfactual for outcomes 2, but the wide confidence interval is too wide to support a definitive claim of effectiveness.

Assuming the 1.55% gain is real, it translates to an additional <r people_benefit_o2> people achieving reliable recovery per year (based on `r params$intervention_long_name`'s annual discharge volume of \<r scales::comma(total_discharges)\> from June 2024 to May 2025).
:::

### Sensitivity analysis

Two important decisions were made that led to the above analytical findings:

1.  **Parallel trend selection** - We inspected the 8 matched control services visually and excluded five that did not follow `r params$intervention_long_name`'s pre-intervention trend.

2.  **Anomalous month removal** - For the remaining matched services we omitted several months for three services with extreme values, which yielded more stable performance across outcomes.

Below we reassess the findings after relaxing each of these decisions to determine whether the original conclusions hold are are sensitive to these analytical choices.

#### Keeping anomalous months

What impact does keeping the extreme values in the time series have?

```{r}
#| label: psm - sensitivity - anomalous months
#| cache: true
#| eval: false

# conduct did analysis on the two matched services
did <-
  get_manual_did_estimation(
    df = df_analysis,
    ods_intervention = params$ods_intervention,
    zoo_intervention = params$zoo_intervention_month
  )

# add to a combined summary (for sensitivity analysis)
did_overall <-
  dplyr::bind_rows(
    did_overall,
    did |>
      dplyr::mutate(specification = "Alternative 1 - keep anomalous months")
  )

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "PSM alternative 1 - keep anomalous months",
      outcome = did$outcome,
      estimate = did$estimate,
      se = did$std.error
    )
  )

# show as a table
did |>
  dplyr::select(
    outcome,
    estimate,
    conf.low,
    conf.high,
    p.value
  ) |>
  gt::gt() |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::fmt_percent(
    columns = c(estimate, conf.low, conf.high),
    decimals = 2
  ) |>
  gt::cols_merge(
    columns = c(conf.low, conf.high),
    pattern = "{1} to {2}"
  ) |>
  gt::cols_label(
    outcome = "Outcome",
    estimate = "Difference-in-Differences (DiD) estimate",
    conf.low = "95% confidence interval"
  ) |>
  gt::tab_style(
    style = list(gt::cell_text(weight = "bold")),
    locations = gt::cells_body(
      columns = c(estimate, conf.low),
      rows = p.value <= 0.05
    )
  ) |>
  gt::cols_hide(columns = p.value) |>
  gt::tab_source_note(gt::md(
    "Statistically significant findings are shown in **bold**"
  ))
```

-   For outcome 1 the DiD estimate is slightly closer to zero and the confidence interval is wider.

-   For outcome 2 the DiD estimate increases, but the confidence interval is also wider.

Sensitivity analyses relaxing the exclusion of anomalous months yielded similar point estimates for both outcomes, though with wider confidence intervals. These results suggest that the estimated effects are directionally consistent but not statistically robust, and should be interpreted with caution.

#### Using all PSM controls

What impact does using all 8 matched control services have on the findings?

```{r}
#| label: psm - sensitivity - all controls
#| cache: true
#| eval: false

df_analysis3 <-
  df |>
  dplyr::filter(
    # limit to activity between Jul 2022 and May 2025
    dplyr::between(
      calc_month,
      zoo::as.yearmon("Jan 2022"),
      zoo::as.yearmon("Jul 2025")
    ),
    # limit to our matched services
    ods_code %in% c(params$ods_intervention, controls$psm_all)
  ) |>
  # simplify the data
  dplyr::select(ods_code, calc_month, o1_rate, o2_rate) |>
  # create treatment and post indicators
  dplyr::mutate(
    treated = dplyr::if_else(ods_code == params$ods_intervention, 1L, 0L),
    post = dplyr::if_else(calc_month >= params$zoo_intervention_month, 1L, 0L),
    line_colour = dplyr::if_else(
      ods_code == params$ods_intervention,
      "#f9bf07",
      adjustcolor("#9d928a", alpha.f = 0.5)
    )
  ) |>
  # remove the anomalous months (to isolate the effect of expanding controls)
  dplyr::filter(
    !(ods_code == params$ods_intervention &
      calc_month %in%
        zoo::as.yearmon(c("May 2022", "Sep 2023", "May 2024", "Jun 2024"))),
    !(ods_code == "RWK79" &
      calc_month %in% zoo::as.yearmon(c("Sep 2023", "Mar 2024"))),
    !(ods_code == "RXX1Y" & calc_month %in% zoo::as.yearmon(c("Mar 2024")))
  )

# conduct did analysis
did <-
  get_manual_did_estimation(
    df = df_analysis3,
    ods_intervention = params$ods_intervention,
    zoo_intervention = params$zoo_intervention_month
  )

# add to a combined summary (for sensitivity analysis)
did_overall <-
  dplyr::bind_rows(
    did_overall,
    did |>
      dplyr::mutate(specification = "Alternative 2 - use all 8 controls")
  )

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "CEM alternative 2 - use all 8 controls",
      outcome = did$outcome,
      estimate = did$estimate,
      se = did$std.error
    )
  )


# display as a table
did |>
  dplyr::select(
    outcome,
    estimate,
    conf.low,
    conf.high,
    p.value
  ) |>
  gt::gt() |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::fmt_percent(
    columns = c(estimate, conf.low, conf.high),
    decimals = 2
  ) |>
  gt::cols_merge(
    columns = c(conf.low, conf.high),
    pattern = "{1} to {2}"
  ) |>
  gt::cols_label(
    outcome = "Outcome",
    estimate = "Difference-in-Differences (DiD) estimate",
    conf.low = "95% confidence interval"
  ) |>
  gt::tab_style(
    style = list(gt::cell_text(weight = "bold")),
    locations = gt::cells_body(
      columns = c(estimate, conf.low),
      rows = p.value <= 0.05
    )
  ) |>
  gt::cols_hide(columns = p.value) |>
  gt::tab_source_note(gt::md(
    "Statistically significant findings are shown in **bold**"
  ))
```

-   For outcome 1 the DiD estimate becomes slightly more negative and the confidence interval is narrowed.

-   For outcome 2 the DiD estimate increases suggesting a stronger positive impact and the confidence interval is wider.

Expanding the control group to include all eight matched services yielded directionally consistent results for both outcomes. The estimated effect for outcome 1 became slightly more negative, while outcome 2 showed a stronger positive effect. Neither result reached statistical significance, but the findings suggest the estimated effects are robust to control group specification.

## Coarsened exact matching - March 2024

Coarsened Exact Matching (CEM) offers an alternative approach to propensity score matching. First, each variable is grouped into broader categories (e.g., 0-19%, 20-39%, 40-59%, etc.). Then Talking Therapy services are matched **exactly** on these coarsened bins.

The key advantage is that balance on the matching variables is guaranteed within each bin. The researcher controls the trade-off by choosing the width of the categories:

-   Narrower bins - tighter similarity between matched services but fewer matches

-   Wider bins - more matches but less precise similarity

The same matching variables selected from the multicollinearity optimisation process will be used. We use three cutpoints to divide each matching variable into four separate bins.

```{r}
#| label: coarsened exact matching
#| fig-height: 8
#| message: FALSE
#| cache: true
#| eval: false

# set the matching formula
formula_matching <-
  formula(
    paste0(
      "flag_intervention ~ ",
      paste0(matching_vars, collapse = " + ")
    )
  )

# do the matching
obj_matches <-
  MatchIt::matchit(
    data = df_prep,
    formula = formula_matching, # using the same formula as determined by VIF analysis
    method = "cem",
    cutpoints = 3
  )

# review the covariate balance
cobalt::love.plot(
  x = obj_matches,
  abs = TRUE,
  thresholds = 0.2,
  var.names = ls_labels_wrap,
  stars = "raw",
  var.order = "unadjusted"
) +
  ggplot2::theme_minimal(base_size = 16) +
  ggplot2::scale_colour_manual(
    values = c("Unadjusted" = "#ec6555", Adjusted = "#5881c1")
  )
```

These results show the matched services as close, but not perfect, matches for `r params$intervention_long_name`.

After matching, most variables show improved similarity (the blue points are nearer to 0 than the red points) and four variables are within the 0.2 SMD threshold.

Applying three cut-points allowed the CEM procedure to match `r params$intervention_long_name` with 6 Talking Therapy services. When we increased the number of cut-points to four - intended to boost sensitivity - only four matches were found.

The six matched services found using using five cut-points are:

```{r}
#| label: coarsened exact matches
#| fig-height: 8
#| cache: true
#| eval: false

matches <- MatchIt::match_data(obj_matches)

# show in a table
matches |>
  dplyr::select(name, ods_code) |>
  dplyr::mutate(
    ods_code = ods_code |>
      as.factor() |>
      forcats::fct_relevel(params$ods_intervention)
  ) |>
  dplyr::arrange(ods_code) |>
  gt::gt() |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::data_color(
    columns = gt::everything(),
    rows = ods_code == params$ods_intervention,
    palette = "#f9bf07"
  ) |>
  gt::cols_label(
    name = "Talking Therapies organisation",
    ods_code = "ODS code"
  )

# plots comparing each matched service
plot_list <-
  purrr::map(
    .x = stringr::str_subset(
      string = matches$ods_code,
      pattern = params$ods_intervention,
      negate = TRUE
    ),
    .f = \(.x) {
      p <-
        compare_matches_preintervention(
          df = df,
          selected_ods = c(params$ods_intervention, .x),
          period_preintervention = zoo::as.yearmon(c("Jan 2022", "Feb 2025")),
          trendline = TRUE
        )
      return(p)
    }
  )
```

### Parallel trends assumption

We now assess the parallel trends for `r params$intervention_long_name` (shown in orange) and each of the 20 matched Talking Therapy services (shown in grey). Trendlines are overlaid on each plot to make it easier to judge whether the series move together.

#### Mind in the City, Hackney and Waltham Forest (DH0)

**Outcome 1:** ❌ The trends are not parallel - they are convergent

**Outcome 2:** ❌ The trends are not parallel - they intersected in late 2022

```{r}
#| label: cem - mind in the city
#| fig-height: 8
#| cache: true
#| eval: false

plot_list[[1]]
```

#### Whittington Health NHS Trust (RKE)

**Outcome 1:** ✔️ The trends are almost parallel

**Outcome 2:** ✔️ The trends are parallel

```{r}
#| label: cem - whittington
#| fig-height: 8
#| cache: true
#| eval: false

plot_list[[2]]
```

#### Oxleas NHS Foundation Trust (RPG)

**Outcome 1:** ✔️ The trends are almost parallel, there was some differences in 2022 but these appear to have resolved throughout the rest of the time series

**Outcome 2:** ✔️ The trends are parallel

```{r}
#| label: cem - oxleas
#| fig-height: 8
#| cache: true
#| eval: false

plot_list[[3]]
```

#### Homerton Healthcare NHS Foundation Trust (RQX)

**Outcome 1:** ✔️ The trends are almost parallel

**Outcome 2:** ✔️ The trends are parallel

```{r}
#| label: cem - homerton
#| fig-height: 8
#| cache: true
#| eval: false

plot_list[[4]]
```

#### Take Time to Talk (RV3L8)

**Outcome 1:** ✔️ The trends are parallel

**Outcome 2:** ✔️ The trends are parallel

```{r}
#| label: cem - take time to talk
#| fig-height: 8
#| cache: true
#| eval: false

plot_list[[5]]
```

#### Southwark Psychological Therapies Services (Southwarck IAPT) (RV5CG)

**Outcome 1:** ✔️ The trends are parallel

**Outcome 2:** ✔️ The trends are parallel

```{r}
#| label: cem - southwark
#| fig-height: 8
#| cache: true
#| eval: false

plot_list[[6]]
```

### Matching summary

A total of 6 Talking Therapy services were matched with `r params$intervention_long_name` using *Coarsened Exact Matching (CEM)*. Of these, 5 exhibited pre-intervention trends that closely align with those of `r params$intervention_long_name` for both outcome measures.

```{r}
#| label: cem - matches with parallel trends
#| cache: true
#| eval: false

# list out the matches with parallel pre-intervention trends
matches_parallel_ods <- c(
  "RKE",
  "RPG",
  "RQX",
  "RV3L8",
  "RV5CG"
)

# add these controls to a list for use in the synthetic control section
controls <- c(
  controls,
  list(
    "cem_all" = matches$ods_code,
    "cem_parallel" = matches_parallel_ods
  )
)

# display these in a table
matches |>
  dplyr::filter(ods_code %in% matches_parallel_ods) |>
  dplyr::select(name, ods_code) |>
  dplyr::arrange(ods_code) |>
  gt::gt() |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::cols_label(
    name = "Talking Therapies organisation",
    ods_code = "ODS code"
  )
```

### Analysis

Now we have matched `r params$intervention_long_name` with 5 other Talking Therapy services and assessed their likelihood of meeting the parallel trends assumption based on their pre-intervention data, let us review how the full time series looks for this group of services.

#### Outcome 1

```{r}
#| label: cem - spaghetti plot1 outcome 1
#| fig-height: 6
#| cache: true
#| eval: false

# get a df with the details for our matched services
df_analysis <-
  df |>
  dplyr::filter(
    # limit to activity between Jul 2022 and Jul 2025
    dplyr::between(
      calc_month,
      zoo::as.yearmon("Jul 2022"),
      zoo::as.yearmon("Aug 2025")
    ),
    # limit to our matched services with parallel trends
    ods_code %in% c(params$ods_intervention, matches_parallel_ods)
  ) |>
  # simplify the data
  dplyr::select(ods_code, calc_month, o1_rate, o2_rate) |>
  # create treatment and post indicators
  dplyr::mutate(
    treated = dplyr::if_else(ods_code == params$ods_intervention, 1L, 0L),
    post = dplyr::if_else(calc_month >= params$zoo_intervention_month, 1L, 0L),
    line_colour = dplyr::if_else(
      ods_code == params$ods_intervention,
      "#f9bf07",
      adjustcolor("#9d928a", alpha.f = 0.5)
    )
  )

# show a spaghetti plot for these services
p <-
  plot_spaghetti_plot(
    df = df_analysis,
    str_outcome = "o1_rate",
    ods_intervention = params$ods_intervention,
    str_title = "Outcome 1: discharges with 5+ treatment contacts",
    str_subtitle = "",
    zoo_intervention = params$zoo_intervention_month,
    bool_intervention = TRUE
  )
p
# p |> plotly::ggplotly()
```

**What this chart shows:**

-   Performance against outcome 1 is shown on the y-axis and time is along the x-axis.

-   There are three time series displayed, one for `r params$intervention_long_name`, shown in orange, and one for each of the two of our matched services, shown in grey.

-   Each series is identified by its ODS code at the end of the data in May 2025.

-   The dotted line represents the start of `r params$intervention_long_name`'s interventions in `r params$zoo_intervention_month`.

```{r}
#| label: cem - anomalous months outcome 1
#| cache: true
#| eval: false

# return any anomalous observations
identify_anomalies(
  df = df_analysis,
  outcome = "o1_rate",
  iqr_alpha = 0.05,
  anomaly_threshold = 0.2
) |>
  identify_anomalies_gt()
```

**Key observations:**

The control services appear to be a good visual match for `r params$intervention_long_name` in the pre- and post-intervention periods. However, three observations were identified as anomalous:

-   `r params$intervention_short_name` had a larger-than-usual dip in June 2024 to 57%,

-   RQX dipped to 60% in January 2025

#### Outcome 2

```{r}
#| label: cem - spaghetti plot1 outcome 2
#| fig-height: 6
#| cache: true
#| eval: false

# show a spaghetti plot for outcome 2
p <-
  plot_spaghetti_plot(
    df = df_analysis,
    str_outcome = "o2_rate",
    ods_intervention = params$ods_intervention,
    str_title = "Outcome 2: discharges achieving reliable recovery",
    str_subtitle = "",
    zoo_intervention = params$zoo_intervention_month,
    bool_intervention = TRUE
  )
p
# p |> plotly::ggplotly()
```

```{r}
#| label: cem - anomalous months outcome 2
#| cache: true
#| eval: false

# return any anomalous observations
identify_anomalies(
  df = df_analysis,
  outcome = "o2_rate",
  iqr_alpha = 0.05,
  anomaly_threshold = 0.2
) |>
  identify_anomalies_gt()
```

**Key observations:**

The control services appear to be a good visual match for `r params$intervention_long_name` in the pre- and post-intervention periods. However, one observation was identified as anomalous:

-   RQX performance dropped to 27% in January 2025.

-   `r params$ods_intervention` dropped to 23% in May 2024.

##### Both outcome excluding outliers

Here are the two outcomes excluding the anomalous months:

```{r}
#| label: cem - spaghetti plot2 outcomes 1 and 2
#| fig-height: 6
#| cache: true
#| eval: false

# get a df excluding the problematic months
df_analysis2 <-
  df_analysis |>
  dplyr::filter(
    !(ods_code == "RQX" & calc_month %in% zoo::as.yearmon(c("Jan 2025"))),
    !(ods_code == "RWK53" &
      calc_month %in% zoo::as.yearmon(c("May 2024", "Jun 2024")))
  )

# show as a spaghette plot
plot_spaghetti_plot(
  df = df_analysis2,
  str_outcome = "o1_rate",
  ods_intervention = params$ods_intervention,
  str_title = "Outcome 1: discharges with 5+ treatment contacts",
  str_subtitle = "These time series now seem less likely to bias the analysis",
  zoo_intervention = params$zoo_intervention_month,
  bool_intervention = TRUE
)

# show as a spaghette plot
plot_spaghetti_plot(
  df = df_analysis2,
  str_outcome = "o2_rate",
  ods_intervention = params$ods_intervention,
  str_title = "Outcome 2: discharges with reliable recovery",
  str_subtitle = "These time series now seem less likely to bias the analysis",
  zoo_intervention = params$zoo_intervention_month,
  bool_intervention = TRUE
)

```

#### Difference-in-Differences (DiD)

The results of the DiD analyses are presented below:

```{r}
#| label: cem - did table
#| cache: true
#| eval: false

# conduct did analysis on the two matched services
did <-
  get_manual_did_estimation(
    df = df_analysis2,
    ods_intervention = params$ods_intervention,
    zoo_intervention = params$zoo_intervention_month
  )

# add to a combined summary (for sensitivity analysis)
did_overall <-
  did |>
  dplyr::mutate(specification = "Main model (baseline)")

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "CEM main model",
      outcome = did$outcome,
      estimate = did$estimate,
      se = did$std.error
    )
  )

# display
did |> display_manual_did_results_as_gt()
```

This table summarises the Difference-in-Differences analysis for `r params$intervention_long_name`'s interventions using the 5 controls identified using the Coarsened Exact Matching process and which exhibited parallel trends.

For outcome 1, `r params$intervention_long_name`'s observed rate is about **0.8% lower** than what the matched controls would predict, with a 95% confidence interval (-3.4% to 1.9%) that includes zero, indicating **no statistically reliable difference**.

For outcome 2, `r params$intervention_long_name`'s rate is about **4.6% higher** than expected, with a 95% confidence interval (2.0% to 7.2%) indicating **a statistically significant difference**.

::: callout-tip
## Interpretation

```{r}
#| label: interpretation help cem
#| cache: true
#| eval: false

# work out the total discharges in 12 months preceeding
total_discharges <-
  df |>
  dplyr::filter(
    ods_code == params$ods_intervention,
    dplyr::between(
      calc_month,
      zoo::as.yearmon("Jun 2024"),
      zoo::as.yearmon("May 2025")
    )
  ) |>
  dplyr::summarise(
    total = sum(o1_denom_discharges_count, na.rm = TRUE)
  ) |>
  dplyr::pull(total)

# work out the expected number of people to benefit from the uplift
people_benefit_o1 <- floor(total_discharges * (-0.77 / 100))
people_benefit_o2 <- floor(total_discharges * (4.56 / 100))
```

These figures clearly present `r params$intervention_long_name`'s post-intervention performance exceeding the counterfactual based on the matched services for outcome 2, which is statistically significant. This finding suggests the interventions had a positive causal impact on the proportion of people discharged with reliable recovery.

Assuming the 4.6% gain is real, it translates to an additional <r people_benefit_o2> people achieving reliable recovery per year (based on `r params$intervention_long_name`'s annual discharge volume of \<r scales::comma(total_discharges)\> from June 2024 to May 2025).
:::

### Sensitivity analysis

Two important decisions were made that led to the above analytical findings:

1.  **Parallel trend selection** - We inspected the 12 matched controls series visually and excluded two that did not follow `r params$intervention_long_name`'s pre-intervention trend.

2.  **Anomalous month removal** - For the remaining matched services we omitted several months for two services with extreme values, which yielded more stable performance across outcomes.

Below we reassess the findings after relaxing each of these decisions to determine whether the original conclusions hold or are sensitive to this analytical choice.

#### Keeping anomalous months

What impact does keeping the extreme values in the time series have?

```{r}
#| label: cem - sensitivity - anomalous months
#| cache: true
#| eval: false

# conduct did analysis using the original data before anomalous months excluded
did <-
  get_manual_did_estimation(
    df = df_analysis,
    ods_intervention = params$ods_intervention,
    zoo_intervention = params$zoo_intervention_month
  )

# add to a combined summary (for sensitivity analysis)
did_overall <-
  dplyr::bind_rows(
    did_overall,
    did |>
      dplyr::mutate(specification = "Alternative 1 - keep anomalous months")
  )

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "CEM alternative 1 - keep anomalous months",
      outcome = did$outcome,
      estimate = did$estimate,
      se = did$std.error
    )
  )

# show as a table
did |> display_manual_did_results_as_gt()
```

This sensitivity analysis confirms the robustness of the main findings:

-   Outcome 1 continues to show no significant effect, and the estimate becomes even closer to zero.

-   Outcome 2 remains significantly and positively affected by the intervention, even when anomalous months are included.

#### Using all CEM controls

What impact does using all 6 matched control services have on the findings?

```{r}
#| label: cem - sensitivity - all controls
#| cache: true
#| eval: false

# get a df with the details for our matched services
df_analysis3 <-
  df |>
  dplyr::filter(
    # limit to activity between Jan 2022 and Aug 2025
    dplyr::between(
      calc_month,
      zoo::as.yearmon("Jul 2022"),
      zoo::as.yearmon("Aug 2025")
    ),
    # limit to our matched services
    ods_code %in% c(params$ods_intervention, controls$cem_all)
  ) |>
  # simplify the data
  dplyr::select(ods_code, calc_month, o1_rate, o2_rate) |>
  # create treatment and post indicators
  dplyr::mutate(
    treated = dplyr::if_else(ods_code == params$ods_intervention, 1L, 0L),
    post = dplyr::if_else(calc_month >= params$zoo_intervention_month, 1L, 0L),
    line_colour = dplyr::if_else(
      ods_code == params$ods_intervention,
      "#f9bf07",
      adjustcolor("#9d928a", alpha.f = 0.5)
    )
  )

# conduct did analysis on the two matched services
did <-
  get_manual_did_estimation(
    df = df_analysis3,
    ods_intervention = params$ods_intervention,
    zoo_intervention = params$zoo_intervention_month
  )

# add to a combined summary (for sensitivity analysis)
did_overall <-
  dplyr::bind_rows(
    did_overall,
    did |>
      dplyr::mutate(specification = "Alternative 2 - use all 6 controls")
  )

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "CEM alternative 2 - use all 6 controls",
      outcome = did$outcome,
      estimate = did$estimate,
      se = did$std.error
    )
  )


# display as a table
did |> display_manual_did_results_as_gt()
```

This sensitivity analysis confirms the robustness of the main findings:

-   Outcome 1 continues to show no significant effect, and the estimate moves becomes more negative

-   Outcome 2 remains significantly and positively affected by the intervention, even when all controls are used regardless of whether they demonstrate parallel trends

#### Summary

```{r}
#| label: cem - sensitivity summary
#| cache: false
#| eval: false

# display a summary table of results
did_overall |>
  # simplify
  dplyr::select(
    specification,
    outcome,
    did = estimate,
    p.value,
    conf.low,
    conf.high
  ) |>
  # group by the sensitivity test
  dplyr::group_by(specification) |>
  gt::gt(row_group_as_column = TRUE) |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::fmt_percent(columns = c(did, conf.low, conf.high), decimals = 2) |>
  gt::cols_merge(columns = c(conf.low, conf.high), pattern = "{1} to {2}") |>
  gt::tab_style(
    style = list(gt::cell_text(weight = "bold")),
    locations = gt::cells_body(
      columns = c(did, conf.low),
      rows = p.value <= 0.05
    )
  ) |>
  gt::cols_hide(columns = p.value) |>
  gt::cols_label(
    outcome = "Outcome",
    did = "DiD estimate",
    conf.low = "95% confidence interval"
  ) |>
  gt::tab_source_note(gt::md(
    "Statistically significant findings are shown in **bold**"
  ))
```

These sensitivity tests **reinforce** the main findings.

-   **Outcome 1** Across all models, the DiD estimates for Outcome 1 are negative but small, and none are statistically significant.

-   **Outcome 2** All three models show a positive and statistically significant effect.

This pattern suggests that the intervention's impact on Outcome 2 is robust and potentially even stronger when accounting for more variation or confounding factors.

## Synthetic Difference-in-Differences (DiD)

The preceeding section highlights the challenges of finding genuine control services that closely match `r params$intervention_long_name`'s profile and satisfy the parallel-trends assumption. Because the estimated treatment effect proved sensitive to several analytical choices, we turn to alternative method: synthetic controls.

Synthetic Difference-in-Differences (Synthetic DiD) blends two ideas: the traditional difference-in-differences method and the synthetic control technique.

-   First it builds a "synthetic" version of the control group by assigning weights to untreated units so that, before the intervention, this synthetic group looks just like the treated unit.

-   Then it compares the outcomes after the intervention between the treated unit and its synthetic counterpart. By creating a better-matched control, Synthetic DiD helps produce more reliable estimates of a treatment's effect, especially when the parallel-trend assumption is weak.

The [{synthdid}](https://synth-inference.github.io/synthdid/) package was used to conduct these Synthetic DiD analyses. This uses the method described by [@arkhangelsky2019] to combine the strengths of synthetic-control weighting with the traditional DiD framework. According to the paper this technique delivers unbiased treatment-effect estimates, even when the parallel-trends assumption is violated.

In this approach we will build a 'donor pool' of all Talking Therapy services to create a synthetic counterfactual that estimates how `r params$intervention_long_name` would have performed without its interventions.

-   As with the earlier section, we first exclude any service that has its own adherence-improvement intervention

-   The {synthdid} package requires a balanced panel; every service in the donor pool must have data for every month from July 2022 through May 2025.

-   Consequently, any service with even a single missing month is dropped from the donor pool.

### Outcome 1

```{r}
#| label: synthdid - outcome 1
#| fig-height: 8
#| warning: false
#| cache: true
#| eval: false

# set up for the did analysis
set.seed(12345)
.yearmon_period = zoo::as.yearmon(c("Jul 2022", "Aug 2025"))
.yearmon_intervention = params$zoo_intervention_month

# get a dataset that is ready for synthetic DiD
df_synth <-
  prepare_df_for_synthdid(
    df = df,
    outcome = "o1_rate",
    yearmon_period = .yearmon_period,
    yearmon_intervention = .yearmon_intervention,
    ods_treated = params$ods_intervention,
    df_intervention_services = df_intervention_services
  )

# get the did estimate, confidence intervals and plot
did <-
  delegate_synthdid_analysis(
    df_synth = df_synth,
    .yearmon_intervention = .yearmon_intervention,
    .yearmon_period = .yearmon_period,
    .yearmon_scale_to = zoo::as.yearmon("Dec 2026"),
    .ods_treated = params$ods_intervention,
    str_treated = params$intervention_short_name,
    summary_spec = "Main model (baseline)",
    summary_outcome = "Outcome 1",
    str_outcome = "o1_rate",
    labs_title = "Outcome 1: discharges with 5+ treatment contacts"
  )

# add these findings to a combined summary (for sensitivity analysis)
did_overall <-
  did$did_summary

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "Synthdid main model (all controls)",
      outcome = "Outcome 1",
      estimate = as.numeric(did$did_estimate),
      se = did$did_se
    )
  )

# display the plot
did$did_plot
```

**What the chart displays**

+------------------------------+-------------------------------------------------------------------------------+-------------------------------------------+
| Element                      | Meaning                                                                       | Visual clue                               |
+==============================+===============================================================================+===========================================+
| Axes                         | Outcome performance (y-axis) vs time (x-axis)                                 | Standard Cartesian axes                   |
+------------------------------+-------------------------------------------------------------------------------+-------------------------------------------+
| Project's actual performance | Measured values for the project                                               | Orange solid line                         |
+------------------------------+-------------------------------------------------------------------------------+-------------------------------------------+
| Synthetic control            | Counterfactual series built from weighted pre-intervention data               | Blue solid line                           |
+------------------------------+-------------------------------------------------------------------------------+-------------------------------------------+
| Intervention start           | Point at which the project's interventions began                              | Vertical grey line                        |
+------------------------------+-------------------------------------------------------------------------------+-------------------------------------------+
| Pre-intervention weights     | Relative contribution of each pre-intervention month to the synthetic control | Pink shapes in the lower-left corner      |
+------------------------------+-------------------------------------------------------------------------------+-------------------------------------------+
| Parallelogram overlay        | Visual comparison of the two trajectories                                     | Blue-topped edge = synthetic control path |
|                              |                                                                               |                                           |
|                              |                                                                               | Dotted bottom edge = counterfactual path  |
|                              |                                                                               |                                           |
|                              |                                                                               | Orange line = project's actual trajectory |
+------------------------------+-------------------------------------------------------------------------------+-------------------------------------------+

: Chart key

**How to read the parallelogram**

-   Top edge (blue) - trajectory of the synthetic control from the pre- to post-intervention period

-   Bottom edge (dotted) - what `r params$intervention_long_name`'s trend would have looked like without any interventions (the counterfactual)

-   Orange line - `r params$intervention_long_name`'s observed post-intervention trend.

`r params$intervention_long_name`'s orange line rises more sharply than the dotted counterfactual, indicating a positive impact of the interventions. The estimated gain is 1.1% above the expected value. The 95% confidence interval spans -12% to + 15%, meaning the true effect could be negative or positive. Consequently, the result is not statistically significant.

#### Contribution plot

```{r}
#| label: synthdid - outcome 1 - contribution plot
#| fig-height: 5
#| warning: false
#| cache: true
#| eval: false

set.seed(12345)

synthdid::synthdid_units_plot(
  estimates = did$did_estimate,
  se.method = "placebo"
) +
  ggplot2::theme(axis.text.x = ggplot2::element_text(size = 5))
```

This plot shows:

-   The synthetic estimate as the black horizontal line

-   Each control Talking Therapy service as a point, where servicees that contribute more weight to the synthetic model shown in larger size

-   The grey horizontal lines represent the end points of a 95% confidence interval

A total of \<r length(summary(did$did_estimate)$controls)\> Talking Therapy services were used in the construction of this synthetic control.

### Outcome 2

```{r}
#| label: synthdid - outcome 2
#| fig-height: 8
#| warning: false
#| cache: true
#| eval: false

# set seed for reproducibility
set.seed(12345)

df_synth <-
  prepare_df_for_synthdid(
    df = df,
    outcome = "o2_rate",
    yearmon_period = .yearmon_period,
    yearmon_intervention = .yearmon_intervention,
    ods_treated = params$ods_intervention,
    df_intervention_services = df_intervention_services
  )

# get the did estimate, confidence intervals and plot
did <-
  delegate_synthdid_analysis(
    df_synth = df_synth,
    .yearmon_intervention = .yearmon_intervention,
    .yearmon_period = .yearmon_period,
    .yearmon_scale_to = zoo::as.yearmon("Dec 2026"),
    .ods_treated = params$ods_intervention,
    str_treated = params$intervention_short_name,
    summary_spec = "Main model (baseline)",
    summary_outcome = "Outcome 2",
    str_outcome = "o2_rate",
    labs_title = "Outcome 2: discharges achieving reliable recovery"
  )

# add these findings to a combined summary (for sensitivity analysis)
did_overall <-
  dplyr::bind_rows(
    did_overall,
    did$did_summary
  )

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "Synthdid main model (all controls)",
      outcome = "Outcome 2",
      estimate = as.numeric(did$did_estimate),
      se = did$did_se
    )
  )

# display the plot
did$did_plot
```

**How to read the parallelogram**

-   Top edge (dotted) - what `r params$intervention_long_name`'s trend would have looked like without any interventions (the counterfactual)

-   Bottom edge (blue) - trajectory of the synthetic control from the pre- to post-intervention period

-   Orange line - `r params$intervention_long_name`'s observed post-intervention trend.

`r params$intervention_long_name`'s orange line rises much more sharply than the dotted counterfactual, indicating an effect in the post-intervention period. The estimated difference is 6.1% above the expected value. The 95% confidence interval spans -1.2% to +13.5%, meaning the true effect could be negative or positive. Consequently, the result is **not statistically significant**.

#### Contribution plot

```{r}
#| label: synthdid - outcome 2 - contribution plot
#| fig-height: 5
#| warning: false
#| cache: true
#| eval: false

set.seed(12345)

synthdid::synthdid_units_plot(
  estimates = did$did_estimate,
  se.method = "placebo"
) +
  ggplot2::theme(axis.text.x = ggplot2::element_text(size = 5))
```

A total of \<r length(summary(did$did_estimate)$controls)\> Talking Therapy services were used in the construction of this synthetic control.

### Summary

```{r}
#| label: synthdid - summary table
#| cache: true
#| eval: false

did_overall |>
  display_did_summary_in_gt(sensitivity_summary = FALSE)
```

::: callout-tip
## Interpretation

```{r}
#| label: interpretation help synthdid
#| cache: true
#| eval: false

# work out the total discharges in 12 months preceeding
total_discharges <-
  df |>
  dplyr::filter(
    ods_code == params$ods_intervention,
    dplyr::between(
      calc_month,
      zoo::as.yearmon("Jun 2024"),
      zoo::as.yearmon("May 2025")
    )
  ) |>
  dplyr::summarise(
    total = sum(o1_denom_discharges_count, na.rm = TRUE)
  ) |>
  dplyr::pull(total)

# work out the expected number of people to benefit from the uplift
people_benefit_o1 <- floor(total_discharges * (1.1 / 100))
people_benefit_o2 <- floor(total_discharges * (6.1 / 100))
```

The charts indicate `r params$intervention_long_name`'s post-intervention performance exceeding the synthetic counterfactual, but the wide confidence interval prevents a definitive claim of effectiveness for both outcomes.

Assuming the 6.1% gain for Outcome 2 is real, it translates to an additional <r people_benefit_o2> people achieving reliable per year (based on `r params$intervention_long_name`'s annual discharge volume of \<r scales::comma(total_discharges)\> from June 2024 to May 2025).
:::

### Sensitivity analysis

In the previous analysis we supplied {synthdid} with the outcomes for *all* Talking Therapy services that were not involved in any known adherence-improving intervention. This full set served as the donor pool for constructing a counterfactual that best matches `r params$intervention_long_name`'s pre-intervention outcome trends.

We adopted this approach because synthetic-control methods require a reasonably large donor pool to generate a reliable weighted counterfactual. However, the propensity score matching and coarsened exact matching sections showed that the donor pool varies across our matching variables.

In this section we examine how restricting the donor pool influences the DiD estimates and assess whether our original conclusions remain robust or become sensitive to these restrictions.

#### Using matches from PSM

What impact does using the matches returned from the propensity score matching (PSM) section have?

```{r}
#| label: synthdid - sensitivity PSM - outcome 1
#| fig-height: 7
#| warning: false
#| cache: false
#| eval: false

set.seed(12345)

# get a did estimate
df_synth <-
  prepare_df_for_synthdid(
    df = df,
    outcome = "o1_rate",
    yearmon_period = .yearmon_period,
    yearmon_intervention = .yearmon_intervention,
    ods_treated = params$ods_intervention,
    ods_controls = controls$psm_all,
    df_intervention_services = df_intervention_services
  )

# get the did estimate, confidence intervals and plot
did <-
  delegate_synthdid_analysis(
    df_synth = df_synth,
    .yearmon_intervention = .yearmon_intervention,
    .yearmon_period = .yearmon_period,
    .yearmon_scale_to = zoo::as.yearmon("Dec 2026"),
    .ods_treated = params$ods_intervention,
    str_treated = params$intervention_short_name,
    summary_spec = "Alternative 1 - using all PSM matches",
    summary_outcome = "Outcome 1",
    str_outcome = "o1_rate",
    labs_title = "Outcome 1: discharges with 5+ treatment contacts"
  )

# add these findings to a combined summary (for sensitivity analysis)
did_overall <-
  dplyr::bind_rows(
    did_overall,
    did$did_summary
  )

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "Synthdid alternative 1 (PSM controls)",
      outcome = "Outcome 1",
      estimate = as.numeric(did$did_estimate),
      se = did$did_se
    )
  )

# display the plot
did$did_plot
```

`r params$intervention_long_name` performed 0.3% below the synthetic control expectation, however, the 95% confidence interval (-1.1% to 0.5%) includes zero so we cannot make any definitive claim.

```{r}
#| label: synthdid - sensitivity PSM - outcome 2
#| fig-height: 7
#| warning: false
#| cache: true
#| eval: false

set.seed(12345)

# get a did estimate
df_synth <-
  prepare_df_for_synthdid(
    df = df,
    outcome = "o2_rate",
    yearmon_period = .yearmon_period,
    yearmon_intervention = .yearmon_intervention,
    ods_treated = params$ods_intervention,
    ods_controls = controls$psm_all,
    df_intervention_services = df_intervention_services
  )

# get the did estimate, confidence intervals and plot
did <-
  delegate_synthdid_analysis(
    df_synth = df_synth,
    .yearmon_intervention = .yearmon_intervention,
    .yearmon_period = .yearmon_period,
    .yearmon_scale_to = zoo::as.yearmon("Dec 2026"),
    .ods_treated = params$ods_intervention,
    str_treated = params$intervention_short_name,
    summary_spec = "Alternative 1 - using all PSM matches",
    summary_outcome = "Outcome 2",
    str_outcome = "o2_rate",
    labs_title = "Outcome 2: discharges achieving reliable recovery"
  )

# add these findings to a combined summary (for sensitivity analysis)
did_overall <-
  dplyr::bind_rows(
    did_overall,
    did$did_summary
  )

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "Synthdid alternative 1 (PSM controls)",
      outcome = "Outcome 2",
      estimate = as.numeric(did$did_estimate),
      se = did$did_se
    )
  )

# display the plot
did$did_plot
```

`r params$intervention_long_name` performed 2% above the synthetic control expectation, and crucially, the 95% confidence interval (\>0% to 3.9%) narrowly does not include zero, which means this means this finding is **statistically significant**.

#### Using matches from CEM

What impact does using the matches returned from the coarsened exact matching (CEM) section have?

```{r}
#| label: synthdid - sensitivity CEM - outcome 1
#| fig-height: 7
#| warning: false
#| cache: true
#| eval: false

set.seed(12345)

# get a did estimate
df_synth <-
  prepare_df_for_synthdid(
    df = df,
    outcome = "o1_rate",
    yearmon_period = .yearmon_period,
    yearmon_intervention = .yearmon_intervention,
    ods_treated = params$ods_intervention,
    ods_controls = controls$cem_all,
    df_intervention_services = df_intervention_services
  )

# get the did estimate, confidence intervals and plot
did <-
  delegate_synthdid_analysis(
    df_synth = df_synth,
    .yearmon_intervention = .yearmon_intervention,
    .yearmon_period = .yearmon_period,
    .yearmon_scale_to = zoo::as.yearmon("Dec 2026"),
    .ods_treated = params$ods_intervention,
    str_treated = params$intervention_short_name,
    summary_spec = "Alternative 2 - using all CEM matches",
    summary_outcome = "Outcome 1",
    str_outcome = "o1_rate",
    labs_title = "Outcome 1: discharges with 5+ treatment contacts"
  )

# add these findings to a combined summary (for sensitivity analysis)
did_overall <-
  dplyr::bind_rows(
    did_overall,
    did$did_summary
  )

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "Synthdid alternative 2 (CEM controls)",
      outcome = "Outcome 1",
      estimate = as.numeric(did$did_estimate),
      se = did$did_se
    )
  )

# display the plot
did$did_plot
```

`r params$intervention_long_name`'s observed outcome was **1% lower** than the synthetic control expectation. Additionally, because the 95% confidence interval (-2% to 0.1%) does not include zero, the result is **statistically significant**.

```{r}
#| label: synthdid - sensitivity CEM - outcome 2
#| fig-height: 7
#| warning: false
#| cache: true
#| eval: false

set.seed(12345)

df_synth <-
  prepare_df_for_synthdid(
    df = df,
    outcome = "o2_rate",
    yearmon_period = .yearmon_period,
    yearmon_intervention = .yearmon_intervention,
    ods_treated = params$ods_intervention,
    ods_controls = controls$cem_all,
    df_intervention_services = df_intervention_services
  )

# get the did estimate, confidence intervals and plot
did <-
  delegate_synthdid_analysis(
    df_synth = df_synth,
    .yearmon_intervention = .yearmon_intervention,
    .yearmon_period = .yearmon_period,
    .yearmon_scale_to = zoo::as.yearmon("Dec 2026"),
    .ods_treated = params$ods_intervention,
    str_treated = params$intervention_short_name,
    summary_spec = "Alternative 2 - using all CEM matches",
    summary_outcome = "Outcome 2",
    str_outcome = "o2_rate",
    labs_title = "Outcome 2: discharges achieving reliable recovery"
  )

# add these findings to a combined summary (for sensitivity analysis)
did_overall <-
  dplyr::bind_rows(
    did_overall,
    did$did_summary
  )

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "Synthdid alternative 2 (CEM controls)",
      outcome = "Outcome 2",
      estimate = as.numeric(did$did_estimate),
      se = did$did_se
    )
  )

# display the plot
did$did_plot
```

`r params$intervention_long_name`'s observed outcome was **5.3% higher** than the synthetic control expectation. However, the 95% confidence interval (-3% to 13.5%) includes zero, so the result is not statistically distinguishable from no effect.

#### Summary

```{r}
#| label: synthdid - sensitivity - summary table
#| cache: true
#| eval: false

did_overall |>
  display_did_summary_in_gt(sensitivity_summary = TRUE)

# save a copy of the summary table for future meta-analyses
saveRDS(
  object = did_meta,
  file = here::here("data", "project", "did_estimates", "cornwall.Rds")
)
```

The main model's estimates are not statistically significant, but the alternatives reveal significant effects for at least one outcome each.

Both alternatives produce narrower confidence intervals, suggesting better model precision.

The sensitivity analysis suggest that the main model may be underpowered or imprecise. The choice of matching method materially affects the interpretation of treatment effects, especially for Outcome 1.

## Supplementary analysis

```{r}
#| label: supp - gather data
#| cache: false
supp1 <-
  delegate_supp_outcome_analysis(
    supp = "mutual_discharge",
    ods_intervention = params$ods_intervention,
    str_intervention = params$intervention_short_name,
    ods_controls = c("RAT"),
    zoo_intervention = params$zoo_intervention_month,
    zoo_period = zoo::as.yearmon(c("Jan 2022", "May 2025")),
    str_plot_subtitle = "No significant changes for either treatment intensity group"
  )

supp2 <-
  delegate_supp_outcome_analysis(
    supp = "reliable_recovery",
    ods_intervention = params$ods_intervention,
    str_intervention = params$intervention_short_name,
    ods_controls = c("RAT"),
    zoo_intervention = params$zoo_intervention_month,
    zoo_period = zoo::as.yearmon(c("Jan 2022", "May 2025")),
    str_plot_subtitle = "No significant changes for either treatment intensity group"
  )
```

To contextualise the results for out two primary outcomes, we conducted two supplementary analyses:

1.  **Mutual discharge agreement** - the proportion of discharges jointly agreed up by patient and therapist

2.  **Reliable recovery** - the proportion of discharges that met criteria for reliable recovery

For each measure we compared:

-   **Pre- vs post-intervention** periods (before and after `r params$intervention_long_name`'s interventions)

-   **Treatment intensity** groups: participants who received **\>= 5 contacts** versus those with **\< 5 contacts**

### Discharge by mutual agreement

On discharge from a Talking Therapy service, every client record must include a coded reason in the `EndCode` field. According to the [IAPT Techical Output Specification](https://digital.nhs.uk/data-and-information/information-standards/governance/latest-activity/standards-and-collections/dapb-1520-improving-access-to-psychological-therapies-data-set), there are 14 predefined categories for coding discharge reasons:

```{r}
#| label: supp - discharge codes
#| cache: true

readxl::read_xlsx(
  path = here::here("data", "reference", "iapt_tos_endcode.xlsx")
) |>
  dplyr::group_by(group) |>
  gt::gt(row_group_as_column = TRUE) |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  # label the columns
  gt::cols_label(
    code = "Code",
    description = "Definition"
  ) |>
  # highlight the code we are interested in
  # bold any statistically significant results
  gt::tab_style(
    # style = gt::cell_text(weight = "bold"),
    style = gt::cell_fill(color = "#fcdf83"),
    locations = gt::cells_body(
      # columns = gt::vars(group, statistic, p.value, parameter),
      columns = gt::any_of(c("code", "description")),
      rows = code == 46
    )
  ) |>
  # headings and footnotes
  gt::tab_header(
    title = "Discharge from Improving Access to Psychological Therapies Service Reason"
  ) |>
  gt::tab_source_note(
    "Details of `EndCode` codes from version 2.1 of the IAPT Technical Output Specification"
  )
```

This section analyses the proportion of referrals coded as **Mutually Agreed Completion of Treatment** (code 46), indicating that both the patient and therapist concurred that the course of therapy had been successfully completed. Consistent with the primary analyses, we limit the sample to referrals with at least two treatment contacts to ensure inclusion of people who entered a course of care.

Where data permits, we also examine referrals coded as **ended before the therapist planned** (code 47) and referrals that **ended earlier than the patient wanted** (code 48). Due to the requirements of the chi-squared analysis - which requires a minimum of five events per cell - these categories may be combined with 'Other codes' if referrals volumes are insufficient.

The bar chart below displays `r params$intervention_long_name`'s data only. Due to insufficient data, referrals that ended earlier than the patient desired have been grouped under 'Other codes'.

The chart highlights an **11.3 percentage point increase in mutually agreed discharges** among individuals who received five or more treatment contacts in the post-intervention period, compared to the pre-intervention period. This shift was accompanied by a 2.9 percentage point decrease in dishcarges initiated earlier than the care professional intended, and an 8.5 percentage point reduction in discharges grouped under 'Other codes'.

```{r}
#| label: supp - mutual - plot
#| cache: false
#| fig-height: 7
#| fig-width: 12

# display a bar chart
supp1$bar_plot

# display the chi-square test results
supp1$gt_chi2_results
```

The chi-squared test confirms that the observed changes are **statistically significant** across both treatment-intensity groups.

These findings suggest that the interventions measurable effects on the proportion of referrals completed through mutual agreement between patient and therapist.

### Achieving reliable recovery

This section assesses the proportion of referrals that attained *reliable recovery* after completing therapy.

Reliable recovery requires two conditions: 1) the patient's symptoms fall below the clinical threshold ('recovery'), and 2) the magnitude of symptom reduction exceeds the reliable index, indicating a change that is statistically meaningful.

As with the previous analysis, the bar chart shows only `r params$intervention_long_name`'s data. In indicates **a visible increase** in the proportion of discharged referrals achieving reliable recovery during the post-intervention period compared with the pre-intervention period.

```{r}
#| label: supp - recovery - plot
#| cache: true
#| fig-height: 4
#| fig-width: 12

# display a bar chart
supp2$bar_plot

# display the chi-square test results
supp2$gt_chi2_results
```

The chi-squared test confirms that the observed changes are **statistically significant** for the 5+ treatment contact intensity group.

These findings suggest that the interventions had a positive effect on the proportions of patients who achieved reliable recovery for those who received 5+ treatment contacts.

# Conclusions

We estimated the impact of `r params$intervention_long_name`'s interventions using two complimentary DiD approaches:

-   **Manual DiD** - `r params$intervention_long_name` was compared with 10 services selected through a coarsened exact matched (CEM) procedure

-   **Synthetic control DiD** - `r params$intervention_long_name` was contrasted with a synthetic counterfactual build from all available donor services.

For the CEM and synthetic approaches we performed a series of sensitivity checks, for example, expanding the control pool and changing the intervention start date and using different matching methods.

## Outcome 1

Across all three methods, the DiD estimates for Outcome 1 are small and statistically insignificant (confidence intervals include zero).

The direction of effect varies slightly; PSM and CEM both suggest a small negative effect, whereas SynthDiD suggests a small positive effect.

There is no robust evidence of a treatment effect on Outcome 1, and findings are sensitive to the matching method used.

## Outcome 2

All three methods show a positive DiD estimate for Outcome 2.

Only the CEM analysis yields a statistically significant result (confidence interval does not include zero), suggesting a 4.56% increase attributable to the intervention.

SynthDiD shows the largest point estimate (6.1%) but lacks precision (wide confidence interval).

There is **moderate evidence of a positive treatment effect on Outcome 2**, particularly when using CEM. This suggests the interventions may have improved the outcome, through results vary by method.

## Recommendations for future evaluation

To obtain a definitive assessment of `r params$intervention_long_name`'s digital-resource and communication interventions, a more rigorous experimental design is needed:

1.  Identify a cohort of comparable services using the matching variables described in this report

2.  Randomly assign half of the services to receive the full intervention package (FAQ pages, explanatory animations, assessment video, communication review, DNA rate tracking) and the other half to serve as controls

3.  Track outcomes prospectively over and adequate post-intervention horizon

4.  Analyust the data with a pre-registered DiD or mixed-effects model, complemented by placebo tests and robustness checks

Such a randomised controlled design would eliminate the donor-pool and specification sensitivities that currently limit inference, allowing a clear determination of whether `r params$intervention_long_name`'s interventions truly improve client preparation and engagement.

# Limitations

The limitations for this analysis include:

**Only one treated unit**

The causal estimate rests on a single time-series (`r params$intervention_long_name`). The result is that standard errors are large which translates to wide confidence intervals and a much larger treatment effect is required to reach statistical significance as a consequence.

**Possible hidden interventions in the donor pool**

We removed services with known interventions from the group of control services, but undisclosed changes may still be present.

Comparing `r params$intervention_long_name` to other services that are also improving attenuates the estimated effect, biasing the results toward zero.

**Time-varying confounders**

Two control services experienced abrupt shocks in mid-2023 which distorted the post-implementation average performance and synthetic control trajectory, increased variability and weakened the credibility of the counterfactual.

**No single treatment date**

`r params$intervention_long_name`'s rollout was staggered across several components and spread over twelve months. As a result the "treated" period is diffuse, making it difficult to define a clean pre-/post-intervention split and to isolate the effect of any one component.

**Synthetic control sensitivity to outliers**

The CEM-derived donor pool contained services with extreme spikes. Outliers can dominate the weighted synthetic control, producing unstable counterfactuals and potentially misleading effect sizes.

Taken together, these limitations suggest that the estimated impacts should be interpreted with caution and highlight the need for a more rigorous, preferably experimental, design in future evaluations.