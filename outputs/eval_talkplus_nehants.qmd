---
title: "NHS Talking Therapies"
subtitle: "Evaluation of interventions to improve adherence to therapy in *TalkPlus, North East Hampshire & Farnham*"
author: "Craig Parylo"
date: today

title-block-banner: '#151412'
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: true
    embed-resources: true
    fig-format: png
    fig-width: 10
    fig-height: 3
    fig-dpi: 600
    default-image-extension: svg
    lightbox: true
    editor: visual
    favicon: "favicon.ico"
    include-in-header:
      text: |
        <link rel="icon" type="image/x-icon" href="favicon.ico">
brand: _brand.yml
css: styles.css
bibliography: references.bib
execute:
  inline: false
---

```{r}
#| label: setup
#| context: setup
#| cache: false

# set up params (NB, the ones in YAML don't work well when running interactively)
params <- list(
  "ods_intervention" = "NCH",
  "intervention_long_name" = "TalkPlus, North East Hampshire & Farnham",
  "intervention_short_name" = "TalkPlus, NE Hants & Farnham",
  "download_from_teams" = FALSE,
  "zoo_intervention_month" = zoo::as.yearmon("Apr 2024")
)

# load in utility functions
source(here::here('scripts', 'utility_functions.R'))

# reference files ---
# get a list of projects that have implemented something to improve adherence
# part 1 - update the list of intervention projects (doesn't need updating everytime)
if (params$download_from_teams) {
  download_file_from_channel(
    str_path = "2. Project delivery/Project plan/TT projects.xlsx",
    str_dest = here::here(
      'data',
      'project',
      'tt_intervention_projects_copy.xlsx'
    )
  )
}
# part 2
df_intervention_services <- read_an_open_excel(
  path = here::here('data', 'project', 'tt_intervention_projects_copy.xlsx'),
  sheet = "intervention_projects"
)

# get a summary of interventions
df_interventions <- read_an_open_excel(
  path = here::here('data', 'project', 'tt_interventions_summary.xlsx'),
  sheet = 'interventions'
) |>
  dplyr::filter(iapt_code == params$ods_intervention) |>
  dplyr::mutate(calc_month = zoo::as.yearmon(month))

# load in matching variables
df <- get_matching_variables()

# load in variable labels
ls_labels <- get_variable_labels()
```

# Executive summary

This evaluation assessed whether a series of interventions introduced by `r params$intervention_long_name` improved therapy adherence and outcomes for patients in Talking Therapies.

While there are signals of benefit, especially for reliable recovery, the evidence is not strong or consistent enough to confirm effectiveness. A more rigorous evaluation design is needed to determine the true impact of these interventions.

**Outcomes measured**

-   Outcome 1: proportion of patients attending five or more treatment sessions.

-   Outcome 2: proportion of patients achieving reliable recovery

**Analytical methods**

-   Manual difference-in-differences (DiD) using matched services via Coarsened Exact Matching (CEM)

-   Synthetic DiD using weighted synthetic controls

-   Sensitivity analyses tested robustness by varying control groups and intervention start dates

**Key findings**

-   No statistically significant improvements were found for either outcome across models.

-   Outcome 2 showed modest positive effects in some models, but results were highly sensitive to analytical choices.

-   Outcome 1 showed slightly positive trends, but none reached statistical significance.

**Limitations**

-   Only one treated unit (TalkPlus), leading to wide confidence intervals.

-   Possible hidden interventions in control services.

-   Staggered rollout of interventions complicates analysis.

-   Synthetic control models are sensitive to outliers and tend to be more conservative in estimating standard error - which led to wider confidence intervals.

**Recommendations**

-   Conduct a randomised controlled trial (RCT) using matched services.

-   Randomly assign services to intervention or control groups.

-   Use pre-registered DiD or mixed-effects models with robustness checks.

# Project overview

## Interventions

This service implemented several improvements to patient information designed to better prepare people before they begin therapy.

```{r}
#| label: List of interventions
#| cache: true

df_interventions |>
  dplyr::select(month, intervention) |>
  dplyr::arrange(month) |>
  gt::gt() |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::fmt_date(columns = month, date_style = "yMMM") |>
  gt::cols_label(month = "Month", intervention = "Intervention") |>
  gt::cols_width(month ~ gt::pct(15)) |>
  gt::tab_header(
    title = "Interventions",
    subtitle = "Changes made by the service to better prepare clients for therapy"
  )
```

```{r}
#| label: Timeline of interventions
#| cache: true

# create a df holding details about the timeline
df_timeline <-
  df_interventions |>
  # make fields compatible with {timevis}
  dplyr::rename(content = intervention_html, start = month) |>
  # select essential details
  dplyr::select(content, start)

# display as a timeline
timevis::timevis(data = df_timeline, showZoom = FALSE)

```

<br> *Timeline view of interventions* <br>

In addition, the service implemented the following changes (without definite start dates, so are not included in this evaluation):

-   Discharge and Planning (DIPs) Process - the team embedded a new process to manage disengagement, giving patients 28 days to re-engage after missed appointments.

## Outcomes

Two outcome measures have been used in this evaluation:

1.  The proportion of discharged referrals where the patient attended five or more treatment sessions

2.  The proportion of discharged referrals that achieved reliable recovery.

These measures follow the numerator and denominator definitions, below.

+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Item               | Definition                                                                                                                                                                                                                                                            |
+====================+=======================================================================================================================================================================================================================================================================+
| Measure            | The proportion of discharged referrals each month where the patient attended five or more treatment sessions.                                                                                                                                                         |
+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Numerator          | Those in the denominator who attended five or more treatment care contacts during their referral^[1](#fn1)^                                                                                                                                                           |
+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Denominator        | Referrals ending each month where the patient received at least two treatment contacts ^[2](#fn2)^                                                                                                                                                                    |
+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Rationale          | This denominator represents monthly discharges for referrals that began a course of therapy.                                                                                                                                                                          |
|                    |                                                                                                                                                                                                                                                                       |
|                    | The numerator is the subset who attended at least five treatment contacts. Recent research identifies five sessions as a minimum associated with greater likelihood of achieving reliable recovery, so this group are those more likely to achieve reliable recovery. |
|                    |                                                                                                                                                                                                                                                                       |
|                    | This measure therefore captures discharged referrals each month that demonstrate sufficient adherence to have at least 50% likelihood of reliable recovery.                                                                                                           |
+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Expected variation | We expect this measure to **increase** as a result of interventions that improve adherence with therapy.                                                                                                                                                              |
+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

: Outcome measure 1

<aside id="footnotes" class="footnotes footnotes-end-of-block" role="doc-footnote">

<ol>

<li id="fn1">

<p>This count will be obtained from the field ‘TreatmentCareContact_Count’ (object I101D29) from the table ‘IDS101Referral’<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p>

</li>

<li id="fn2">

<p>This count will be obtained from the field ‘TreatmentCareContact_Count’ (object I101D29) from the table ‘IDS101Referral’<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p>

</li>

</ol>

</aside>

+--------------------+--------------------------------------------------------------------------------------------------------------------------+
| Item               | Description                                                                                                              |
+====================+==========================================================================================================================+
| Measure            | The proportion of referrals that achieved reliable recovery                                                              |
+--------------------+--------------------------------------------------------------------------------------------------------------------------+
| Numerator          | Of the denominator, those who achieved Reliable recovery^[1](#fn1)^                                                      |
+--------------------+--------------------------------------------------------------------------------------------------------------------------+
| Denominator        | Referrals ending each month where the patient received at least two treatment contacts ^[2](#fn2)^                       |
+--------------------+--------------------------------------------------------------------------------------------------------------------------+
| Rationale          | This measure identifies referrals that attained the target outcome of reliable recovery.                                 |
|                    |                                                                                                                          |
|                    | It serves to evaluate whether changes in this outcome align with the shifts observed in the process measure (Outcome 1). |
+--------------------+--------------------------------------------------------------------------------------------------------------------------+
| Expected variation | We expect this measure to **increase** as a result of interventions that improve adherence with therapy.                 |
+--------------------+--------------------------------------------------------------------------------------------------------------------------+

: Outcome measure 2

<aside id="footnotes" class="footnotes footnotes-end-of-block" role="doc-footnote">

<ol>

<li id="fn1">

<p>Defined as both <code>ReliableImprovement_Flag = `True`</code> <strong>and</strong> <code>Recovery_Flag = `True`</code><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p>

</li>

<li id="fn2">

<p>This count will be obtained from the field ‘TreatmentCareContact_Count’ (object I101D29) from the table ‘IDS101Referral’<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p>

</li>

</ol>

</aside>

## Matching variables

Since no consensus exists on predictors of therapy adherence, a [literature search](https://github.com/The-Strategy-Unit/talking_therapies/blob/main/data/reference/lit_search.xlsx) identified plausible variables. These were shortlisted based on feasibility of measurement in the IAPT dataset.

The selected factors, listed below, are mostly expressed as proportions of either referrals or care contacts. Aggregating patient-level data into these proportions represents the overall Talking Therapies service and makes the variables more suitable for the matching process.

Outcome measure:

-   Proportion of referrals that have completed treatment, but where the patient did not attend at least five treatment sessions.

Demographic characteristics:

-   Proportion of referrals for people aged 25 years and younger at referral

-   Proportion of referrals for people aged 60 years and older at referral

-   Proportion of referrals for people whose gender identity is female

-   Proportion of referrals for people whose LSOA of residence is among the 20% most deprived in England

-   Proportion of referrals for people whose LSOA of residence is among the 20% least deprived in England

-   Proportion of referrals for people whose broad ethnic background is 'White'

Therapist and service characteristics:

-   Proportion of care contacts where the therapist has attained an NHS TT qualification

-   Proportion of care contacts conducted on hospital premises

-   Proportion of care contacts conducted face-to-face

-   Proportion of care contacts outside of weekdays, 9am to 5pm

-   Proportion of care contacts delivered as internet enabled therapy

-   Proportion of care contacts delivered to an individual patient

-   Proportion of referrals where the referral-to-treatment wait time was within six weeks

-   Proportion of referrals where there was step-up to high-intensity therapy

Language and accessibility:

-   Proportion of care contacts conducted in English

-   Proportion of care contacts conducted with an interpreter present

A draft version of these matching variables was shared by email with members of the NHS Talking Therapies (TT) and Individual Placement and Support (IPS) National Programme Delivery Group for review in July 2025. The list above has since been augmented based on feedback.

## Outcomes for TalkPlus, North East Hampshire & Farnham

`r params$intervention_long_name` discharges data is available from the beginning of 2022 with the most recent data point being June 2025.

```{r}
#| label: project discharges time series
#| fig-height: 7
#| cache: true

df |>
  dplyr::filter(ods_code == params$ods_intervention) |>
  ggplot2::ggplot(
    mapping = ggplot2::aes(
      x = calc_month,
      y = o1_denom_discharges_count
    )
  ) +
  # add an arrow and text pointing to start of regular activity
  ggplot2::annotate(
    geom = "segment",
    x = zoo::as.yearmon("Apr 2021"),
    xend = zoo::as.yearmon("Nov 2021"),
    y = 260,
    yend = 260,
    colour = "#5881c1",
    arrow = ggplot2::arrow(type = "closed", length = ggplot2::unit(0.2, "cm"))
  ) +
  ggplot2::annotate(
    geom = "text",
    x = zoo::as.yearmon("Mar 2021"),
    y = 260,
    label = "Discharges begin",
    hjust = 1,
    colour = "#5881c1"
  ) +
  # add in the rest of the plot
  ggplot2::geom_line() +
  ggplot2::geom_point() +
  ggplot2::theme_minimal(base_size = 20) +
  ggplot2::theme(axis.title.x = ggplot2::element_blank()) +
  ggplot2::labs(
    title = params$intervention_long_name,
    subtitle = stringr::str_wrap(
      "Referral discharges begin with regular frequency from January 2022",
      60
    ),
    # x = "",
    y = "Number of discharges"
  )
```

Focusing on the period January 2022 to June 2025, the time series for each of the outcome variables is shown below. Each plot includes a trendline in [orange]{style="color: #f9bf07;"} and a dotted line in [blue]{style="color: #5881c1;"} indicating when each of the interventions was started.

```{r}
#| label: project outcome 1
#| fig-height: 7
#| cache: true

# filter the data for the project and a suitable timeframe
df_temp <-
  df |>
  dplyr::filter(
    ods_code == params$ods_intervention,
    dplyr::between(
      x = calc_month,
      left = zoo::as.yearmon("Jan 2022"),
      right = zoo::as.yearmon("Jun 2025")
    )
  )

# get a rate of increase for outcome 1
lm_temp <-
  lm(
    formula = o1_rate ~ calc_month,
    data = df_temp
  )

# extract as a variable
rate_per_year <-
  lm_temp |>
  broom::tidy() |>
  dplyr::filter(term == "calc_month") |>
  dplyr::pull(estimate) |>
  round(3)

# plot
df_temp |>
  plot_outcomes_over_time(
    df_interventions = df_interventions,
    var_outcome = "o1_rate",
    trendline = TRUE,
    interventions = TRUE,
    title = params$intervention_long_name,
    subtitle = stringr::str_wrap(
      string = glue::glue(
        "Outcome 1 shows an overall upward trend between 2022 and 2025, at a rate of {scales::percent(rate_per_year, accuracy = 0.1)} per year"
      ),
      width = 50
    )
  )
```

```{r}
#| label: project outcome 2
#| fig-height: 7
#| cache: true

# get a rate of increase for outcome 2
lm_temp <-
  lm(
    formula = o2_rate ~ calc_month,
    data = df_temp
  )

# extract as a variable
rate_per_year <-
  lm_temp |>
  broom::tidy() |>
  dplyr::filter(term == "calc_month") |>
  dplyr::pull(estimate) |>
  round(3)

# plot
df_temp |>
  plot_outcomes_over_time(
    df_interventions = df_interventions,
    var_outcome = "o2_rate",
    trendline = TRUE,
    interventions = TRUE,
    title = params$intervention_long_name,
    subtitle = stringr::str_wrap(
      string = glue::glue(
        "Outcome 2 shows an overall upward trend between 2022 and 2025, at a rate of {scales::percent(rate_per_year, accuracy = 0.1)} per year"
      ),
      width = 50
    )
  )
```

The matching process will use data from the eleven-month period preceding `r params$intervention_long_name` first intervention, specifically from January 2022 to November 2022. This pre-intervention period provides a stable baseline for matching services, ensuring that the comparison is conducted before any intervention effects could potentially influence the data.

# National outcome trends

We will first look at the national trends for our two outcome measures.

The next two charts include only months in which each services recorded at least 100 discharges. This filter removes unreliable rates that can arise from newly launched services or months with very few discharges.

```{r}
#| fig-height: 7
#| label: outcome 1 national trend
#| cache: true

# filter the data to make it easier to use
df_temp <-
  df |>
  dplyr::filter(
    # limit to the start of activity and exclude latest point
    dplyr::between(
      calc_month,
      zoo::as.yearmon("Jan 2022"),
      zoo::as.yearmon("May 2025")
    ),
    # limit to months where each service has more than 100 discharges to avoid spurious rates
    o1_denom_discharges_count > 100
  )

# linear model
lm_temp <-
  lm(
    formula = o1_rate ~ calc_month,
    data = df_temp
  )
# extract as a variable
rate_per_year <- lm_temp |>
  broom::tidy() |>
  dplyr::filter(term == "calc_month") |>
  dplyr::pull(estimate) |>
  round(3)

# get average rates per month
df_summary_per_month <-
  df_temp |>
  dplyr::summarise(
    o1_rate_av = mean(o1_rate, na.rm = TRUE),
    o1_rate_sd = sd(o1_rate, na.rm = TRUE),
    o2_rate_av = mean(o2_rate, na.rm = TRUE),
    o2_rate_sd = sd(o2_rate, na.rm = TRUE),
    .by = c(calc_month)
  ) |>
  dplyr::arrange(calc_month)

# show a spaghetti plot of all TT services over time
ggplot2::ggplot() +
  # add traces for each individual TT service
  ggplot2::geom_line(
    data = df_temp,
    mapping = ggplot2::aes(
      x = calc_month,
      y = o1_rate,
      group = ods_code
    ),
    colour = adjustcolor("#9d928a", alpha.f = 0.3),
    linewidth = 0.5
  ) +
  # add a ribbon of +/- one sd to show spread
  ggplot2::geom_ribbon(
    data = df_summary_per_month,
    mapping = ggplot2::aes(
      x = calc_month,
      ymin = (o1_rate_av - o1_rate_sd),
      ymax = (o1_rate_av + o1_rate_sd)
    ),
    fill = adjustcolor("#f9bf07", alpha.f = 0.2)
  ) +
  # add a trendline
  ggplot2::geom_smooth(
    data = df_temp,
    mapping = ggplot2::aes(x = calc_month, y = o1_rate),
    method = "lm",
    formula = y ~ x, # made explicit to avoid console messages
    se = FALSE,
    colour = adjustcolor("#2c2825", alpha.f = 1),
    linetype = "dotted"
  ) +
  ggplot2::scale_y_continuous(labels = scales::label_percent(accuracy = 1)) +
  zoo::scale_x_yearmon() +
  ggplot2::theme_minimal(base_size = 20) +
  ggplot2::theme(
    axis.title = ggplot2::element_blank()
  ) +
  ggplot2::labs(
    title = "Outcome 1: discharges with 5+ treatment contacts",
    subtitle = glue::glue(
      "National trend since 2022 is upwards at a rate of {rate_per_year * 100}% per year"
    )
  )
```

**What the chart shows:**

-   Each grey line traces a single Talking Therapy service's monthly performance on outcome 1 (percentage of dishcarged referrals that received at least five treatment contacts).

-   The dotted line is a linear regression that captures the overall trend across all services.

-   The yellow band around the dotted line marks ± 1 standard deviation, illustrating the typical spread of service-level rates.

Nationally, the proportion of referrals meeting the 5-contact threshold has risen by around 1.6% per year, climbing from \~57% in Jan 2022 to \~ 62% in May 2025. Monthly results are highly variable; some services approach 100% in certain months, while others fall to near 0%, especially during mid-to-late 2023 when several services achieved 0% in several months.

The upward national trend indicates overall improvement, but the wide dispersion (yellow band) shows that individual services experience very different outcomes, highlighting opportunities for targeted support.

```{r}
#| fig-height: 7
#| label: outcome 2 national trend
#| warning: false
#| cache: true

# linear model
lm_temp <-
  lm(
    formula = o2_rate ~ calc_month,
    data = df_temp
  )
# extract as a variable
rate_per_year <- lm_temp |>
  broom::tidy() |>
  dplyr::filter(term == "calc_month") |>
  dplyr::pull(estimate) |>
  round(3)

# show a spaghetti plot of all TT services over time
ggplot2::ggplot() +
  # add traces for each individual TT service
  ggplot2::geom_line(
    data = df_temp,
    mapping = ggplot2::aes(
      x = calc_month,
      y = o2_rate,
      group = ods_code
    ),
    colour = adjustcolor("#9d928a", alpha.f = 0.3),
    linewidth = 0.5
  ) +
  # add a ribbon of +/- one sd to show spread
  ggplot2::geom_ribbon(
    data = df_summary_per_month,
    mapping = ggplot2::aes(
      x = calc_month,
      ymin = (o2_rate_av - o2_rate_sd),
      ymax = (o2_rate_av + o2_rate_sd)
    ),
    fill = adjustcolor("#f9bf07", alpha.f = 0.2)
  ) +
  # add a trendline
  ggplot2::geom_smooth(
    data = df_temp,
    mapping = ggplot2::aes(x = calc_month, y = o2_rate),
    method = "lm",
    formula = y ~ x, # made explicit to avoid console messages
    se = FALSE,
    colour = adjustcolor("#2c2825", alpha.f = 1),
    linetype = "dotted"
  ) +
  ggplot2::scale_y_continuous(labels = scales::label_percent(accuracy = 1)) +
  zoo::scale_x_yearmon() +
  ggplot2::theme_minimal(base_size = 20) +
  ggplot2::theme(
    axis.title = ggplot2::element_blank()
  ) +
  ggplot2::labs(
    title = "Outcome 2: discharges achieving reliable recovery",
    subtitle = glue::glue(
      "National trend since 2022 is upwards at a rate of {rate_per_year * 100}% per year"
    )
  )
```

**What the chart shows:**

-   Each grey line traces a single Talking Therapy service's monthly performance on outcome 2 (percentage of dishcarged referrals that received between 2 and 4 treatment contacts).

-   The dotted line is a linear regression that captures the overall trend across all services.

-   The yellow band around the dotted line marks ± 1 standard deviation, illustrating the typical spread of service-level rates.

The national share of these referrals has been increasing at a rate of 0.2% per year since 2022. Some services report low rates for this outcome each month, indicating most of their completed cases do not achieve reliable recovery. Other services show over 50% of completed referrals achieving reliable recovery which exceeds the national ambition to achieve 50% reliable recovery in Talking Therapy referrals.

While the overall picture is improving, the wide spread among individual services suggests targeted interventions are needed to help the higher-percentage providers move more referrals toward the five-contact benchmark.

# Matching variables

The aim of matching is to pair our intervention Talking Therapies service, `r params$intervention_long_name`, with one more untreated services that have similar charactersitics, creating a comparison group that mimics a randomised experiment. This reduces bias and makes it easier to estimate the intervention's effect from observational data.

## Using all matching variables - March 2024

The dataset is cut off at March 2024, the month immediately before `r params$intervention_short_name` launched its first interventions - 'One-at-a-time' sessions and training for the administrative team. This pre-intervention slice will serve as the basis for the matching process.

In the initial matching run we include all matching variables and specify five nearest neighbour services. Using several candidates increases the chance of finding one service that meets the parallel-trends assumption.

```{r}
#| label: matching_all_vars
#| fig-height: 9
#| cache: true

# get a list of matching vars
temp_vars <- stringr::str_subset(string = names(df), pattern = "^m.*_rate$")

# prepare the data
df_prep <-
  df |>
  # keep just the variables of interest
  dplyr::select(
    c(
      ods_code,
      name,
      calc_month,
      dplyr::contains("o1_denom"),
      dplyr::contains("_rate")
    )
  ) |>
  # flag records for the intervention service
  dplyr::mutate(
    flag_intervention = ods_code %in% params$ods_intervention
  ) |>
  dplyr::filter(
    # keep services that have data for all the matching variables
    dplyr::if_all(
      .cols = temp_vars,
      .fns = ~ !is.na(.)
    ),
    # keep services that have activity up to June 2025
    max(calc_month, na.rm = TRUE) >= zoo::as.yearmon("Jun 2025"),
    # keep services that have activity in each of the matching yearmonths
    # all(yearmons_matching %in% calc_month),
    # exclude other services that have implemented an intervention
    (ods_code == params$ods_intervention | flag_intervention == 0),
    .by = ods_code
  ) |>
  # shorten the 'o1_denom' variable name
  dplyr::rename("o1_denom" = o1_denom_discharges_count) |>
  # limit to just month before the interventions began
  dplyr::filter(calc_month == params$zoo_intervention_month - 1 / 12)

# string wrap variable names to better fit the plot
ls_labels_wrap <-
  purrr::modify_if(
    .x = ls_labels,
    .p = is.character,
    .f = ~ stringr::str_wrap(string = .x, width = 50)
  )

# set the matching formula
formula_matching <-
  formula(
    paste0(
      "flag_intervention ~ ",
      paste0(
        stringr::str_subset(
          string = names(df_prep),
          pattern = "^m.*_rate$"
        ),
        collapse = " + "
      )
    )
  )

# do the matching
obj_matches <-
  MatchIt::matchit(
    data = df_prep,
    formula = formula_matching,
    distance = "glm",
    method = "nearest",
    ratio = 5,
  )

# review the covariate balance
cobalt::love.plot(
  x = obj_matches,
  abs = TRUE,
  thresholds = 0.1,
  var.names = ls_labels_wrap,
  stars = "raw",
  drop.distance = TRUE
) +
  ggplot2::theme_minimal(base_size = 16) +
  ggplot2::scale_colour_manual(
    values = c("Unadjusted" = "#ec6555", Adjusted = "#5881c1")
  )

```

There are three warning messages displayed. The first two warning messages come from the propensity score matching process and likely indicate issues such as perfect separation of the data, or multicollinearity, which break key logistic regression assumptions. The third warning message comes from the process to visualise the model.

Reviewing the data reveals possible causes:

-   M14 Proportion of contacts conducted in English - the asterisk means the 'raw' score is displayed rather than absolute standardised mean differences the rest of the variables are displayed in

-   M5 Proportion of discharges for people living in 20% most deprived areas and M6 Proportion of discharges for people leaving in 20% least deprived areas both show large standardised differences.

Clearly, using all these matching variables is problematic. Let's investigate further

## Examining matching variables

### Pre-matching assessment

First let us see the level of balance in the matching variables before any matching occurs:

```{r}
#| label: pre-matching covariate balance
#| cache: true

# set the matching formula
formula_matching <-
  formula(
    paste0(
      "flag_intervention ~ ",
      paste0(
        c(
          stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
          stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
        ),
        collapse = " + "
      )
    )
  )

# check the balance prior to matching
set.seed(123)
match_pre <-
  MatchIt::matchit(
    formula = formula_matching,
    data = df_prep,
    method = NULL
    # distance = 'glm'
  ) |>
  summary()

t <-
  match_pre$sum.all |>
  tibble::as_tibble(rownames = "Matching variable") |>
  # exclude the distance metric - it isn't very useful here
  dplyr::filter(`Matching variable` != "distance") |>
  # drop the var. ratio and std. pair dist measures as they're not useful as the model doens't resolve
  dplyr::select(-c(`Var. Ratio`, `Std. Pair Dist.`)) |>
  gt::gt() |>
  gt::fmt_number(
    columns = gt::everything(),
    decimals = 4
  ) |>
  gt::data_color(
    columns = c(`Std. Mean Diff.`),
    method = "numeric",
    palette = "#f5b2aa",
    rows = abs(`Std. Mean Diff.`) < 0.1
  ) |>
  gt::tab_options(quarto.disable_processing = TRUE)
t
```

This table lists each matching variable together with its average value for `r params$intervention_long_name` (the treated group) and for all other donor services (the control group).

Our goal is to identify variables that show large differences, because those are the ones that the matching process can potentially improve. Variables with a standardised mean difference less than 0.1 are highlighted in pink. Variables which are uncoloured indicate where we could increase similarity between the treated and control groups.

Variables with less than 0.1 difference are less promising for improvement. In this case, `m3_rate` (Proportion of discharges for people aged 60 years and older at referral), `m12_rate` (Proportion of contacts conducted face-to-face) and `m14_rate` (M14 Proportion of contacts conducted in English).

Recommendation: drop `m3_rate`, `m12_rate` and `m14_rate` from the matching process as there is little scope to improve balance on these variables.

### Multicollinearity

Multicollinearity occurs when two or more matching variables are highly linearly related. Because such variables convey overlapping information, the matching process struggles to calculate reliable propensity scores.

In this section we identify strongly related matching variables using the Variance Inflation Factor (VIF). VIF measures how much a variable is linearly related to the others; higher values indicate stronger multicollinearity.

-   A VIF between 5 and 10 is often considered a warning sign. In the table below these are highlighted in yellow.
-   A VIF greater than 10 is strongly signals multicollinearity. Variables with such high VIF values should be excluded from the model. In the table below, any variable whose VIF exceeds 10 is highlighted in pink to flag a potential problem.

```{r}
#| label: multicollinearity - step 1
#| cache: true

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(matching_vars, c("m3_rate", "m12_rate", "m14_rate"))
t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

In this table, `m13_rate` (the proportion of contacts conducted outside of weekdays, 9am to 5pm) has the highest VIF of 114, far exceeding the usual threshold.

**Next step:** evaluate the impact of removing `m13_rate` from the matching model, as its extreme multicollinearity may distort the matching process.

```{r}
#| label: multicollinearity - step 2
#| cache: true

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(
  matching_vars,
  c("m3_rate", "m12_rate", "m14_rate", "m13_rate")
)
t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

After dropping `m13_rate`, the VIF table shows lower multicollinearity overall, but a few variables still exceed the VIF \> 10 threshold. The highest remaining VIF belongs to `m5_rate` (proportion of discharges for people living in 20% most deprived areas).

**Next step:** remove `m5_rate` from the matching model and re-run the VIF analysis to determine whether the remaining values fall below the high-VIF threshold and to assess any changes.

```{r}
#| label: multicollinearity - step 3
#| cache: true

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(
  matching_vars,
  c("m3_rate", "m12_rate", "m14_rate", "m13_rate", "m5_rate")
)
t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

After excluding `m5_rate`, nine variables still show VIF \> 10. The highest of these is `m2_rate` (proportion of discharges for people aged under 26 years at referral).

**Next step:** drop `m2_rate` from the matching model and recompute the VIFs to verify whether the remaining variables now fall below the high-VIF threshold.

```{r}
#| label: multicollinearity - step 4
#| cache: true

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(
  matching_vars,
  c("m3_rate", "m12_rate", "m14_rate", "m13_rate", "m5_rate", "m2_rate")
)
t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

Removing `m2_rate` resulted in lower overall VIF scores, however the model fails to resolve so we should continue with the variable assessment. The highest of these is for `m10_rate` (proportion of contacts conducted where there was a qualified therapist present).

**Next step:** remove `m10_rate` from the set of matching covariates and re-estimate the propensity scores and check whether the model stabilises.

```{r}
#| label: multicollinearity - step 5
#| cache: true

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(
  matching_vars,
  c(
    "m3_rate",
    "m12_rate",
    "m14_rate",
    "m13_rate",
    "m5_rate",
    "m2_rate",
    "m10_rate"
  )
)
t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

After dropping `m17_rate`, five variables now exceed the VIF \> 10 threshold. The highest remaining VIF belongs to `m8_rate` (proportion of discharges for people who had a referral-to-treatment time within six weeks).

**Next step:** remove `m8_rate`from the set of matching covariates and re-estimate the propensity scores and check whether the model stabilises.

```{r}
#| label: multicollinearity - step 6
#| cache: true

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(
  matching_vars,
  c(
    "m3_rate",
    "m12_rate",
    "m14_rate",
    "m13_rate",
    "m5_rate",
    "m2_rate",
    "m10_rate",
    "m8_rate"
  )
)
t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

After dropping `m8_rate`, the VIF table shows lower multicollinearity overall, but two variables still exceed the VIF \> 10 threshold. The highest remaining VIF belongs to `o1_denom` (number of discharges for referrals that were taken on for treatment).

**Next step:** drop `o1_denom` and re-run the model.

```{r}
#| label: multicollinearity - step 7
#| cache: true

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(
  matching_vars,
  c(
    "m3_rate",
    "m12_rate",
    "m14_rate",
    "m13_rate",
    "m5_rate",
    "m2_rate",
    "m10_rate",
    "m8_rate",
    "o1_denom"
  )
)
t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

Removing `o1_denom` uncovered high VIF scores for six matching covariates. The highest of these is for `m6_rate` (proportion of discharges for people living in the 20% least deprived areas).

**Next step:** drop `m6_rate` and re-run the model.

```{r}
#| label: multicollinearity - step 8
#| cache: true

# define which vars to include in this process
matching_vars <- c(
  stringr::str_subset(string = names(df_prep), pattern = "^o.*_denom$"),
  stringr::str_subset(string = names(df_prep), pattern = "^m.*_rate$")
)
# exclude those we don't want
matching_vars <- setdiff(
  matching_vars,
  c(
    "m3_rate",
    "m12_rate",
    "m14_rate",
    "m13_rate",
    "m5_rate",
    "m2_rate",
    "m10_rate",
    "m8_rate",
    "o1_denom",
    "m6_rate"
  )
)

t <- get_vif_score_table(matching_vars = matching_vars, df = df_prep)
t
```

After dropping `m6_rate`, the VIF table now shows that all remaining variables are within threshold, however, the model still fails to converge.

The list of matching variables attained following this process is:

```{r}
#| label: multicollinearity - final list of variables
#| cache: true
# get the list of variables in a tibble

df_matching_var_labels <-
  tibble::tibble(
    variable = names(ls_labels),
    description = unlist(ls_labels, use.names = FALSE)
  ) |>
  dplyr::filter(variable %in% matching_vars)

# present as a {gt} table
df_matching_var_labels |>
  gt::gt() |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::cols_label(
    variable = "Variable name",
    description = "Variable description"
  )
```

This means we cannot proceed with propensity score matching and will proceed to another method, coarsened exact matching.

# Analysis

## Coarsened exact matching - March 2024

Coarsened Exact Matching (CEM) offers an alternative approach to propensity score matching. First, each variable is grouped into broader categories (e.g., 0-19%, 20-39%, 40-59%, etc.). Then Talking Therapy services are matched **exactly** on these coarsened bins.

The key advantage is that balance on the matching variables is guaranteed within each bin. The researcher controls the trade-off by choosing the width of the categories:

-   Narrower bins - tighter similarity between matched services but fewer matches

-   Wider bins - more matches but less precise similarity

The same matching variables selected from the multicollinearity optimisation process will be used. We will start with five cutpoints to divide each matching variable into six separate bins.

```{r}
#| label: coarsened exact matching
#| fig-height: 8
#| message: FALSE
#| cache: true

# set the matching formula
formula_matching <-
  formula(
    paste0(
      "flag_intervention ~ ",
      paste0(matching_vars, collapse = " + ")
    )
  )

# do the matching
obj_matches <-
  MatchIt::matchit(
    data = df_prep,
    formula = formula_matching, # using the same formula as determined by VIF analysis
    method = "cem",
    cutpoints = 5
  )

# review the covariate balance
cobalt::love.plot(
  x = obj_matches,
  abs = TRUE,
  thresholds = 0.2,
  var.names = ls_labels_wrap,
  stars = "raw",
  var.order = "unadjusted"
) +
  ggplot2::theme_minimal(base_size = 16) +
  ggplot2::scale_colour_manual(
    values = c("Unadjusted" = "#ec6555", Adjusted = "#5881c1")
  )
```

These results show the matched services as close, but not perfect, matches for `r params$intervention_long_name`.

After matching, most variables show improved similarity (the blue points are nearer to 0 than the red points) and six variables are within the 0.2 SMD threshold, though one of these was already within this range prior to matching.

Applying five cut-points allowed the CEM procedure to match `r params$intervention_long_name` with 12 Talking Therapy services. When we increased the number of cut-points to six - intended to boost sensitivity - only four matches were found.

The 12 matched services found using using five cut-points are:

```{r}
#| label: coarsened exact matches
#| fig-height: 8
#| cache: true

matches <- MatchIt::match_data(obj_matches)

# show in a table
matches |>
  dplyr::select(name, ods_code) |>
  dplyr::mutate(
    ods_code = ods_code |>
      as.factor() |>
      forcats::fct_relevel(params$ods_intervention)
  ) |>
  dplyr::arrange(ods_code) |>
  gt::gt() |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::data_color(
    columns = gt::everything(),
    rows = ods_code == params$ods_intervention,
    palette = "#f9bf07"
  ) |>
  gt::cols_label(
    name = "Talking Therapies organisation",
    ods_code = "ODS code"
  )

# plots comparing each matched service
plot_list <-
  purrr::map(
    .x = stringr::str_subset(
      string = matches$ods_code,
      pattern = params$ods_intervention,
      negate = TRUE
    ),
    .f = \(.x) {
      p <-
        compare_matches_preintervention(
          df = df,
          selected_ods = c(params$ods_intervention, .x),
          period_preintervention = zoo::as.yearmon(c("Jan 2022", "Mar 2024")),
          trendline = TRUE
        )
      return(p)
    }
  )
```

### Parallel trends assumption

We now assess the parallel trends for `r params$intervention_long_name` (shown in orange) and each of the 20 matched Talking Therapy services (shown in grey). Trendlines are overlaid on each plot to make it easier to judge whether the series move together.

#### Sign Health (HQ) AM7

**Outcome 1:** ✔️ The trends are parallel

**Outcome 2:** ✔️ The trends are almost parallel, there is a hint of divergence but overall a close match

```{r}
#| label: cem - sign health
#| fig-height: 8
#| cache: true

plot_list[[1]]
```

#### NHS East Cheshire Talking Therapies AMC03

**Outcome 1:** ✔️ The trends are parallel

**Outcome 2:** ✔️ The trends are parallel

```{r}
#| label: cem - ne cheshire
#| fig-height: 8
#| cache: true

plot_list[[2]]
```

#### Centre for Psychology ANV01

**Outcome 1:** ✔️ The trends are almost parallel, there is a hint of divergence but seems to be caused by the spikes in the latter part of 2022

**Outcome 2:** ✔️ The trends are almost parallel, there is a hint of divergence but seems to be caused by the spikes in the latter part of 2022

```{r}
#| label: cem - centre
#| fig-height: 8
#| cache: true

plot_list[[3]]
```

#### Livewell Southwest NR5

**Outcome 1:** ❌ The trends are convergent

**Outcome 2:** ❌ The trends are convergent

```{r}
#| label: cem - livewell
#| fig-height: 8
#| cache: true

plot_list[[4]]
```

#### Dorset Healthcare University NHS Foundation Trust RDY

**Outcome 1:** ❌ The trends are convergent, and Dorset's data begins in late 2022

**Outcome 2:** ❌ The trends are convergent, and Dorset's data begins in late 2022

```{r}
#| label: cem - dorset
#| fig-height: 8
#| cache: true

plot_list[[5]]
```

#### Psychological Partnership NHS Foundation Trust RDYDL

**Outcome 1:** ✔️ The trends are very close, there is a hint that they crossed over

**Outcome 2:** ✔️ The trends are almost parallel

```{r}
#| label: cem - psychological
#| fig-height: 8
#| cache: true

plot_list[[6]]
```

#### Cornwall Partnership NHS Foundation Trust RJ8

**Outcome 1:** ✔️ The trends are parallel from mid-2022 onwards

**Outcome 2:** ✔️ The trends are parallel from mid-2022 onwards

```{r}
#| label: cem - cornwall
#| fig-height: 8
#| cache: true

plot_list[[7]]
```

#### Midlands Partnership University NHS Foundation Trust RRE

**Outcome 1:** ✔️ The trends are parallel from mid-2022 onwards

**Outcome 2:** ✔️ The trends are parallel

```{r}
#| label: cem - midlands
#| fig-height: 8
#| cache: true

plot_list[[8]]
```

#### Wallsend Health Centre RTF61

**Outcome 1:** ✔️ The trends are parallel

**Outcome 2:** ✔️ The trends are parallel

```{r}
#| label: cem - wallsend
#| fig-height: 8
#| cache: true

plot_list[[9]]
```

#### Mersey Care NHS Foundation Trust RW4

**Outcome 1:** ✔️ The trends are parallel

**Outcome 2:** ✔️ The trends are parallel

```{r}
#| label: cem - mersey
#| fig-height: 8
#| cache: true

plot_list[[10]]
```

#### Lancashire and South Cumbria NHS Foundation Trust HQ RW501

**Outcome 1:** ✔️ The trends are parallel

**Outcome 2:** ✔️ The trends are parallel

```{r}
#| label: cem - lancashire
#| fig-height: 8
#| cache: true

plot_list[[11]]
```

#### Sheffield Health Partnership University NHS Foundation Trust TAH

**Outcome 1:** ✔️ The trends are parallel from mid-2022 onwards

**Outcome 2:** ✔️ The trends are parallel

```{r}
#| label: cem - sheffield
#| fig-height: 8
#| cache: true

plot_list[[12]]
```

### Matching summary

A total of 12 Talking Therapy services were matched with `r params$intervention_long_name` using *Coarsened Exact Matching (CEM)*. Of these, 10 exhibited pre-intervention trends that closely align with those of `r params$intervention_long_name` for both outcome measures.

In three instances, alignment in trends was notably stronger from mid-2022 onward. To enhance comparability of control services and improve the precision of the counterfactual estimate, the pre-intervention period will be truncated to begin in July 2022.

```{r}
#| label: cem - matches with parallel trends
#| cache: true

# list out the matches with parallel pre-intervention trends
matches_parallel_ods <- c(
  "AM7",
  "AMC03",
  "ANV01",
  "RDYDL",
  "RJ8",
  "RRE",
  "RTF61",
  "RW4",
  "RW501",
  "TAH"
)

# add these controls to a list for use in the synthetic control section
controls <- list(
  "cem_all" = matches$ods_code,
  "cem_parallel" = matches_parallel_ods
)

# display these in a table
matches |>
  dplyr::filter(ods_code %in% matches_parallel_ods) |>
  dplyr::select(name, ods_code) |>
  dplyr::arrange(ods_code) |>
  gt::gt() |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::cols_label(
    name = "Talking Therapies organisation",
    ods_code = "ODS code"
  )
```

### Analysis

Now we have matched `r params$intervention_long_name` with 10 other Talking Therapy services and assessed their likelihood of meeting the parallel trends assumption based on their pre-intervention data, let us review how the full time series looks for this group of services.

#### Outcome 1

```{r}
#| label: cem - spaghetti plot1 outcome 1
#| fig-height: 6
#| cache: true

# get a df with the details for our matched services
df_analysis <-
  df |>
  dplyr::filter(
    # limit to activity between Jul 2022 and May 2025
    dplyr::between(
      calc_month,
      zoo::as.yearmon("Jul 2022"),
      zoo::as.yearmon("May 2025")
    ),
    # limit to our matched services with parallel trends
    ods_code %in% c(params$ods_intervention, matches_parallel_ods)
  ) |>
  # simplify the data
  dplyr::select(ods_code, calc_month, o1_rate, o2_rate) |>
  # create treatment and post indicators
  dplyr::mutate(
    treated = dplyr::if_else(ods_code == params$ods_intervention, 1L, 0L),
    post = dplyr::if_else(calc_month >= params$zoo_intervention_month, 1L, 0L),
    line_colour = dplyr::if_else(
      ods_code == params$ods_intervention,
      "#f9bf07",
      adjustcolor("#9d928a", alpha.f = 0.5)
    )
  )

# show a spaghetti plot for these services
p <-
  plot_spaghetti_plot(
    df = df_analysis,
    str_outcome = "o1_rate",
    ods_intervention = params$ods_intervention,
    str_title = "Outcome 1: discharges with 5+ treatment contacts",
    str_subtitle = "",
    zoo_intervention = params$zoo_intervention_month,
    bool_intervention = TRUE
  )
p
# p |> plotly::ggplotly()
```

**What this chart shows:**

-   Performance against outcome 1 is shown on the y-axis and time is along the x-axis.

-   There are three time series displayed, one for `r params$intervention_long_name`, shown in orange, and one for each of the two of our matched services, shown in grey.

-   Each series is identified by its ODS code at the end of the data in May 2025.

-   The dotted line represents the start of `r params$intervention_long_name`'s interventions in `r params$zoo_intervention_month`.

**Key observations:**

The control services appear to be a good visual match for `r params$intervention_long_name` in the pre- and post-intervention periods.

#### Outcome 2

```{r}
#| label: cem - spaghetti plot1 outcome 2
#| fig-height: 6
#| cache: true

# show a spaghetti plot for outcome 2
p <-
  plot_spaghetti_plot(
    df = df_analysis,
    str_outcome = "o2_rate",
    ods_intervention = params$ods_intervention,
    str_title = "Outcome 2: discharges achieving reliable recovery",
    str_subtitle = "",
    zoo_intervention = params$zoo_intervention_month,
    bool_intervention = TRUE
  )
p
# p |> plotly::ggplotly()
```

**Key observations:**

The control services appear to be a good visual match for `r params$intervention_long_name` in the pre- and post-intervention periods.

#### Difference-in-Differences (DiD)

The results of the DiD analyses are presented below:

```{r}
#| label: cem - did table
#| cache: true

# conduct did analysis on the two matched services
did <-
  get_manual_did_estimation(
    df = df_analysis,
    ods_intervention = params$ods_intervention,
    zoo_intervention = params$zoo_intervention_month
  )

# add to a combined summary (for sensitivity analysis)
did_overall <-
  did |>
  dplyr::mutate(specification = "Main model (baseline)")

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  tibble::tibble(
    specification = "CEM main model",
    outcome = did$outcome,
    estimate = did$estimate,
    se = did$std.error
  )

# display
did |>
  dplyr::select(
    outcome,
    estimate,
    conf.low,
    conf.high,
    p.value
  ) |>
  gt::gt() |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::fmt_percent(
    columns = c(estimate, conf.low, conf.high),
    decimals = 2
  ) |>
  gt::cols_merge(
    columns = c(conf.low, conf.high),
    pattern = "{1} to {2}"
  ) |>
  gt::cols_label(
    outcome = "Outcome",
    estimate = "Difference-in-Differences (DiD) estimate",
    conf.low = "95% confidence interval"
  ) |>
  gt::tab_style(
    style = list(gt::cell_text(weight = "bold")),
    locations = gt::cells_body(
      columns = c(estimate, conf.low),
      rows = p.value <= 0.05
    )
  ) |>
  gt::cols_hide(columns = p.value) |>
  gt::tab_source_note(gt::md(
    "Statistically significant findings are shown in **bold**"
  ))
```

This table summarises the Difference-in-Differences analysis for `r params$intervention_long_name`'s interventions using the 10 controls identified using the Coarsened Exact Matching process and which exhibited parallel trends.

For outcome 1, `r params$intervention_long_name`'s observed rate is about **0.6% higher** than what the matched controls would predict, yet the 95% confidence interval (-1.8% to 2.9%) includes zero, indicating **no statistically reliable difference**.

For outcome 2, `r params$intervention_long_name`'s rate is about **1.7% higher** than expected, yet the 95% confidence interval (-0.8% to 4.3%) includes zero, indicating **no statistically reliable difference**.

::: callout-tip
## Interpretation

```{r}
#| label: interpretation help cem
#| cache: true

# work out the total discharges in 12 months preceeding
total_discharges <-
  df |>
  dplyr::filter(
    ods_code == params$ods_intervention,
    dplyr::between(
      calc_month,
      zoo::as.yearmon("Jun 2024"),
      zoo::as.yearmon("May 2025")
    )
  ) |>
  dplyr::summarise(
    total = sum(o1_denom_discharges_count, na.rm = TRUE)
  ) |>
  dplyr::pull(total)

# work out the expected number of people to benefit from the uplift
people_benefit_o1 <- floor(total_discharges * (0.58 / 100))
people_benefit_o2 <- floor(total_discharges * (1.73 / 100))
```

These figures clearly present `r params$intervention_long_name`'s post-intervention performance exceeding the counterfactual based on the matched services for both outcomes, but the wide confidence intervals **prevents** a definitive claim of effectiveness for **both outcomes**.

Assuming the 1.7% gain is real, it translates to an additional **`r people_benefit_o2` people** achieving reliable recovery per year (based on `r params$intervention_long_name`'s annual discharge volume of `r scales::comma(total_discharges)` from June 2024 to May 2025).
:::

### Sensitivity analysis

An important decision was made that led to the above analytical findings:

1.  **Parallel trend selection** - We inspected the 12 matched controls series visually and excluded two that did not follow `r params$intervention_long_name`'s pre-intervention trend.

Below we reassess the findings after relaxing each of this decision to determine whether the original conclusions hold or are sensitive to this analytical choice.

#### Using all CEM controls

What impact does using all 12 matched control services have on the findings?

```{r}
#| label: cem - sensitivity - all controls
#| cache: true

# get a df with the details for our matched services
df_analysis <-
  df |>
  dplyr::filter(
    # limit to activity between Jan 2022 and May 2025
    dplyr::between(
      calc_month,
      zoo::as.yearmon("Jul 2022"),
      zoo::as.yearmon("May 2025")
    ),
    # limit to our matched services
    ods_code %in% c(params$ods_intervention, controls$cem_all)
  ) |>
  # simplify the data
  dplyr::select(ods_code, calc_month, o1_rate, o2_rate) |>
  # create treatment and post indicators
  dplyr::mutate(
    treated = dplyr::if_else(ods_code == params$ods_intervention, 1L, 0L),
    post = dplyr::if_else(calc_month >= params$zoo_intervention_month, 1L, 0L),
    line_colour = dplyr::if_else(
      ods_code == params$ods_intervention,
      "#f9bf07",
      adjustcolor("#9d928a", alpha.f = 0.5)
    )
  )

# conduct did analysis on the two matched services
did <-
  get_manual_did_estimation(
    df = df_analysis,
    ods_intervention = params$ods_intervention,
    zoo_intervention = params$zoo_intervention_month
  )

# add to a combined summary (for sensitivity analysis)
did_overall <-
  dplyr::bind_rows(
    did_overall,
    did |>
      dplyr::mutate(specification = "Alternative 1 - use all 12 controls")
  )

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "CEM alternative 1 - use all 12 controls",
      outcome = did$outcome,
      estimate = did$estimate,
      se = did$std.error
    )
  )


# display as a table
did |>
  dplyr::select(
    outcome,
    estimate,
    conf.low,
    conf.high,
    p.value
  ) |>
  gt::gt() |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::fmt_percent(
    columns = c(estimate, conf.low, conf.high),
    decimals = 2
  ) |>
  gt::cols_merge(
    columns = c(conf.low, conf.high),
    pattern = "{1} to {2}"
  ) |>
  gt::cols_label(
    outcome = "Outcome",
    estimate = "Difference-in-Differences (DiD) estimate",
    conf.low = "95% confidence interval"
  ) |>
  gt::tab_style(
    style = list(gt::cell_text(weight = "bold")),
    locations = gt::cells_body(
      columns = c(estimate, conf.low),
      rows = p.value <= 0.05
    )
  ) |>
  gt::cols_hide(columns = p.value) |>
  gt::tab_source_note(gt::md(
    "Statistically significant findings are shown in **bold**"
  ))
```

For outcome 1, `r params$intervention_long_name`'s observed rate is **0.9% higher** than what the matched controls would predict, yet the 95% confidence interval (-1.5% to 3.2%) also includes zero, indicating **no statistically reliable difference**.

For outcome 2, `r params$intervention_long_name`'s observed rate is **2.2% higher** than what the matched controls would predict, yet the 95% confidence interval (-0.3% to 4.6%) also includes zero, indicating **no statistically reliable difference**.

#### Summary

```{r}
#| label: cem - sensitivity summary
#| cache: false

# display a summary table of results
did_overall |>
  # simplify
  dplyr::select(
    specification,
    outcome,
    did = estimate,
    p.value,
    conf.low,
    conf.high
  ) |>
  # group by the sensitivity test
  dplyr::group_by(specification) |>
  gt::gt(row_group_as_column = TRUE) |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  gt::fmt_percent(columns = c(did, conf.low, conf.high), decimals = 2) |>
  gt::cols_merge(columns = c(conf.low, conf.high), pattern = "{1} to {2}") |>
  gt::tab_style(
    style = list(gt::cell_text(weight = "bold")),
    locations = gt::cells_body(
      columns = c(did, conf.low),
      rows = p.value <= 0.05
    )
  ) |>
  gt::cols_hide(columns = p.value) |>
  gt::cols_label(
    outcome = "Outcome",
    did = "DiD estimate",
    conf.low = "95% confidence interval"
  ) |>
  gt::tab_source_note(gt::md(
    "Statistically significant findings are shown in **bold**"
  ))
```

This sensitivity test **reinforces** the main findings.

*When all 12 matched services are used as controls*, the results remain consistent with the primary analysis. Expanding the control pool slightly increases the estimated treatment effect for both outcomes; however, the 95% confidence interval continues to include zero, indicating that **neither outcome reaches statistical significance**.

## Synthetic Difference-in-Differences (DiD)

The preceeding section highlights the challenges of finding genuine control services that closely match `r params$intervention_long_name`'s profile and satisfy the parallel-trends assumption. Because the estimated treatment effect proved sensitive to several analytical choices, we turn to alternative method: synthetic controls.

Synthetic Difference-in-Differences (Synthetic DiD) blends two ideas: the traditional difference-in-differences method and the synthetic control technique.

-   First it builds a "synthetic" version of the control group by assigning weights to untreated units so that, before the intervention, this synthetic group looks just like the treated unit.

-   Then it compares the outcomes after the intervention between the treated unit and its synthetic counterpart. By creating a better-matched control, Synthetic DiD helps produce more reliable estimates of a treatment's effect, especially when the parallel-trend assumption is weak.

The [{synthdid}](https://synth-inference.github.io/synthdid/) package was used to conduct these Synthetic DiD analyses. This uses the method described by [@arkhangelsky2019] to combine the strengths of synthetic-control weighting with the traditional DiD framework. According to the paper this technique delivers unbiased treatment-effect estimates, even when the parallel-trends assumption is violated.

In this approach we will build a 'donor pool' of all Talking Therapy services to create a synthetic counterfactual that estimates how `r params$intervention_long_name` would have performed without its interventions.

-   aAs with the earlier section, we first exclude any service that has its own adherence-improvement intervention

-   The {synthdid} package requires a balanced panel; every service in the donor pool must have data for every month from July 2022 through May 2025.

-   Consequently, any service with even a single missing month is dropped from the donor pool.

### Outcome 1

```{r}
#| label: synthdid - outcome 1
#| fig-height: 8
#| warning: false
#| cache: true
#| eval: true

# set up for the did analysis
set.seed(12345)
.yearmon_period = zoo::as.yearmon(c("Jul 2022", "Jun 2025"))
.yearmon_intervention = params$zoo_intervention_month

# get a dataset that is ready for synthetic DiD
df_synth <-
  prepare_df_for_synthdid(
    df = df,
    outcome = "o1_rate",
    yearmon_period = .yearmon_period,
    yearmon_intervention = .yearmon_intervention,
    ods_treated = params$ods_intervention,
    df_intervention_services = df_intervention_services
  )

# get the did estimate, confidence intervals and plot
did <-
  delegate_synthdid_analysis(
    df_synth = df_synth,
    .yearmon_intervention = .yearmon_intervention,
    .yearmon_period = .yearmon_period,
    .yearmon_scale_to = zoo::as.yearmon("Dec 2025"),
    .ods_treated = params$ods_intervention,
    str_treated = params$intervention_short_name,
    summary_spec = "Main model (baseline)",
    summary_outcome = "Outcome 1",
    str_outcome = "o1_rate",
    labs_title = "Outcome 1: discharges with 5+ treatment contacts"
  )

# add these findings to a combined summary (for sensitivity analysis)
did_overall <-
  did$did_summary

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "Synthdid main model (all controls)",
      outcome = "Outcome 1",
      estimate = as.numeric(did$did_estimate),
      se = did$did_se
    )
  )

# display the plot
did$did_plot
```

**What the chart displays**

+------------------------------+-------------------------------------------------------------------------------+-------------------------------------------+
| Element                      | Meaning                                                                       | Visual clue                               |
+==============================+===============================================================================+===========================================+
| Axes                         | Outcome performance (y-axis) vs time (x-axis)                                 | Standard Cartesian axes                   |
+------------------------------+-------------------------------------------------------------------------------+-------------------------------------------+
| Project's actual performance | Measured values for the project                                               | Orange solid line                         |
+------------------------------+-------------------------------------------------------------------------------+-------------------------------------------+
| Synthetic control            | Counterfactual series built from weighted pre-intervention data               | Blue solid line                           |
+------------------------------+-------------------------------------------------------------------------------+-------------------------------------------+
| Intervention start           | Point at which the project's interventions began                              | Vertical grey line                        |
+------------------------------+-------------------------------------------------------------------------------+-------------------------------------------+
| Pre-intervention weights     | Relative contribution of each pre-intervention month to the synthetic control | Pink shapes in the lower-left corner      |
+------------------------------+-------------------------------------------------------------------------------+-------------------------------------------+
| Parallelogram overlay        | Visual comparison of the two trajectories                                     | Blue-topped edge = synthetic control path |
|                              |                                                                               |                                           |
|                              |                                                                               | Dotted bottom edge = counterfactual path  |
|                              |                                                                               |                                           |
|                              |                                                                               | Orange line = project's actual trajectory |
+------------------------------+-------------------------------------------------------------------------------+-------------------------------------------+

: Chart key

**How to read the parallelogram**

-   Top edge (blue) - trajectory of the synthetic control from the pre- to post-intervention period

-   Bottom edge (dotted) - what `r params$intervention_long_name`'s trend would have looked like without any interventions (the counterfactual)

-   Orange line - `r params$intervention_long_name`'s observed post-intervention trend.

`r params$intervention_long_name`'s orange line rises more sharply than the dotted counterfactual, indicating a positive impact of the interventions. The estimated gain is 0.1% above the expected value. The 95% confidence interval spans -6% to + 6%, meaning the true effect could be slightly negative or moderately positive. Consequently, the result is not statistically significant.

#### Contribution plot

```{r}
#| label: synthdid - outcome 1 - contribution plot
#| fig-height: 5
#| warning: false
#| cache: true
#| eval: true

set.seed(12345)

synthdid::synthdid_units_plot(
  estimates = did$did_estimate,
  se.method = "placebo"
) +
  ggplot2::theme(axis.text.x = ggplot2::element_text(size = 5))
```

This plot shows:

-   The synthetic estimate as the black horizontal line

-   Each control Talking Therapy service as a point, where servicees that contribute more weight to the synthetic model shown in larger size

-   The grey horizontal lines represent the end points of a 95% confidence interval

A total of `r length(summary(did$did_estimate)$controls)` Talking Therapy services were used in the construction of this synthetic control.

### Outcome 2

```{r}
#| label: synthdid - outcome 2
#| fig-height: 8
#| warning: false
#| cache: true
#| eval: true

# set seed for reproducibility
set.seed(12345)

df_synth <-
  prepare_df_for_synthdid(
    df = df,
    outcome = "o2_rate",
    yearmon_period = .yearmon_period,
    yearmon_intervention = .yearmon_intervention,
    ods_treated = params$ods_intervention,
    df_intervention_services = df_intervention_services
  )

# get the did estimate, confidence intervals and plot
did <-
  delegate_synthdid_analysis(
    df_synth = df_synth,
    .yearmon_intervention = .yearmon_intervention,
    .yearmon_period = .yearmon_period,
    .yearmon_scale_to = zoo::as.yearmon("Dec 2025"),
    .ods_treated = params$ods_intervention,
    str_treated = params$intervention_short_name,
    summary_spec = "Main model (baseline)",
    summary_outcome = "Outcome 2",
    str_outcome = "o2_rate",
    labs_title = "Outcome 2: discharges achieving reliable recovery"
  )

# add these findings to a combined summary (for sensitivity analysis)
did_overall <-
  dplyr::bind_rows(
    did_overall,
    did$did_summary
  )

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "Synthdid main model (all controls)",
      outcome = "Outcome 2",
      estimate = as.numeric(did$did_estimate),
      se = did$did_se
    )
  )

# display the plot
did$did_plot
```

**How to read the parallelogram**

-   Top edge (dotted) - what `r params$intervention_long_name`'s trend would have looked like without any interventions (the counterfactual)

-   Bottom edge (blue) - trajectory of the synthetic control from the pre- to post-intervention period

-   Orange line - `r params$intervention_long_name`'s observed post-intervention trend.

`r params$intervention_long_name`'s orange line rises much more sharply than the dotted counterfactual, indicating an effect in the post-intervention period. The estimated difference is 1.8% above the expected value. The 95% confidence interval spans -4% to + 8%, meaning the true effect could be negative or positive. Consequently, the result is **not statistically significant**.

#### Contribution plot

```{r}
#| label: synthdid - outcome 2 - contribution plot
#| fig-height: 5
#| warning: false
#| cache: true
#| eval: true

set.seed(12345)

synthdid::synthdid_units_plot(
  estimates = did$did_estimate,
  se.method = "placebo"
) +
  ggplot2::theme(axis.text.x = ggplot2::element_text(size = 5))
```

A total of `r length(summary(did$did_estimate)$controls)` Talking Therapy services were used in the construction of this synthetic control.

### Summary

```{r}
#| label: synthdid - summary table
#| cache: true
#| eval: true

did_overall |>
  display_did_summary_in_gt(sensitivity_summary = FALSE)
```

::: callout-tip
## Interpretation

```{r}
#| label: interpretation help synthdid
#| cache: true
#| eval: false

# work out the total discharges in 12 months preceeding
total_discharges <-
  df |>
  dplyr::filter(
    ods_code == params$ods_intervention,
    dplyr::between(
      calc_month,
      zoo::as.yearmon("Jun 2024"),
      zoo::as.yearmon("May 2025")
    )
  ) |>
  dplyr::summarise(
    total = sum(o1_denom_discharges_count, na.rm = TRUE)
  ) |>
  dplyr::pull(total)

# work out the expected number of people to benefit from the uplift
people_benefit_o1 <- floor(total_discharges * (0.1 / 100))
people_benefit_o2 <- floor(total_discharges * (1.8 / 100))
```

The charts indicate `r params$intervention_long_name`'s post-intervention performance exceeding the synthetic counterfactual, but the wide confidence interval prevents a definitive claim of effectiveness for both outcomes.

Assuming the 1.8% gain for Outcome 2 is real, it translates to an additional **`r people_benefit_o2` people** achieving reliable per year (based on `r params$intervention_long_name`'s annual discharge volume of `r scales::comma(total_discharges)` from June 2024 to May 2025).
:::

### Sensitivity analysis

In the previous analysis we supplied {synthdid} with the outcomes for *all* Talking Therapy services that were not involved in any known adherence-improving intervention. This full set served as the donor pool for constructing a counterfactual that best matches `r params$intervention_long_name`'s pre-intervention outcome trends.

We adopted this approach because synthetic-control methods require a reasonably large donor pool to generate a reliable weighted counterfactual. However, the [coarsened exact matching](#coarsened-exact-matching-mar-2024) section showed that the donor pool varies across our matching variables.

In this section we examine how restricting the donor pool influences the DiD estimates and assess whether our original conclusions remain robust or become sensitive to these restrictions.

#### Using matches from CEM

What impact does using the matches returned from the [coarsened exact matching (CEM)](#coarsened-exact-matching-mar-2024) section have?

```{r}
#| label: synthdid - sensitivity CEM - outcome 1
#| fig-height: 7
#| warning: false
#| cache: true
#| eval: true

set.seed(12345)

# get a did estimate
df_synth <-
  prepare_df_for_synthdid(
    df = df,
    outcome = "o1_rate",
    yearmon_period = .yearmon_period,
    yearmon_intervention = .yearmon_intervention,
    ods_treated = params$ods_intervention,
    ods_controls = controls$cem_all,
    df_intervention_services = df_intervention_services
  )

# get the did estimate, confidence intervals and plot
did <-
  delegate_synthdid_analysis(
    df_synth = df_synth,
    .yearmon_intervention = .yearmon_intervention,
    .yearmon_period = .yearmon_period,
    .yearmon_scale_to = zoo::as.yearmon("Mar 2026"),
    .ods_treated = params$ods_intervention,
    str_treated = params$intervention_short_name,
    summary_spec = "Alternative 1 - using all CEM matches",
    summary_outcome = "Outcome 1",
    str_outcome = "o1_rate",
    labs_title = "Outcome 1: discharges with 5+ treatment contacts"
  )

# add these findings to a combined summary (for sensitivity analysis)
did_overall <-
  dplyr::bind_rows(
    did_overall,
    did$did_summary
  )

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "Synthdid alternative 2 (CEM controls)",
      outcome = "Outcome 1",
      estimate = as.numeric(did$did_estimate),
      se = did$did_se
    )
  )

# display the plot
did$did_plot
```

`r params$intervention_long_name`'s observed outcome was **2.8% higher** than the synthetic control expectation. However, the 95% confidence interval (-10% to 16%) includes zero, so the result is not statistically distinguishable from no effect.

```{r}
#| label: synthdid - sensitivity CEM - outcome 2
#| fig-height: 7
#| warning: false
#| cache: true
#| eval: true

set.seed(12345)

df_synth <-
  prepare_df_for_synthdid(
    df = df,
    outcome = "o2_rate",
    yearmon_period = .yearmon_period,
    yearmon_intervention = .yearmon_intervention,
    ods_treated = params$ods_intervention,
    ods_controls = controls$cem_all,
    df_intervention_services = df_intervention_services
  )

# get the did estimate, confidence intervals and plot
did <-
  delegate_synthdid_analysis(
    df_synth = df_synth,
    .yearmon_intervention = .yearmon_intervention,
    .yearmon_period = .yearmon_period,
    .yearmon_scale_to = zoo::as.yearmon("Mar 2026"),
    .ods_treated = params$ods_intervention,
    str_treated = params$intervention_short_name,
    summary_spec = "Alternative 1 - using all CEM matches",
    summary_outcome = "Outcome 2",
    str_outcome = "o2_rate",
    labs_title = "Outcome 2: discharges achieving reliable recovery"
  )

# add these findings to a combined summary (for sensitivity analysis)
did_overall <-
  dplyr::bind_rows(
    did_overall,
    did$did_summary
  )

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "Synthdid alternative 2 (CEM controls)",
      outcome = "Outcome 2",
      estimate = as.numeric(did$did_estimate),
      se = did$did_se
    )
  )

# display the plot
did$did_plot
```

`r params$intervention_long_name`'s observed outcome was **3.3% higher** than the synthetic control expectation. However, the 95% confidence interval (-3% to 10%) includes zero, so the result is not statistically distinguishable from no effect.

#### Using a September 2024 intervention date

`r params$intervention_long_name` launched a therapy-adherence programme in April 2023, which ran to March 2025. In the main analyses we treated April 2023 as the start of the intervention and all subsequent months as the post-intervention period.

Here we re-define the intervention point to September 2024, the midpoint of the programme, and examine how this alternate timing affects the estimated impact.

```{r}
#| label: synthdid - sensitivity sep 2024 - outcome 1
#| fig-height: 7
#| warning: false
#| cache: true
#| eval: true

set.seed(12345)

# get a did estimate
df_synth <-
  prepare_df_for_synthdid(
    df = df,
    outcome = "o1_rate",
    yearmon_period = .yearmon_period,
    yearmon_intervention = zoo::as.yearmon("Sep 2024"),
    ods_treated = params$ods_intervention,
    df_intervention_services = df_intervention_services
  )

# get the did estimate, confidence intervals and plot
did <-
  delegate_synthdid_analysis(
    df_synth = df_synth,
    .yearmon_intervention = zoo::as.yearmon("Sep 2024"),
    .yearmon_period = .yearmon_period,
    .yearmon_scale_to = zoo::as.yearmon("Apr 2026"),
    .ods_treated = params$ods_intervention,
    str_treated = params$intervention_short_name,
    summary_spec = "Alternative 2 - using September 2024 intervention",
    summary_outcome = "Outcome 1",
    str_outcome = "o1_rate",
    labs_title = "Outcome 1: discharges with 5+ treatment contacts"
  )

# add these findings to a combined summary (for sensitivity analysis)
did_overall <-
  dplyr::bind_rows(
    did_overall,
    did$did_summary
  )

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "Synthdid alternative 2 (September 2024 intervention)",
      outcome = "Outcome 1",
      estimate = as.numeric(did$did_estimate),
      se = did$did_se
    )
  )

# display the plot
did$did_plot
```

```{r}
#| label: synthdid - sensitivity sep 2024 - outcome 2
#| fig-height: 7
#| warning: false
#| cache: true
#| eval: true

set.seed(12345)

# get a did estimate
df_synth <-
  prepare_df_for_synthdid(
    df = df,
    outcome = "o2_rate",
    yearmon_period = .yearmon_period,
    yearmon_intervention = zoo::as.yearmon("Sep 2024"),
    ods_treated = params$ods_intervention,
    df_intervention_services = df_intervention_services
  )

# get the did estimate, confidence intervals and plot
did <-
  delegate_synthdid_analysis(
    df_synth = df_synth,
    .yearmon_intervention = zoo::as.yearmon("Sep 2024"),
    .yearmon_period = .yearmon_period,
    .yearmon_scale_to = zoo::as.yearmon("Apr 2026"),
    .ods_treated = params$ods_intervention,
    str_treated = params$intervention_short_name,
    summary_spec = "Alternative 2 - using September 2024 intervention",
    summary_outcome = "Outcome 2",
    str_outcome = "o2_rate",
    labs_title = "Outcome 2: discharges achieving reliable recovery"
  )

# add these findings to a combined summary (for sensitivity analysis)
did_overall <-
  dplyr::bind_rows(
    did_overall,
    did$did_summary
  )

# add details to a summary of ALL analyses in this document for selection for a subsequent meta analysis
did_meta <-
  dplyr::bind_rows(
    did_meta,
    tibble::tibble(
      specification = "Synthdid alternative 2 (September 2024 intervention)",
      outcome = "Outcome 2",
      estimate = as.numeric(did$did_estimate),
      se = did$did_se
    )
  )

# display the plot
did$did_plot
```

#### Summary

```{r}
#| label: synthdid - sensitivity - summary table
#| cache: true
#| eval: true

did_overall |>
  display_did_summary_in_gt(sensitivity_summary = TRUE)

# save a copy of the summary table for future meta-analyses
saveRDS(
  object = did_meta,
  file = here::here("data", "project", "did_estimates", "nehants.Rds")
)
```

The sensitivity analyses suggest that the main results are broadly credible, but they also highlight where the evidence is fragile.

The main model, using all available control services to construct the synthetic control, found **no statistically significant effect for either Outcome 1 or Outcome 2**.

To assess the robustness to the choice of donor pool we re-ran the synthetic difference-in-differences analyses using the matched services identified using coarsened exact matching, and to assess robustness to when the intervention started we conducted an analysis with September 2024 as the start point.

*Coarsened exact matching (CEM)* - Using the CEM-derived donor pool reproduces the main findings: `r params$intervention_long_name` tends to perform **slightly better** than its peers, but the confidence intervals are wide enough that we cannot reject the null hypothesis of no difference. CEM forces exact balance on key covariates, reducing heterogeneity among donor units.

*September 2024* - The treatment effect drops for both outcomes, making Outcome 2 become negative, but the confidence intervals are wide enough that we cannot reject the null hypothesis of no difference.

Overall, none of the estimates are statistically significant, as all 95% confidence intervals include zero. This suggest the intervention **does not have a robust or consistent effect** on either outcome and across differnet specifications.

## Supplementary analysis

```{r}
#| label: supp - gather data
#| cache: false
supp1 <-
  delegate_supp_outcome_analysis(
    supp = "mutual_discharge",
    ods_intervention = params$ods_intervention,
    str_intervention = params$intervention_short_name,
    ods_controls = c("RAT"),
    zoo_intervention = params$zoo_intervention_month,
    zoo_period = zoo::as.yearmon(c("Jan 2022", "May 2025")),
    str_plot_subtitle = "No significant changes for either treatment intensity group"
  )

supp2 <-
  delegate_supp_outcome_analysis(
    supp = "reliable_recovery",
    ods_intervention = params$ods_intervention,
    str_intervention = params$intervention_short_name,
    ods_controls = c("RAT"),
    zoo_intervention = params$zoo_intervention_month,
    zoo_period = zoo::as.yearmon(c("Jan 2022", "May 2025")),
    str_plot_subtitle = "No significant changes for either treatment intensity group"
  )
```

To contextualise the results for out two primary outcomes, we conducted two supplementary analyses:

1.  **Mutual discharge agreement** - the proportion of discharges jointly agreed up by patient and therapist

2.  **Reliable recovery** - the proportion of discharges that met criteria for reliable recovery

For each measure we compared:

-   **Pre- vs post-intervention** periods (before and after `r params$intervention_long_name`'s interventions)

-   **Treatment intensity** groups: participants who received **\>= 5 contacts** versus those with **\< 5 contacts**

### Discharge by mutual agreement

On discharge from a Talking Therapy service, every client record must include a coded reason in the `EndCode` field. According to the [IAPT Techical Output Specification](https://digital.nhs.uk/data-and-information/information-standards/governance/latest-activity/standards-and-collections/dapb-1520-improving-access-to-psychological-therapies-data-set), there are 14 predefined categories for coding discharge reasons:

```{r}
#| label: supp - discharge codes
#| cache: true

readxl::read_xlsx(
  path = here::here("data", "reference", "iapt_tos_endcode.xlsx")
) |>
  dplyr::group_by(group) |>
  gt::gt(row_group_as_column = TRUE) |>
  gt::tab_options(quarto.disable_processing = TRUE) |>
  # label the columns
  gt::cols_label(
    code = "Code",
    description = "Definition"
  ) |>
  # highlight the code we are interested in
  # bold any statistically significant results
  gt::tab_style(
    # style = gt::cell_text(weight = "bold"),
    style = gt::cell_fill(color = "#fcdf83"),
    locations = gt::cells_body(
      # columns = gt::vars(group, statistic, p.value, parameter),
      columns = gt::any_of(c("code", "description")),
      rows = code == 46
    )
  ) |>
  # headings and footnotes
  gt::tab_header(
    title = "Discharge from Improving Access to Psychological Therapies Service Reason"
  ) |>
  gt::tab_source_note(
    "Details of `EndCode` codes from version 2.1 of the IAPT Technical Output Specification"
  )
```

This section examines the share of referrals coded as *Mutually agreed completion of treatment* (code 46) after a course of therapy.

This code indicates that both patient and therapist agree the treatment has been completed. As with the primary analyses, we restrict the sample to referrals with *at least two treatment contacts*, ensuring we are examining individuals who actually entered a course of care.

The bar chart below displays `r params$intervention_long_name`'s data only. It indicates **no noticeable change** in the proportion of mutually-agreed discharges during the post-intervention period compared with the pre-intervention period.

```{r}
#| label: supp - mutual - plot
#| cache: false
#| fig-height: 4
#| fig-width: 12

# display a bar chart
supp1$bar_plot

# display the chi-square test results
supp1$gt_chi2_results
```

The chi-squared test confirms that the observed changes are **not statistically significant** across either treatment-intensity group.

These findings suggest that the interventions had no discernable effect on the proportion of referrals completed through mutual agreement between patient and therapist.

### Achieving reliable recovery

This section assesses the proportion of referrals that attained *reliable recovery* after completing therapy.

Reliable recovery requires two conditions: 1) the patient's symptoms fall below the clinical threshold ('recovery'), and 2) the magnitude of symptom reduction exceeds the reliable index, indicating a change that is statistically meaningful.

As with the previous analysis, the bar chart shows only `r params$intervention_long_name`'s data. In indicates **no noticeable change** in the proportion of discharged referrals achieving reliable recovery during the post-intervention period compared with the pre-intervention period.

```{r}
#| label: supp - recovery - plot
#| cache: true
#| fig-height: 4
#| fig-width: 12

# display a bar chart
supp2$bar_plot

# display the chi-square test results
supp2$gt_chi2_results
```

The chi-squared test confirms that the observed changes are **not statistically significant** across either treatment-intensity group.

These findings suggest that the interventions had no discernable effect on the proportion of referrals achieving reliable recovery.

# Conclusions

We estimated the impact of `r params$intervention_long_name`'s interventions using two complimentary DiD approaches:

-   **Manual DiD** - `r params$intervention_long_name` was compared with 10 services selected through a coarsened exact matched (CEM) procedure

-   **Synthetic control DiD** - `r params$intervention_long_name` was contrasted with a synthetic counterfactual build from all available donor services.

For the CEM and synthetic approaches we performed a series of sensitivity checks, for example, expanding the control pool and changing the intervention start date and using different matching methods.

**No robust or consistent evidence** was found that the interventions improved therapy adherence or outcomes.

-   Outcome 1: Proportion of patients receiving five or more treatment sessions showed **slightly positive trends**, but **none were statistically significant**.

-   Outcome 2: Proportion of patients achieving reliable recovery showed **modest improvements** in some models but these were highly sensitive to analytical choices and **none were consistently significant**.

Across all models, confidence intervals included zero, meaning no statistically reliable effect could be confirmed. There is a possible signal of benefit, especially for Outcome 2, but evidence is not strong enough to support definitive conclusions.

**Recommendations for future evaluation**

To obtain a definitive assessment of `r params$intervention_long_name`'s digital-resource and communication interventions, a more rigorous experimental design is needed:

1.  Identify a cohort of comparable services using the matching variables described in this report

2.  Randomly assign half of the services to receive the full intervention package (FAQ pages, explanatory animations, assessment video, communication review, DNA rate tracking) and the other half to serve as controls

3.  Track outcomes prospectively over and adequate post-intervention horizon

4.  Analyust the data with a pre-registered DiD or mixed-effects model, complemented by placebo tests and robustness checks

Such a randomised controlled design would eliminate the donor-pool and specification sensitivities that currently limit inference, allowing a clear determination of whether `r params$intervention_long_name`'s interventions truly improve client preparation and engagement.

# Limitations

The limitations for this analysis include:

**Only one treated unit**

The causal estimate rests on a single time-series (`r params$intervention_long_name`). The result is that standard errors are large which translates to wide confidence intervals and a much larger treatment effect is required to reach statistical significance as a consequence.

**Possible hidden interventions in the donor pool**

We removed services with known interventions from the group of control services, but undisclosed changes may still be present.

Comparing `r params$intervention_long_name` to other services that are also improving attenuates the estimated effect, biasing the results toward zero.

**Time-varying confounders**

Two control services experienced abrupt shocks in mid-2023 which distorted the post-implementation average performance and synthetic control trajectory, increased variability and weakened the credibility of the counterfactual.

**No single treatment date**

`r params$intervention_long_name`'s rollout was staggered across several components and spread over twelve months. As a result the "treated" period is diffuse, making it difficult to define a clean pre-/post-intervention split and to isolate the effect of any one component.

**Synthetic control sensitivity to outliers**

The CEM-derived donor pool contained services with extreme spikes. Outliers can dominate the weighted synthetic control, producing unstable counterfactuals and potentially misleading effect sizes.

Taken together, these limitations suggest that the estimated impacts should be interpreted with caution and highlight the need for a more rigorous, preferably experimental, design in future evaluations.